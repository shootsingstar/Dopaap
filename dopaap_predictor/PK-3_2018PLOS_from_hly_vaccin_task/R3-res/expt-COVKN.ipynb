{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABICAYAAADI6S+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAACDElEQVR4nO3aP2pUURjG4e8ElWhs/BPstBIUFBQHtyK4gNmQnQtwCZItCFEbVyFRiKCVcGxsHNRhYI7vzPF5ulxu8X4EfsVlWu+9APj3DtIDAP5XAgwQIsAAIQIMECLAACECDBByYd0LrbVlVS2rqo4uHjy5d+3y8FEp368fpScM9eXKvP+785r3tqqq82+X0hOGOvy8NkV77evHd2e99+PV522T3wEvbl3tp88ebnXYLvn0/Gl6wlAnjx+lJwzzuu6nJwx18v52esJQd1/dSE8Y6s2Lw7e998Xqc58gAEIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggpPXe//5Ca8uqWv7880FVfRg9KuhmVZ2lRwwy821V7tt3s993p/d+vPpwbYB/ebm10977YquzdsjM9818W5X79t3s9/2JTxAAIQIMELJpgF8OWbE7Zr5v5tuq3LfvZr/vtzb6BgzA9vgEARAiwAAhAgwQIsAAIQIMEPID0IJRG96Z/ToAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "# 防止爆显存\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import molmap.model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette(\"rainbow_r\", 6) #PiYG\n",
    "sns.palplot(color)\n",
    "\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AA_pro\n",
    "PCP = pd.read_csv('/raid/hly/vaccin/data/cal_CTD/PCP_61.csv', index_col='properties').index\n",
    "AApro_dic = pd.read_csv('/raid/hly/umap/single_index/AApro_UMAP.csv', header=0,index_col=0)\n",
    "AA_pro = AApro_dic.loc[PCP].astype('float')\n",
    "AA_pro = AA_pro.T\n",
    "AA_pro = ((AA_pro - AA_pro.min()) / (AA_pro.max() - AA_pro.min())).T #归一化\n",
    "\n",
    "\n",
    "# get_3d_feat -- our method (老师筛选了31个理化性质，一个aa对应一个值)\n",
    "def get_3d_feat2(seq):\n",
    "    n = len(seq)\n",
    "    # 生成理化性质矩阵\n",
    "    seq_pro = pd.DataFrame(AA_pro[aa] for aa in seq).T\n",
    "    seq_pro = seq_pro.values[:, :, None]  #二维变成三维（31， n， 1）\n",
    "    # 相乘开根号\n",
    "    mt_pro = np.transpose((seq_pro * np.transpose(seq_pro, [0, 2, 1])), [1, 2, 0]) **.25\n",
    "    #transpose三维转置。（31，n，1）*（31，1，n）=（31，n，n），再转置成（n，n，31）.\n",
    "    for k in range(mt_pro.shape[2]):\n",
    "        for i in range(n):\n",
    "            for j in range(i):\n",
    "                if k < 60:                                      ##here\n",
    "                    mt_pro[i,j,k] = (mt_pro[j,i,k] * mt_pro[j,i,k+1])**.5\n",
    "                else:\n",
    "                    mt_pro[i,j,k] = (mt_pro[j,i,k] * mt_pro[j,i,0])**.5\n",
    "                \n",
    "    # 生成序列距离矩阵\n",
    "    pt_dis = np.ones((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            pt_dis[i][j] = abs(i-j)\n",
    "    pt_dis = ((pt_dis - 0) / (n-1 - 0)) ## 归一化（最小值为0，最大值为n-1）\n",
    "    pt_dis = pt_dis[:, :, np.newaxis]  ##（n，n，1）\n",
    "\n",
    "    # 将序列距离矩阵与理化性质矩阵合并，并放在第一层\n",
    "    mt = np.concatenate((pt_dis,mt_pro),axis = 2)\n",
    "    \n",
    "    x = np.pad(mt, [(0, max_seq_len-n), (0, max_seq_len-n), (0, 0)]) #填充0.令数据集中每条序列对应的Xshape相同。\n",
    "\n",
    "    return x[ :, :, :, None]\n",
    "\n",
    "\n",
    "def get_pos_weight(c):\n",
    "    cnt = [0] * 8\n",
    "    for i in Y_train:\n",
    "        if 2<= i < 4:\n",
    "            cnt[0] = cnt[0] + 1\n",
    "        if 4<= i < 5:\n",
    "            cnt[1] = cnt[1] + 1\n",
    "        if 5 <= i < 6:\n",
    "            cnt[2] = cnt[2] + 1\n",
    "        if 6<= i < 7:\n",
    "            cnt[3] = cnt[3] + 1\n",
    "        if 7<= i < 8:\n",
    "            cnt[4] = cnt[4] + 1\n",
    "        if 8<= i < 9:\n",
    "            cnt[5] = cnt[5] + 1\n",
    "        if 9<= i < 10:\n",
    "            cnt[6] = cnt[6] + 1\n",
    "        if 10<= i < 12:\n",
    "            cnt[7] = cnt[7] + 1\n",
    "    total = sum(cnt)\n",
    "    for i in range(len(cnt)):\n",
    "        if cnt[i] != 0:\n",
    "            cnt[i] = (c * total) / (cnt[i] + c * total)\n",
    "    return np.array(cnt)\n",
    "\n",
    "\n",
    "class Inception(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units = 8, strides = 1):\n",
    "        super(Inception, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv3D(units, (1,1,1), padding='same', activation = 'relu', strides = strides,kernel_regularizer=tf.keras.regularizers.l2(lamda),\n",
    "  bias_regularizer=tf.keras.regularizers.l1(lamda), activity_regularizer=tf.keras.regularizers.l2(lamda))\n",
    "        self.conv2 = tf.keras.layers.Conv3D(units, (3,3,3), padding='same', activation = 'relu', strides = strides,kernel_regularizer=tf.keras.regularizers.l2(lamda),\n",
    "  bias_regularizer=tf.keras.regularizers.l1(lamda), activity_regularizer=tf.keras.regularizers.l2(lamda))\n",
    "        self.conv3 = tf.keras.layers.Conv3D(units, (5,5,5), padding='same', activation = 'relu', strides = strides,kernel_regularizer=tf.keras.regularizers.l2(lamda),\n",
    "  bias_regularizer=tf.keras.regularizers.l1(lamda), activity_regularizer=tf.keras.regularizers.l2(lamda))\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x1 = self.conv1(inputs)\n",
    "        x2 = self.conv2(inputs)\n",
    "        x3 = self.conv3(inputs)\n",
    "        outputs = self.concat([x1, x2, x3])\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self): \n",
    "        config = {\"conv1\": self.conv1,\"conv2\":self.conv2,'conv3':self.conv3}\n",
    "        base_config = super(Inception, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HLA-A_0206_COV_(lr_0.0001-bs_32-lam_0.001-ks_[(3, 3, 7),(1, 3, 5)]-kn_(48, 32, 64))_\n",
      "epoch: 0001, loss: 0.6592 - val_loss: 0.4357; rmse: 0.2701 - rmse_val: 0.4926;  r2: 0.0634 - r2_val: -0.9371; mae: 0.2243 - mae_val: 0.4147;mse: 0.0730 - mse_val: 0.2426; r: 0.3123 - r_val: 0.5969                                                                                                    \n",
      "epoch: 0002, loss: 0.3033 - val_loss: 0.3439; rmse: 0.2709 - rmse_val: 0.5110;  r2: 0.0578 - r2_val: -1.0850; mae: 0.2211 - mae_val: 0.4349;mse: 0.0734 - mse_val: 0.2611; r: 0.4092 - r_val: 0.5650                                                                                                    \n",
      "epoch: 0003, loss: 0.2302 - val_loss: 0.2705; rmse: 0.2534 - rmse_val: 0.4553;  r2: 0.1761 - r2_val: -0.6551; mae: 0.2092 - mae_val: 0.3897;mse: 0.0642 - mse_val: 0.2073; r: 0.4684 - r_val: 0.5773                                                                                                    \n",
      "epoch: 0004, loss: 0.1870 - val_loss: 0.2319; rmse: 0.2453 - rmse_val: 0.4404;  r2: 0.2279 - r2_val: -0.5486; mae: 0.2017 - mae_val: 0.3797;mse: 0.0602 - mse_val: 0.1939; r: 0.5190 - r_val: 0.6031                                                                                                    \n",
      "epoch: 0005, loss: 0.1573 - val_loss: 0.2028; rmse: 0.2358 - rmse_val: 0.4261;  r2: 0.2866 - r2_val: -0.4495; mae: 0.1930 - mae_val: 0.3687;mse: 0.0556 - mse_val: 0.1815; r: 0.5631 - r_val: 0.6147                                                                                                    \n",
      "epoch: 0006, loss: 0.1358 - val_loss: 0.1804; rmse: 0.2308 - rmse_val: 0.4144;  r2: 0.3161 - r2_val: -0.3712; mae: 0.1880 - mae_val: 0.3595;mse: 0.0533 - mse_val: 0.1717; r: 0.5856 - r_val: 0.6114                                                                                                    \n",
      "epoch: 0007, loss: 0.1182 - val_loss: 0.1627; rmse: 0.2247 - rmse_val: 0.4049;  r2: 0.3519 - r2_val: -0.3093; mae: 0.1821 - mae_val: 0.3511;mse: 0.0505 - mse_val: 0.1640; r: 0.6144 - r_val: 0.6171                                                                                                    \n",
      "epoch: 0008, loss: 0.1043 - val_loss: 0.1585; rmse: 0.2224 - rmse_val: 0.4241;  r2: 0.3652 - r2_val: -0.4362; mae: 0.1787 - mae_val: 0.3666;mse: 0.0495 - mse_val: 0.1799; r: 0.6390 - r_val: 0.6206                                                                                                    \n",
      "epoch: 0009, loss: 0.0929 - val_loss: 0.1453; rmse: 0.2180 - rmse_val: 0.4137;  r2: 0.3898 - r2_val: -0.3664; mae: 0.1729 - mae_val: 0.3571;mse: 0.0475 - mse_val: 0.1711; r: 0.6530 - r_val: 0.6066                                                                                                    \n",
      "epoch: 0010, loss: 0.0837 - val_loss: 0.1412; rmse: 0.2129 - rmse_val: 0.4234;  r2: 0.4183 - r2_val: -0.4315; mae: 0.1690 - mae_val: 0.3658;mse: 0.0453 - mse_val: 0.1793; r: 0.6803 - r_val: 0.6152                                                                                                    \n",
      "epoch: 0011, loss: 0.0754 - val_loss: 0.1387; rmse: 0.2143 - rmse_val: 0.4339;  r2: 0.4106 - r2_val: -0.5031; mae: 0.1687 - mae_val: 0.3746;mse: 0.0459 - mse_val: 0.1883; r: 0.6981 - r_val: 0.5923                                                                                                    \n",
      "epoch: 0012, loss: 0.0692 - val_loss: 0.1150; rmse: 0.1995 - rmse_val: 0.3852;  r2: 0.4890 - r2_val: -0.1847; mae: 0.1583 - mae_val: 0.3334;mse: 0.0398 - mse_val: 0.1484; r: 0.7185 - r_val: 0.6071                                                                                                    \n",
      "epoch: 0013, loss: 0.0627 - val_loss: 0.0867; rmse: 0.2234 - rmse_val: 0.3118;  r2: 0.3593 - r2_val: 0.2238; mae: 0.1813 - mae_val: 0.2732;mse: 0.0499 - mse_val: 0.0972; r: 0.7263 - r_val: 0.6172                                                                                                    \n",
      "epoch: 0014, loss: 0.0578 - val_loss: 0.1061; rmse: 0.1916 - rmse_val: 0.3847;  r2: 0.5287 - r2_val: -0.1814; mae: 0.1502 - mae_val: 0.3326;mse: 0.0367 - mse_val: 0.1480; r: 0.7453 - r_val: 0.6061                                                                                                    \n",
      "epoch: 0015, loss: 0.0524 - val_loss: 0.0935; rmse: 0.1854 - rmse_val: 0.3581;  r2: 0.5587 - r2_val: -0.0238; mae: 0.1448 - mae_val: 0.3111;mse: 0.0344 - mse_val: 0.1282; r: 0.7559 - r_val: 0.6075                                                                                                    \n",
      "epoch: 0016, loss: 0.0484 - val_loss: 0.0845; rmse: 0.1821 - rmse_val: 0.3393;  r2: 0.5743 - r2_val: 0.0809; mae: 0.1422 - mae_val: 0.2966;mse: 0.0332 - mse_val: 0.1151; r: 0.7688 - r_val: 0.5903                                                                                                    \n",
      "epoch: 0017, loss: 0.0450 - val_loss: 0.1050; rmse: 0.1849 - rmse_val: 0.4062;  r2: 0.5614 - r2_val: -0.3176; mae: 0.1434 - mae_val: 0.3518;mse: 0.0342 - mse_val: 0.1650; r: 0.7895 - r_val: 0.5917                                                                                                    \n",
      "epoch: 0018, loss: 0.0420 - val_loss: 0.0788; rmse: 0.1740 - rmse_val: 0.3365;  r2: 0.6115 - r2_val: 0.0957; mae: 0.1355 - mae_val: 0.2914;mse: 0.0303 - mse_val: 0.1133; r: 0.7914 - r_val: 0.6155                                                                                                    \n",
      "epoch: 0019, loss: 0.0389 - val_loss: 0.0998; rmse: 0.1756 - rmse_val: 0.4037;  r2: 0.6043 - r2_val: -0.3011; mae: 0.1357 - mae_val: 0.3488;mse: 0.0308 - mse_val: 0.1629; r: 0.8148 - r_val: 0.5885                                                                                                    \n",
      "epoch: 0020, loss: 0.0365 - val_loss: 0.0931; rmse: 0.1681 - rmse_val: 0.3896;  r2: 0.6373 - r2_val: -0.2121; mae: 0.1297 - mae_val: 0.3355;mse: 0.0283 - mse_val: 0.1518; r: 0.8251 - r_val: 0.5829                                                                                                    \n",
      "epoch: 0021, loss: 0.0349 - val_loss: 0.0964; rmse: 0.1783 - rmse_val: 0.4029;  r2: 0.5919 - r2_val: -0.2962; mae: 0.1382 - mae_val: 0.3463;mse: 0.0318 - mse_val: 0.1623; r: 0.8218 - r_val: 0.5813                                                                                                    \n",
      "epoch: 0022, loss: 0.0330 - val_loss: 0.0813; rmse: 0.1599 - rmse_val: 0.3633;  r2: 0.6716 - r2_val: -0.0540; mae: 0.1238 - mae_val: 0.3134;mse: 0.0256 - mse_val: 0.1320; r: 0.8324 - r_val: 0.5986                                                                                                    \n",
      "epoch: 0023, loss: 0.0311 - val_loss: 0.0754; rmse: 0.1526 - rmse_val: 0.3485;  r2: 0.7011 - r2_val: 0.0300; mae: 0.1172 - mae_val: 0.3019;mse: 0.0233 - mse_val: 0.1215; r: 0.8470 - r_val: 0.6029                                                                                                    \n",
      "epoch: 0024, loss: 0.0288 - val_loss: 0.0733; rmse: 0.1462 - rmse_val: 0.3447;  r2: 0.7257 - r2_val: 0.0513; mae: 0.1116 - mae_val: 0.2964;mse: 0.0214 - mse_val: 0.1188; r: 0.8583 - r_val: 0.6019                                                                                                    \n",
      "epoch: 0025, loss: 0.0273 - val_loss: 0.0669; rmse: 0.1405 - rmse_val: 0.3262;  r2: 0.7467 - r2_val: 0.1505; mae: 0.1076 - mae_val: 0.2800;mse: 0.0197 - mse_val: 0.1064; r: 0.8675 - r_val: 0.6042                                                                                                    \n",
      "epoch: 0026, loss: 0.0268 - val_loss: 0.0785; rmse: 0.1456 - rmse_val: 0.3654;  r2: 0.7281 - r2_val: -0.0660; mae: 0.1122 - mae_val: 0.3124;mse: 0.0212 - mse_val: 0.1335; r: 0.8769 - r_val: 0.6000                                                                                                    \n",
      "epoch: 0027, loss: 0.0259 - val_loss: 0.0589; rmse: 0.1519 - rmse_val: 0.3039;  r2: 0.7040 - r2_val: 0.2625; mae: 0.1207 - mae_val: 0.2627;mse: 0.0231 - mse_val: 0.0924; r: 0.8849 - r_val: 0.5921                                                                                                    \n",
      "epoch: 0028, loss: 0.0243 - val_loss: 0.0614; rmse: 0.1459 - rmse_val: 0.3141;  r2: 0.7266 - r2_val: 0.2124; mae: 0.1169 - mae_val: 0.2710;mse: 0.0213 - mse_val: 0.0986; r: 0.8928 - r_val: 0.5800                                                                                                    \n",
      "epoch: 0029, loss: 0.0230 - val_loss: 0.0698; rmse: 0.1244 - rmse_val: 0.3429;  r2: 0.8014 - r2_val: 0.0611; mae: 0.0949 - mae_val: 0.2921;mse: 0.0155 - mse_val: 0.1176; r: 0.9036 - r_val: 0.5873                                                                                                    \n",
      "epoch: 0030, loss: 0.0218 - val_loss: 0.0684; rmse: 0.1181 - rmse_val: 0.3397;  r2: 0.8209 - r2_val: 0.0788; mae: 0.0898 - mae_val: 0.2882;mse: 0.0140 - mse_val: 0.1154; r: 0.9115 - r_val: 0.6061                                                                                                    \n",
      "epoch: 0031, loss: 0.0211 - val_loss: 0.0663; rmse: 0.1162 - rmse_val: 0.3344;  r2: 0.8266 - r2_val: 0.1070; mae: 0.0877 - mae_val: 0.2853;mse: 0.0135 - mse_val: 0.1118; r: 0.9160 - r_val: 0.5913                                                                                                    \n",
      "epoch: 0032, loss: 0.0206 - val_loss: 0.0663; rmse: 0.1163 - rmse_val: 0.3352;  r2: 0.8264 - r2_val: 0.1027; mae: 0.0894 - mae_val: 0.2854;mse: 0.0135 - mse_val: 0.1124; r: 0.9144 - r_val: 0.6239                                                                                                    \n",
      "epoch: 0033, loss: 0.0202 - val_loss: 0.0610; rmse: 0.1224 - rmse_val: 0.3189;  r2: 0.8077 - r2_val: 0.1882; mae: 0.0975 - mae_val: 0.2718;mse: 0.0150 - mse_val: 0.1017; r: 0.9242 - r_val: 0.6195                                                                                                    \n",
      "epoch: 0034, loss: 0.0200 - val_loss: 0.0511; rmse: 0.1746 - rmse_val: 0.2848;  r2: 0.6085 - r2_val: 0.3523; mae: 0.1502 - mae_val: 0.2428;mse: 0.0305 - mse_val: 0.0811; r: 0.9162 - r_val: 0.6250                                                                                                    \n",
      "epoch: 0035, loss: 0.0194 - val_loss: 0.0763; rmse: 0.1228 - rmse_val: 0.3677;  r2: 0.8066 - r2_val: -0.0797; mae: 0.0971 - mae_val: 0.3140;mse: 0.0151 - mse_val: 0.1352; r: 0.9311 - r_val: 0.5987                                                                                                    \n",
      "epoch: 0036, loss: 0.0188 - val_loss: 0.0626; rmse: 0.1010 - rmse_val: 0.3259;  r2: 0.8692 - r2_val: 0.1521; mae: 0.0752 - mae_val: 0.2776;mse: 0.0102 - mse_val: 0.1062; r: 0.9361 - r_val: 0.6107                                                                                                    \n",
      "epoch: 0037, loss: 0.0179 - val_loss: 0.0658; rmse: 0.1058 - rmse_val: 0.3374;  r2: 0.8565 - r2_val: 0.0913; mae: 0.0815 - mae_val: 0.2860;mse: 0.0112 - mse_val: 0.1138; r: 0.9363 - r_val: 0.6239                                                                                                    \n",
      "epoch: 0038, loss: 0.0175 - val_loss: 0.0532; rmse: 0.1130 - rmse_val: 0.2950;  r2: 0.8361 - r2_val: 0.3050; mae: 0.0907 - mae_val: 0.2512;mse: 0.0128 - mse_val: 0.0870; r: 0.9442 - r_val: 0.6380                                                                                                    \n",
      "epoch: 0039, loss: 0.0167 - val_loss: 0.0594; rmse: 0.0896 - rmse_val: 0.3169;  r2: 0.8969 - r2_val: 0.1980; mae: 0.0656 - mae_val: 0.2693;mse: 0.0080 - mse_val: 0.1004; r: 0.9497 - r_val: 0.6287                                                                                                    \n",
      "epoch: 0040, loss: 0.0165 - val_loss: 0.0607; rmse: 0.0937 - rmse_val: 0.3217;  r2: 0.8873 - r2_val: 0.1737; mae: 0.0714 - mae_val: 0.2744;mse: 0.0088 - mse_val: 0.1035; r: 0.9510 - r_val: 0.6052                                                                                                    \n",
      "epoch: 0041, loss: 0.0163 - val_loss: 0.0550; rmse: 0.0981 - rmse_val: 0.3028;  r2: 0.8765 - r2_val: 0.2680; mae: 0.0758 - mae_val: 0.2591;mse: 0.0096 - mse_val: 0.0917; r: 0.9520 - r_val: 0.6215                                                                                                    \n",
      "epoch: 0042, loss: 0.0154 - val_loss: 0.0605; rmse: 0.0840 - rmse_val: 0.3219;  r2: 0.9095 - r2_val: 0.1724; mae: 0.0605 - mae_val: 0.2742;mse: 0.0071 - mse_val: 0.1036; r: 0.9563 - r_val: 0.6391                                                                                                    \n",
      "epoch: 0043, loss: 0.0150 - val_loss: 0.0557; rmse: 0.0943 - rmse_val: 0.3065;  r2: 0.8860 - r2_val: 0.2498; mae: 0.0731 - mae_val: 0.2599;mse: 0.0089 - mse_val: 0.0940; r: 0.9522 - r_val: 0.6540                                                                                                    \n",
      "epoch: 0044, loss: 0.0147 - val_loss: 0.0597; rmse: 0.0804 - rmse_val: 0.3205;  r2: 0.9170 - r2_val: 0.1799; mae: 0.0583 - mae_val: 0.2723;mse: 0.0065 - mse_val: 0.1027; r: 0.9605 - r_val: 0.6251                                                                                                    \n",
      "epoch: 0045, loss: 0.0145 - val_loss: 0.0604; rmse: 0.0792 - rmse_val: 0.3233;  r2: 0.9194 - r2_val: 0.1652; mae: 0.0572 - mae_val: 0.2749;mse: 0.0063 - mse_val: 0.1046; r: 0.9620 - r_val: 0.6357                                                                                                    \n",
      "epoch: 0046, loss: 0.0150 - val_loss: 0.0618; rmse: 0.0793 - rmse_val: 0.3281;  r2: 0.9192 - r2_val: 0.1405; mae: 0.0578 - mae_val: 0.2781;mse: 0.0063 - mse_val: 0.1076; r: 0.9601 - r_val: 0.5965                                                                                                    \n",
      "epoch: 0047, loss: 0.0140 - val_loss: 0.0644; rmse: 0.0804 - rmse_val: 0.3368;  r2: 0.9170 - r2_val: 0.0942; mae: 0.0588 - mae_val: 0.2851;mse: 0.0065 - mse_val: 0.1134; r: 0.9615 - r_val: 0.6321                                                                                                    \n",
      "epoch: 0048, loss: 0.0140 - val_loss: 0.0604; rmse: 0.0758 - rmse_val: 0.3242;  r2: 0.9263 - r2_val: 0.1605; mae: 0.0545 - mae_val: 0.2763;mse: 0.0057 - mse_val: 0.1051; r: 0.9644 - r_val: 0.6361                                                                                                    \n",
      "epoch: 0049, loss: 0.0137 - val_loss: 0.0574; rmse: 0.0789 - rmse_val: 0.3146;  r2: 0.9201 - r2_val: 0.2098; mae: 0.0583 - mae_val: 0.2657;mse: 0.0062 - mse_val: 0.0990; r: 0.9611 - r_val: 0.6354                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "expt_name = 'expt-COV-KN'                                              #here\n",
    "Train_dir = '/raid/hly/PK-3[2018PLOS]/data/train_data-MID/class_1'   #here\n",
    "Test_dir = '/raid/hly/PK-3[2018PLOS]/data/PK-3_benchmark_data'\n",
    "\n",
    "Allele_ls = ['HLA-A_0206','HLA-A_1101','HLA-A_6802','HLA-A_3301']\n",
    "#'HLA-A_0201','HLA-B_0702','HLA-B_4403','HLA-B_5701','HLA-A_3002','HLA-B_5301','HLA-A_0203'\n",
    "\n",
    "for Allele in Allele_ls:\n",
    "    df_train = pd.read_csv(os.path.join(Train_dir,Allele)+'.csv')\n",
    "    df_test = pd.read_csv(os.path.join(Test_dir,Allele)+'.csv')  \n",
    "    \n",
    "    # 创建储存 Allele 结果的文件夹\n",
    "    res_class = '/raid/hly/PK-3[2018PLOS]/R3-res/'+ expt_name               \n",
    "    Allele_fold = os.path.join(res_class,Allele)\n",
    "\n",
    "    if not os.path.exists(Allele_fold) : \n",
    "        os.makedirs(Allele_fold)\n",
    "        os.makedirs(os.path.join(Allele_fold,'loss'))\n",
    "        os.makedirs(os.path.join(Allele_fold,'models'))\n",
    "        os.makedirs(os.path.join(Allele_fold,'results'))\n",
    "        # os.makedirs(os.path.join(Allele_fold,'fig-loss'))\n",
    "        # os.makedirs(os.path.join(Allele_fold,'fig-pfm'))\n",
    "        # os.makedirs(os.path.join(Allele_fold,'fig-pred_true')) \n",
    "\n",
    "    # 获得训练集和测试集的最大序列长度\n",
    "    train_max_seq_len = df_train['Description'].apply(len).max()\n",
    "    test_max_seq_len = df_test['Description'].apply(len).max()\n",
    "    max_seq_len = max(train_max_seq_len,test_max_seq_len)\n",
    "\n",
    "\n",
    "    # 生成 X_train + Y_train \n",
    "    X_train_name = os.path.join(Allele_fold, Allele+'_X_train_'+'.data')\n",
    "    if not os.path.exists(X_train_name) :\n",
    "        X_train = []\n",
    "        for seq in df_train['Description']:\n",
    "            X_train.append(get_3d_feat2(seq))\n",
    "        X_train = np.stack(X_train)\n",
    "        dump(X_train, X_train_name)\n",
    "    else:\n",
    "        X_train = load(X_train_name)\n",
    "    X_train = X_train.astype('float32')\n",
    "    Y_train = df_train['Normalized_QM'].values.reshape(-1, 1) \n",
    "   \n",
    "   # 生成 X_test + Y_test \n",
    "    X_test_name = os.path.join(Allele_fold, Allele+'_X_test_'+'.data')\n",
    "    if not os.path.exists(X_test_name) :\n",
    "        X_test = []\n",
    "        for seq in df_test['Description']:\n",
    "            X_test.append(get_3d_feat2(seq))\n",
    "        X_test = np.stack(X_test)\n",
    "        dump(X_test, X_test_name)\n",
    "    else:\n",
    "        X_test = load(X_test_name)\n",
    "    X_test = X_test.astype('float32')\n",
    "    Y_test = df_test['Normalized_QM'].values.reshape(-1, 1) \n",
    "\n",
    "    # 确定参数\n",
    "    inc = (1,3,5)\n",
    "    lr = 1e-4\n",
    "    if max_seq_len < 15:\n",
    "        ks_fir_ls = [(3,3,7),(5,5,9),(9,9,13)]\n",
    "    else:\n",
    "        ks_fir_ls = [(3,3,7),(9,9,13),(15,15,19)]\n",
    "        \n",
    "    kn_ls = [(48,32,64),(75,50,100)]   #后续改变第二层的kernel number  #,(75,50,100),(96,64,128)\n",
    "    lamda_ls = [1e-3,1e-6,1e-9]  \n",
    "    bs = 32\n",
    "   \n",
    "   #******************************************\n",
    "    # R2_ls = []\n",
    "    task_name = Allele + '_' + expt_name.split('-')[1]\n",
    "    \n",
    "    for kn in kn_ls:\n",
    "        kn_1,kn_2,kn_3 = kn[0],kn[1],kn[2]\n",
    "        for ks_fir in ks_fir_ls:\n",
    "            for lamda in lamda_ls:\n",
    "\n",
    "                # continue 情况\n",
    "                df_done = pd.read_csv('/raid/hly/PK-3[2018PLOS]/R3-res/done_list.csv')\n",
    "                exists_name = task_name + '_(lr_%s-bs_%s-lam_%s-ks_[%s,%s]-kn_%s)_' %(lr,bs,lamda,ks_fir,inc,kn)\n",
    "                if (exists_name +'_results.csv') in (df_done['done_file'].values):\n",
    "                    continue\n",
    "\n",
    "                for n in range(2):\n",
    "            \n",
    "                    print(exists_name)  \n",
    "\n",
    "                    # 查看目前最佳 R2\n",
    "                    result_file = os.path.join(Allele_fold,'results')\n",
    "                    result_csv = result_file + '/' + task_name + '_results.csv'\n",
    "                    if os.path.exists(result_csv) :\n",
    "                        df_exit_res = pd.read_csv(result_csv)\n",
    "                        best_exit_R2 = df_exit_res['valid_r2'][0]\n",
    "                    else:\n",
    "                        best_exit_R2 = [0]\n",
    "                        \n",
    "                    lr = lr\n",
    "                    patience = 50\n",
    "                    epochs = 600\n",
    "                    loss= tf.keras.losses.log_cosh     #weighted_loss #tf.keras.losses.mean_squared_error \n",
    "                    batch_size = bs\n",
    "\n",
    "                    df_loss = pd.DataFrame()          \n",
    "                    results = []\n",
    "\n",
    "\n",
    "                    model = tf.keras.Sequential([\n",
    "                    tf.keras.layers.Conv3D(kn_1, ks_fir, activation='relu', padding='same',kernel_regularizer=tf.keras.regularizers.l2(lamda),\n",
    "            bias_regularizer=tf.keras.regularizers.l1(lamda), activity_regularizer=tf.keras.regularizers.l2(lamda)),\n",
    "                    tf.keras.layers.MaxPool3D(), #pool_size = (2,2,2)\n",
    "                    #here\n",
    "                    tf.keras.layers.Conv3D(kn_1, (5,5,5), activation='relu', padding='same',kernel_regularizer=tf.keras.regularizers.l2(lamda),\n",
    "            bias_regularizer=tf.keras.regularizers.l1(lamda), activity_regularizer=tf.keras.regularizers.l2(lamda)),\n",
    "                    tf.keras.layers.MaxPool3D(), #pool_size = (2,2,2)\n",
    "                    #here\n",
    "                    Inception(units=kn_2, strides=1),\n",
    "                    tf.keras.layers.MaxPool3D(),\n",
    "                    Inception(units=kn_3, strides=1),\n",
    "                    tf.keras.layers.GlobalMaxPooling3D(),           #tf.keras.layers.Flatten(),\n",
    "                    tf.keras.layers.Dense(128, activation='relu'),\n",
    "                    tf.keras.layers.Dense(32, activation='relu'),\n",
    "                    tf.keras.layers.Dense(1)\n",
    "                    ])\n",
    "\n",
    "                    opt = tf.keras.optimizers.Adam(lr=lr)\n",
    "                    model.compile(optimizer=opt, loss=loss)\n",
    "\n",
    "                    performance = molmap.model.cbks.Reg3D_EarlyStoppingAndPerformance((X_train, Y_train), \n",
    "                                                                    (X_test, Y_test), \n",
    "                                                                patience = patience,\n",
    "                                                                )\n",
    "\n",
    "                    model.fit(X_train, Y_train, batch_size=batch_size, \n",
    "                            epochs = epochs, verbose = 0, shuffle = True, \n",
    "                            validation_data = (X_test, Y_test), callbacks = [performance]) \n",
    "\n",
    "\n",
    "                    best_epoch = performance.best_epoch\n",
    "                    trainable_params = model.count_params()\n",
    "\n",
    "                    #获取RMSE和R2\n",
    "                    train_rmse,train_mse,train_mae,train_r,train_r2 = performance.evaluate(X_train, Y_train)            \n",
    "                    test_rmse,test_mse,test_mae,test_r,test_r2 = performance.evaluate(X_test, Y_test)\n",
    "\n",
    "                    # R2_ls.append(test_r2)                \n",
    "\n",
    "                    if test_r2 >= best_exit_R2:\n",
    "\n",
    "                        #储存loss\n",
    "                        dfl = pd.DataFrame(performance.history)\n",
    "                        df_loss = df_loss.append(dfl, ignore_index = True)\n",
    "                        df_loss.to_csv(os.path.join(os.path.join(Allele_fold,'loss'),  task_name +'_loss.csv'))\n",
    "\n",
    "                        #整体性结果\n",
    "                        final_res = {\n",
    "                                        'train_rmse':np.nanmean(train_rmse), \n",
    "                                        'valid_rmse':np.nanmean(test_rmse),  \n",
    "                                        'train_mse':np.nanmean(train_mse), \n",
    "                                        'valid_mse':np.nanmean(test_mse),                      \n",
    "                                        'train_r2':np.nanmean(train_r2), \n",
    "                                        'valid_r2':np.nanmean(test_r2), \n",
    "                                        'train_mae':np.nanmean(train_mae), \n",
    "                                        'valid_mae':np.nanmean(test_mae),\n",
    "                                        'train_r':np.nanmean(train_r), \n",
    "                                        'valid_r':np.nanmean(test_r),\n",
    "                                        'trainable params': trainable_params, \n",
    "                                        'best_epoch': best_epoch,\n",
    "                                        'lr' : lr,\n",
    "                                        'batch_size':bs,\n",
    "                                        'kernel_size_1':ks_fir,\n",
    "                                        'kernel_size_incept': inc,\n",
    "                                        'kernel_number':kn,\n",
    "                                        'lamda' : lamda\n",
    "                                        }\n",
    "\n",
    "                        results.append(final_res)\n",
    "                        dfr = pd.DataFrame(results)\n",
    "                        dfr.to_csv(os.path.join(os.path.join(Allele_fold,'results'),  task_name +'_results.csv'))\n",
    "                        \n",
    "                        # 保存模型\n",
    "                        model.save(os.path.join(os.path.join(Allele_fold,'models'),  task_name +'_model_' +'.h5'))\n",
    "\n",
    "                        # make prediction\n",
    "                        Y_test_pred = model.predict(X_test)\n",
    "                        df_pred = pd.DataFrame(Y_test_pred.tolist()).rename(columns={0:'Pred_QM'})\n",
    "                        df_truepred = pd.merge(df_test,df_pred,how='inner',left_index=True,right_index=True)\n",
    "                        df_truepred.to_csv(os.path.join(Allele_fold,Allele+'true_pred.csv'))\n",
    "\n",
    "                        # # 保存 loss_fig\n",
    "                        # plt.plot(df_loss['loss'])\n",
    "                        # plt.plot(df_loss['val_loss'])\n",
    "                        # plt.savefig(os.path.join(os.path.join(Allele_fold,'fig-loss'),  task_name +'_lossfig.png'),bbox_inches='tight', dpi=300)\n",
    "                        \n",
    "                        # 删除model\n",
    "                        del model\n",
    "\n",
    "                    print('*******************************************************')\n",
    "\n",
    "                    # 删除缓存\n",
    "                    del performance\n",
    "                    gc.collect()\n",
    "                    K.clear_session()\n",
    "                    tf.compat.v1.reset_default_graph() # TF graph isn't same as Keras grap\n",
    "                    \n",
    "                df_done = pd.read_csv('/raid/hly/PK-3[2018PLOS]/R3-res/done_list.csv')   \n",
    "                new_donels = df_done['done_file'].append(pd.Series(exists_name +'_results.csv'))\n",
    "                df_newdone = pd.DataFrame(new_donels,columns=['done_file'])\n",
    "                df_newdone.to_csv('/raid/hly/PK-3[2018PLOS]/R3-res/done_list.csv')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 12, 12, 62, 96)    101184    \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 6, 6, 31, 96)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 6, 6, 31, 96)      1152096   \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 3, 3, 15, 96)      0         \n",
      "_________________________________________________________________\n",
      "inception (Inception)        (None, 3, 3, 15, 192)     940224    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 1, 1, 7, 192)      0         \n",
      "_________________________________________________________________\n",
      "inception_1 (Inception)      (None, 1, 1, 7, 384)      3760512   \n",
      "_________________________________________________________________\n",
      "global_max_pooling3d (Global (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               49280     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,007,457\n",
      "Trainable params: 6,007,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('vaccin': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "616f56fef8ea7183d51ad2039e0213a0ade719c1a48fd338f6185e7423826c67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
