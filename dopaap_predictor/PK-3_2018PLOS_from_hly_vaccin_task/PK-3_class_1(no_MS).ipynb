{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABICAYAAADI6S+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAACDElEQVR4nO3aP2pUURjG4e8ElWhs/BPstBIUFBQHtyK4gNmQnQtwCZItCFEbVyFRiKCVcGxsHNRhYI7vzPF5ulxu8X4EfsVlWu+9APj3DtIDAP5XAgwQIsAAIQIMECLAACECDBByYd0LrbVlVS2rqo4uHjy5d+3y8FEp368fpScM9eXKvP+785r3tqqq82+X0hOGOvy8NkV77evHd2e99+PV522T3wEvbl3tp88ebnXYLvn0/Gl6wlAnjx+lJwzzuu6nJwx18v52esJQd1/dSE8Y6s2Lw7e998Xqc58gAEIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggpPXe//5Ca8uqWv7880FVfRg9KuhmVZ2lRwwy821V7tt3s993p/d+vPpwbYB/ebm10977YquzdsjM9818W5X79t3s9/2JTxAAIQIMELJpgF8OWbE7Zr5v5tuq3LfvZr/vtzb6BgzA9vgEARAiwAAhAgwQIsAAIQIMEPID0IJRG96Z/ToAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import molmap.model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette(\"rainbow_r\", 6) #PiYG\n",
    "sns.palplot(color)\n",
    "\n",
    "from joblib import load, dump\n",
    "import sklearn.metrics\n",
    "import scipy\n",
    "import logging\n",
    "\n",
    "def r2_score(y_true,y_pred):\n",
    "    y_mean = np.mean(y_true)\n",
    "    r2 = 1-sum((y_true-y_pred)**2)/sum((y_mean-y_true)**2)\n",
    "    return r2\n",
    "def PCC(y_pred,y_true):\n",
    "    diff_pred,diff_true=y_pred-np.mean(y_pred),y_true-np.mean(y_true)\n",
    "    return np.sum(diff_pred*diff_true)/np.sqrt(np.sum(diff_pred**2)*np.sum(diff_true**2))\n",
    "\n",
    "def from_ic50(ic50, max_ic50=50000.0):\n",
    "    x = 1.0 - (np.log(np.maximum(ic50, 1e-12)) / np.log(max_ic50))\n",
    "    return np.minimum(\n",
    "        1.0,\n",
    "        np.maximum(0.0, x))\n",
    "def to_ic50(x, max_ic50=50000.0):\n",
    "    return max_ic50 ** (1.0 - x)\n",
    "sample_weight=None,\n",
    "threshold_nm=500,\n",
    "max_ic50=50000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取 blosum62 matrix + pam250 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blosum62 = pd.read_csv('/raid/hly/NEW METHOD EXPT/blosum&pam/data/BLOSUM62.txt', sep='\\s')\n",
    "blosum62 = blosum62.iloc[:-4,:-4]\n",
    "\n",
    "pam250 = pd.read_csv('/raid/hly/NEW METHOD EXPT/blosum&pam/data/PAM250.csv',index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将 blosum62 matrix 以及 pam250 mutation matrix 标准化到 0~1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aapro归一化\n",
    "PCP = pd.read_csv('/raid/hly/vaccin/data/cal_CTD/PCP_61.csv', index_col='properties').index\n",
    "AApro_dic = pd.read_csv('/raid/hly/umap/single_index/AApro_UMAP.csv', header=0,index_col=0)\n",
    "AA_pro = AApro_dic.loc[PCP].astype('float')\n",
    "AA_pro = AA_pro.T\n",
    "AA_pro = ((AA_pro - AA_pro.min()) / (AA_pro.max() - AA_pro.min())).T #归一化"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "序列相关 aapro,blosum62,pam250 距离矩阵的生成与拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3d_feat(seq):\n",
    "    n = len(seq)\n",
    "\n",
    "    # 生成理化性质矩阵\n",
    "    seq_pro = pd.DataFrame(AA_pro[aa] for aa in seq).T\n",
    "    seq_pro = seq_pro.values[:, :, None]  #二维变成三维（61， n， 1）\n",
    "    ## 相乘\n",
    "    mt_pro = np.transpose((seq_pro * np.transpose(seq_pro, [0, 2, 1])), [1, 2, 0])  #**.5   #here!! **0.25\n",
    "    ## transpose三维转置。（61，n，1）*（61，1，n）=（61，n，n），再转置成（n，n，61）.\n",
    "\n",
    "    # 生成blosum矩阵\n",
    "    seq_blosum = np.ones((n,n))\n",
    "    for i in range(n):\n",
    "        a = seq[i]\n",
    "        for j in range(n):\n",
    "            b = seq[j]\n",
    "            seq_blosum[i][j] = blosum62.loc[a,b]\n",
    "    seq_blosum_nor = ((seq_blosum - seq_blosum.min()) / (seq_blosum.max() - seq_blosum.min()))\n",
    "    seq_blosum_nor = seq_blosum_nor[:, :, np.newaxis]  ##（n，n，1）\n",
    "\n",
    "    # 生成pam矩阵\n",
    "    seq_pam = np.ones((n,n))\n",
    "    for i in range(n):\n",
    "        a = seq[i]\n",
    "        for j in range(n):\n",
    "            b = seq[j]\n",
    "            seq_pam[i][j] = pam250.loc[a,b]\n",
    "    seq_pam_nor = ((seq_pam - seq_pam.min()) / (seq_pam.max() - seq_pam.min()))\n",
    "    seq_pam_nor = seq_pam_nor[:, :, np.newaxis]  ##（n，n，1）\n",
    "\n",
    "    # 生成序列距离矩阵\n",
    "    pt_dis = np.ones((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            pt_dis[i][j] = abs(i-j)\n",
    "    pt_dis = ((pt_dis - 0) / (n-1 - 0)) ## 归一化（最小值为0，最大值为n-1）\n",
    "    pt_dis = pt_dis[:, :, np.newaxis]  ##（n，n，1）\n",
    "\n",
    "    # 改变 理化性质矩阵 的下半部分\n",
    "    for k in range(mt_pro.shape[2]):\n",
    "        for i in range(n):\n",
    "            for j in range(i):\n",
    "                if k < 60:                                      ##here\n",
    "                    mt_pro[i,j,k] = (mt_pro[j,i,k] * mt_pro[j,i,k+1])**.5\n",
    "                else:\n",
    "                    mt_pro[i,j,k] = (mt_pro[j,i,k] * mt_pro[j,i,0])**.5\n",
    "\n",
    "    # 将序列距离矩阵与mt合并，并放在第一层\n",
    "    mt = np.concatenate((pt_dis,seq_blosum_nor,seq_pam_nor,mt_pro),axis = 2)\n",
    "\n",
    "    x = np.pad(mt, [(0, max_seq_len-n), (0, max_seq_len-n), (0, 0)]) #填充0.令数据集中每条序列对应的Xshape相同。\n",
    "\n",
    "    return x[ :, :, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units = 8, strides = 1):\n",
    "        super(Inception, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv3D(units, (1,1,1), padding='same', activation = 'relu', strides = strides,kernel_regularizer=tf.keras.regularizers.l2(lamda),\n",
    "  bias_regularizer=tf.keras.regularizers.l1(lamda), activity_regularizer=tf.keras.regularizers.l2(lamda))\n",
    "        self.conv2 = tf.keras.layers.Conv3D(units, (3,3,3), padding='same', activation = 'relu', strides = strides,kernel_regularizer=tf.keras.regularizers.l2(lamda),\n",
    "  bias_regularizer=tf.keras.regularizers.l1(lamda), activity_regularizer=tf.keras.regularizers.l2(lamda))\n",
    "        self.conv3 = tf.keras.layers.Conv3D(units, (5,5,5), padding='same', activation = 'relu', strides = strides,kernel_regularizer=tf.keras.regularizers.l2(lamda),\n",
    "  bias_regularizer=tf.keras.regularizers.l1(lamda), activity_regularizer=tf.keras.regularizers.l2(lamda))\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x1 = self.conv1(inputs)\n",
    "        x2 = self.conv2(inputs)\n",
    "        x3 = self.conv3(inputs)\n",
    "        outputs = self.concat([x1, x2, x3])\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self): \n",
    "        config = {\"conv1\": self.conv1,\"conv2\":self.conv2,'conv3':self.conv3}\n",
    "        base_config = super(Inception, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_1(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.Cov_1 = tf.keras.layers.Conv3D(kn_1, ks_fir, activation='relu', padding='same',kernel_regularizer=tf.keras.regularizers.l2(lamda),\n",
    "    bias_regularizer=tf.keras.regularizers.l1(lamda), activity_regularizer=tf.keras.regularizers.l2(lamda))\n",
    "            self.MaxPool_1 = tf.keras.layers.MaxPool3D() #pool_size = (2,2,2)\n",
    "    #         #here\n",
    "    #         tf.keras.layers.Conv3D(kn_1, (5,5,5), activation='relu', padding='same',kernel_regularizer=tf.keras.regularizers.l2(lamda),\n",
    "    # bias_regularizer=tf.keras.regularizers.l1(lamda), activity_regularizer=tf.keras.regularizers.l2(lamda)),\n",
    "    #         tf.keras.layers.MaxPool3D(), #pool_size = (2,2,2)\n",
    "    #         #here\n",
    "            self.Cov_2 =Inception(units=kn_2, strides=1)\n",
    "            self.MaxPool_2 = tf.keras.layers.MaxPool3D()\n",
    "            self.Cov_3 = Inception(units=kn_3, strides=1)\n",
    "            self.GlobalMaxPool = tf.keras.layers.GlobalMaxPooling3D()         #tf.keras.layers.Flatten(),\n",
    "            self.Dense_1 = tf.keras.layers.Dense(128, activation='relu')\n",
    "            self.Dense_2 =tf.keras.layers.Dense(32, activation='relu')\n",
    "            self.Dense_3 =tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, input):\n",
    "            x = self.Cov_1(input)\n",
    "            x = self.MaxPool_1(x)\n",
    "            x = self.Cov_2(x) \n",
    "            x = self.MaxPool_2(x)\n",
    "            x = self.Cov_3(x)\n",
    "            x = self.GlobalMaxPool(x)\n",
    "            x = self.Dense_1(x)\n",
    "            x = self.Dense_2(x)\n",
    "            x = self.Dense_3(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_2(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.Cov_1 = tf.keras.layers.Conv3D(kn_1, ks_fir, activation='relu', padding='same',kernel_regularizer=tf.keras.regularizers.l2(lamda),\n",
    "    bias_regularizer=tf.keras.regularizers.l1(lamda), activity_regularizer=tf.keras.regularizers.l2(lamda))\n",
    "            self.MaxPool_1 = tf.keras.layers.MaxPool3D() #pool_size = (2,2,2)\n",
    "            #here\n",
    "            self.Cov_2 = tf.keras.layers.Conv3D(kn_1, (5,5,5), activation='relu', padding='same',kernel_regularizer=tf.keras.regularizers.l2(lamda),\n",
    "    bias_regularizer=tf.keras.regularizers.l1(lamda), activity_regularizer=tf.keras.regularizers.l2(lamda))\n",
    "            self.MaxPool_2 = tf.keras.layers.MaxPool3D() #pool_size = (2,2,2)\n",
    "            #here\n",
    "            self.Cov_3 =Inception(units=kn_2, strides=1)\n",
    "            self.MaxPool_3 = tf.keras.layers.MaxPool3D()\n",
    "            self.Cov_4 = Inception(units=kn_3, strides=1)\n",
    "            self.GlobalMaxPool = tf.keras.layers.GlobalMaxPooling3D()         #tf.keras.layers.Flatten(),\n",
    "            self.Dense_1 = tf.keras.layers.Dense(128, activation='relu')\n",
    "            self.Dense_2 =tf.keras.layers.Dense(32, activation='relu')\n",
    "            self.Dense_3 =tf.keras.layers.Dense(1)\n",
    "            \n",
    "    \n",
    "    def call(self, input):\n",
    "            x = self.Cov_1(input)\n",
    "            x = self.MaxPool_1(x)\n",
    "            #here\n",
    "            x = self.Cov_2(x)\n",
    "            x = self.MaxPool_2(x)\n",
    "            #here\n",
    "            x = self.Cov_3(x) \n",
    "            x = self.MaxPool_3(x)\n",
    "            x = self.Cov_4(x)\n",
    "            x = self.GlobalMaxPool(x)\n",
    "            x = self.Dense_1(x)\n",
    "            x = self.Dense_2(x)\n",
    "            x = self.Dense_3(x)\n",
    "            return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从MHCflurry训练验证集提取出可使用的数据集。allele['HLA-B_2704','HLA-B_2706','HLA-B_3801']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 0034, loss: 0.0009 - val_loss: 0.0097; rmse: 0.0247 - rmse_val: 0.1365;  r2: 0.9886 - r2_val: 0.6524; mae: 0.0167 - mae_val: 0.0962; r: 0.9956 - r_val: 0.8185;tau: 0.8424 - tau_val: 0.5816                                                                                                    \n",
      " epoch: 0035, loss: 0.0008 - val_loss: 0.0099; rmse: 0.0249 - rmse_val: 0.1387;  r2: 0.9884 - r2_val: 0.6408; mae: 0.0168 - mae_val: 0.0966; r: 0.9947 - r_val: 0.8065;tau: 0.8411 - tau_val: 0.5820                                                                                                    \n",
      " epoch: 0036, loss: 0.0008 - val_loss: 0.0098; rmse: 0.0265 - rmse_val: 0.1377;  r2: 0.9869 - r2_val: 0.6462; mae: 0.0173 - mae_val: 0.0960; r: 0.9935 - r_val: 0.8106;tau: 0.8341 - tau_val: 0.5817                                                                                                    \n",
      " epoch: 0037, loss: 0.0008 - val_loss: 0.0095; rmse: 0.0251 - rmse_val: 0.1352;  r2: 0.9882 - r2_val: 0.6591; mae: 0.0173 - mae_val: 0.0957; r: 0.9949 - r_val: 0.8178;tau: 0.8356 - tau_val: 0.5889                                                                                                    \n",
      " epoch: 0038, loss: 0.0008 - val_loss: 0.0097; rmse: 0.0400 - rmse_val: 0.1372;  r2: 0.9701 - r2_val: 0.6487; mae: 0.0276 - mae_val: 0.0983; r: 0.9908 - r_val: 0.8195;tau: 0.8245 - tau_val: 0.5847                                                                                                    \n",
      " epoch: 0039, loss: 0.0010 - val_loss: 0.0099; rmse: 0.0305 - rmse_val: 0.1386;  r2: 0.9827 - r2_val: 0.6416; mae: 0.0212 - mae_val: 0.0962; r: 0.9935 - r_val: 0.8093;tau: 0.8302 - tau_val: 0.5793                                                                                                    \n",
      " epoch: 0040, loss: 0.0009 - val_loss: 0.0091; rmse: 0.0264 - rmse_val: 0.1324;  r2: 0.9870 - r2_val: 0.6729; mae: 0.0177 - mae_val: 0.0917; r: 0.9938 - r_val: 0.8245;tau: 0.8357 - tau_val: 0.5865                                                                                                    \n",
      " epoch: 0041, loss: 0.0010 - val_loss: 0.0095; rmse: 0.0329 - rmse_val: 0.1358;  r2: 0.9799 - r2_val: 0.6557; mae: 0.0229 - mae_val: 0.0945; r: 0.9924 - r_val: 0.8187;tau: 0.8294 - tau_val: 0.5870                                                                                                    \n",
      " epoch: 0042, loss: 0.0010 - val_loss: 0.0090; rmse: 0.0277 - rmse_val: 0.1320;  r2: 0.9857 - r2_val: 0.6750; mae: 0.0184 - mae_val: 0.0908; r: 0.9931 - r_val: 0.8272;tau: 0.8347 - tau_val: 0.5899                                                                                                    \n",
      " epoch: 0043, loss: 0.0009 - val_loss: 0.0097; rmse: 0.0288 - rmse_val: 0.1368;  r2: 0.9845 - r2_val: 0.6505; mae: 0.0194 - mae_val: 0.0964; r: 0.9924 - r_val: 0.8109;tau: 0.8313 - tau_val: 0.5821                                                                                                    \n",
      " epoch: 0044, loss: 0.0012 - val_loss: 0.0094; rmse: 0.0318 - rmse_val: 0.1343;  r2: 0.9811 - r2_val: 0.6635; mae: 0.0221 - mae_val: 0.0950; r: 0.9919 - r_val: 0.8256;tau: 0.8231 - tau_val: 0.5907                                                                                                    \n",
      " epoch: 0045, loss: 0.0013 - val_loss: 0.0095; rmse: 0.0298 - rmse_val: 0.1350;  r2: 0.9834 - r2_val: 0.6597; mae: 0.0202 - mae_val: 0.0939; r: 0.9920 - r_val: 0.8201;tau: 0.8251 - tau_val: 0.5959                                                                                                    \n",
      " epoch: 0046, loss: 0.0009 - val_loss: 0.0095; rmse: 0.0265 - rmse_val: 0.1353;  r2: 0.9869 - r2_val: 0.6582; mae: 0.0181 - mae_val: 0.0959; r: 0.9936 - r_val: 0.8185;tau: 0.8324 - tau_val: 0.5837                                                                                                    \n",
      " epoch: 0047, loss: 0.0009 - val_loss: 0.0098; rmse: 0.0361 - rmse_val: 0.1378;  r2: 0.9757 - r2_val: 0.6457; mae: 0.0249 - mae_val: 0.0955; r: 0.9937 - r_val: 0.8138;tau: 0.8356 - tau_val: 0.5841                                                                                                    \n",
      " epoch: 0048, loss: 0.0009 - val_loss: 0.0098; rmse: 0.0260 - rmse_val: 0.1380;  r2: 0.9874 - r2_val: 0.6446; mae: 0.0176 - mae_val: 0.0965; r: 0.9943 - r_val: 0.8120;tau: 0.8375 - tau_val: 0.5862                                                                                                    \n",
      " epoch: 0049, loss: 0.0008 - val_loss: 0.0095; rmse: 0.0318 - rmse_val: 0.1361;  r2: 0.9811 - r2_val: 0.6545; mae: 0.0215 - mae_val: 0.0933; r: 0.9948 - r_val: 0.8159;tau: 0.8392 - tau_val: 0.5880                                                                                                    \n",
      " epoch: 0050, loss: 0.0008 - val_loss: 0.0098; rmse: 0.0336 - rmse_val: 0.1378;  r2: 0.9790 - r2_val: 0.6458; mae: 0.0226 - mae_val: 0.0967; r: 0.9943 - r_val: 0.8092;tau: 0.8385 - tau_val: 0.5731                                                                                                    \n",
      " epoch: 0051, loss: 0.0008 - val_loss: 0.0092; rmse: 0.0255 - rmse_val: 0.1333;  r2: 0.9879 - r2_val: 0.6685; mae: 0.0171 - mae_val: 0.0938; r: 0.9939 - r_val: 0.8210;tau: 0.8358 - tau_val: 0.5851                                                                                                    \n",
      " epoch: 0052, loss: 0.0008 - val_loss: 0.0101; rmse: 0.0276 - rmse_val: 0.1401;  r2: 0.9858 - r2_val: 0.6336; mae: 0.0182 - mae_val: 0.0981; r: 0.9932 - r_val: 0.8040;tau: 0.8344 - tau_val: 0.5725                                                                                                    \n",
      " epoch: 0053, loss: 0.0008 - val_loss: 0.0099; rmse: 0.0293 - rmse_val: 0.1390;  r2: 0.9840 - r2_val: 0.6395; mae: 0.0189 - mae_val: 0.0979; r: 0.9923 - r_val: 0.8055;tau: 0.8304 - tau_val: 0.5703                                                                                                    \n",
      " epoch: 0054, loss: 0.0009 - val_loss: 0.0101; rmse: 0.0344 - rmse_val: 0.1401;  r2: 0.9780 - r2_val: 0.6337; mae: 0.0218 - mae_val: 0.0979; r: 0.9939 - r_val: 0.8116;tau: 0.8329 - tau_val: 0.5779                                                                                                    \n",
      " epoch: 0055, loss: 0.0009 - val_loss: 0.0098; rmse: 0.0419 - rmse_val: 0.1380;  r2: 0.9673 - r2_val: 0.6443; mae: 0.0319 - mae_val: 0.1013; r: 0.9925 - r_val: 0.8186;tau: 0.8248 - tau_val: 0.5883                                                                                                    \n",
      " epoch: 0056, loss: 0.0009 - val_loss: 0.0095; rmse: 0.0314 - rmse_val: 0.1361;  r2: 0.9816 - r2_val: 0.6541; mae: 0.0249 - mae_val: 0.0983; r: 0.9939 - r_val: 0.8150;tau: 0.8311 - tau_val: 0.5863                                                                                                    \n",
      " epoch: 0057, loss: 0.0010 - val_loss: 0.0101; rmse: 0.0348 - rmse_val: 0.1401;  r2: 0.9774 - r2_val: 0.6338; mae: 0.0228 - mae_val: 0.0968; r: 0.9932 - r_val: 0.8144;tau: 0.8331 - tau_val: 0.5768                                                                                                    \n",
      " epoch: 0058, loss: 0.0010 - val_loss: 0.0095; rmse: 0.0286 - rmse_val: 0.1355;  r2: 0.9848 - r2_val: 0.6573; mae: 0.0188 - mae_val: 0.0952; r: 0.9927 - r_val: 0.8173;tau: 0.8370 - tau_val: 0.5829                                                                                                    \n",
      " epoch: 0059, loss: 0.0008 - val_loss: 0.0093; rmse: 0.0233 - rmse_val: 0.1340;  r2: 0.9899 - r2_val: 0.6650; mae: 0.0167 - mae_val: 0.0943; r: 0.9959 - r_val: 0.8204;tau: 0.8439 - tau_val: 0.5843                                                                                                    \n",
      " epoch: 0060, loss: 0.0008 - val_loss: 0.0095; rmse: 0.0229 - rmse_val: 0.1356;  r2: 0.9903 - r2_val: 0.6567; mae: 0.0150 - mae_val: 0.0946; r: 0.9955 - r_val: 0.8166;tau: 0.8417 - tau_val: 0.5794                                                                                                    \n",
      " epoch: 0061, loss: 0.0007 - val_loss: 0.0096; rmse: 0.0235 - rmse_val: 0.1367;  r2: 0.9897 - r2_val: 0.6512; mae: 0.0154 - mae_val: 0.0948; r: 0.9949 - r_val: 0.8140;tau: 0.8396 - tau_val: 0.5863                                                                                                    \n",
      " epoch: 0062, loss: 0.0007 - val_loss: 0.0097; rmse: 0.0286 - rmse_val: 0.1372;  r2: 0.9848 - r2_val: 0.6488; mae: 0.0189 - mae_val: 0.0959; r: 0.9936 - r_val: 0.8144;tau: 0.8352 - tau_val: 0.5774                                                                                                    \n",
      " epoch: 0063, loss: 0.0007 - val_loss: 0.0097; rmse: 0.0332 - rmse_val: 0.1374;  r2: 0.9795 - r2_val: 0.6477; mae: 0.0222 - mae_val: 0.0933; r: 0.9955 - r_val: 0.8137;tau: 0.8422 - tau_val: 0.5811                                                                                                    \n",
      " epoch: 0064, loss: 0.0008 - val_loss: 0.0103; rmse: 0.0285 - rmse_val: 0.1415;  r2: 0.9849 - r2_val: 0.6265; mae: 0.0190 - mae_val: 0.0996; r: 0.9943 - r_val: 0.8036;tau: 0.8356 - tau_val: 0.5707                                                                                                    \n",
      " epoch: 0065, loss: 0.0008 - val_loss: 0.0093; rmse: 0.0236 - rmse_val: 0.1344;  r2: 0.9896 - r2_val: 0.6628; mae: 0.0168 - mae_val: 0.0924; r: 0.9956 - r_val: 0.8227;tau: 0.8421 - tau_val: 0.5937                                                                                                    \n",
      " epoch: 0066, loss: 0.0007 - val_loss: 0.0098; rmse: 0.0250 - rmse_val: 0.1379;  r2: 0.9884 - r2_val: 0.6452; mae: 0.0183 - mae_val: 0.0992; r: 0.9960 - r_val: 0.8117;tau: 0.8410 - tau_val: 0.5778                                                                                                    \n",
      " epoch: 0067, loss: 0.0007 - val_loss: 0.0095; rmse: 0.0216 - rmse_val: 0.1359;  r2: 0.9913 - r2_val: 0.6553; mae: 0.0150 - mae_val: 0.0944; r: 0.9960 - r_val: 0.8138;tau: 0.8410 - tau_val: 0.5824                                                                                                    \n",
      " epoch: 0068, loss: 0.0007 - val_loss: 0.0096; rmse: 0.0319 - rmse_val: 0.1369;  r2: 0.9810 - r2_val: 0.6502; mae: 0.0206 - mae_val: 0.0965; r: 0.9945 - r_val: 0.8192;tau: 0.8352 - tau_val: 0.5883                                                                                                    \n",
      " epoch: 0069, loss: 0.0008 - val_loss: 0.0091; rmse: 0.0228 - rmse_val: 0.1332;  r2: 0.9903 - r2_val: 0.6691; mae: 0.0149 - mae_val: 0.0927; r: 0.9952 - r_val: 0.8213;tau: 0.8369 - tau_val: 0.5920                                                                                                    \n",
      " epoch: 0070, loss: 0.0007 - val_loss: 0.0097; rmse: 0.0242 - rmse_val: 0.1372;  r2: 0.9891 - r2_val: 0.6484; mae: 0.0162 - mae_val: 0.0939; r: 0.9949 - r_val: 0.8131;tau: 0.8416 - tau_val: 0.5863                                                                                                    \n",
      " epoch: 0071, loss: 0.0007 - val_loss: 0.0097; rmse: 0.0238 - rmse_val: 0.1375;  r2: 0.9894 - r2_val: 0.6473; mae: 0.0180 - mae_val: 0.0980; r: 0.9961 - r_val: 0.8108;tau: 0.8428 - tau_val: 0.5819                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00071: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "WARNING:root:Found input variables with inconsistent numbers of samples: [188, 188, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************\n",
      "HLA-B_5301_(lr_0.0001-bs_32-lam_1e-06-ks_[(9, 9, 13),(1, 3, 5)]-kn_(96, 64, 128))_\n",
      " epoch: 0001, loss: 0.0393 - val_loss: 0.0340; rmse: 0.2596 - rmse_val: 0.2582;  r2: -0.0361 - r2_val: -0.0358; mae: 0.2226 - mae_val: 0.2144; r: 0.1671 - r_val: 0.1502;tau: 0.1126 - tau_val: 0.1064                                                                                                    \n",
      " epoch: 0002, loss: 0.0331 - val_loss: 0.0316; rmse: 0.2498 - rmse_val: 0.2516;  r2: 0.0401 - r2_val: 0.0160; mae: 0.2017 - mae_val: 0.1991; r: 0.4288 - r_val: 0.4241;tau: 0.2756 - tau_val: 0.2798                                                                                                    \n",
      " epoch: 0003, loss: 0.0300 - val_loss: 0.0278; rmse: 0.2354 - rmse_val: 0.2337;  r2: 0.1483 - r2_val: 0.1513; mae: 0.1995 - mae_val: 0.1930; r: 0.5044 - r_val: 0.5006;tau: 0.3332 - tau_val: 0.3302                                                                                                    \n",
      " epoch: 0004, loss: 0.0258 - val_loss: 0.0251; rmse: 0.2159 - rmse_val: 0.2224;  r2: 0.2835 - r2_val: 0.2316; mae: 0.1759 - mae_val: 0.1775; r: 0.5962 - r_val: 0.5718;tau: 0.4068 - tau_val: 0.3957                                                                                                    \n",
      " epoch: 0005, loss: 0.0230 - val_loss: 0.0255; rmse: 0.2099 - rmse_val: 0.2247;  r2: 0.3224 - r2_val: 0.2154; mae: 0.1657 - mae_val: 0.1739; r: 0.6746 - r_val: 0.6336;tau: 0.4753 - tau_val: 0.4462                                                                                                    \n",
      " epoch: 0006, loss: 0.0206 - val_loss: 0.0197; rmse: 0.1841 - rmse_val: 0.1957;  r2: 0.4787 - r2_val: 0.4047; mae: 0.1480 - mae_val: 0.1550; r: 0.7258 - r_val: 0.7047;tau: 0.5194 - tau_val: 0.5166                                                                                                    \n",
      " epoch: 0007, loss: 0.0172 - val_loss: 0.0163; rmse: 0.1713 - rmse_val: 0.1760;  r2: 0.5489 - r2_val: 0.5188; mae: 0.1378 - mae_val: 0.1414; r: 0.7619 - r_val: 0.7387;tau: 0.5526 - tau_val: 0.5572                                                                                                    \n",
      " epoch: 0008, loss: 0.0169 - val_loss: 0.0178; rmse: 0.1653 - rmse_val: 0.1853;  r2: 0.5801 - r2_val: 0.4663; mae: 0.1289 - mae_val: 0.1427; r: 0.7913 - r_val: 0.7517;tau: 0.5798 - tau_val: 0.5549                                                                                                    \n",
      " epoch: 0009, loss: 0.0143 - val_loss: 0.0161; rmse: 0.1636 - rmse_val: 0.1756;  r2: 0.5884 - r2_val: 0.5209; mae: 0.1322 - mae_val: 0.1421; r: 0.8125 - r_val: 0.7491;tau: 0.6057 - tau_val: 0.5459                                                                                                    \n",
      " epoch: 0010, loss: 0.0132 - val_loss: 0.0145; rmse: 0.1472 - rmse_val: 0.1657;  r2: 0.6667 - r2_val: 0.5731; mae: 0.1171 - mae_val: 0.1305; r: 0.8399 - r_val: 0.7674;tau: 0.6303 - tau_val: 0.5601                                                                                                    \n",
      " epoch: 0011, loss: 0.0119 - val_loss: 0.0150; rmse: 0.1349 - rmse_val: 0.1696;  r2: 0.7201 - r2_val: 0.5529; mae: 0.1039 - mae_val: 0.1283; r: 0.8691 - r_val: 0.7928;tau: 0.6630 - tau_val: 0.5848                                                                                                    \n",
      " epoch: 0012, loss: 0.0108 - val_loss: 0.0136; rmse: 0.1201 - rmse_val: 0.1608;  r2: 0.7782 - r2_val: 0.5980; mae: 0.0947 - mae_val: 0.1263; r: 0.8913 - r_val: 0.7870;tau: 0.6926 - tau_val: 0.5807                                                                                                    \n",
      " epoch: 0013, loss: 0.0087 - val_loss: 0.0129; rmse: 0.1060 - rmse_val: 0.1560;  r2: 0.8271 - r2_val: 0.6216; mae: 0.0830 - mae_val: 0.1175; r: 0.9125 - r_val: 0.7914;tau: 0.7224 - tau_val: 0.5819                                                                                                    \n",
      " epoch: 0014, loss: 0.0070 - val_loss: 0.0131; rmse: 0.1076 - rmse_val: 0.1578;  r2: 0.8221 - r2_val: 0.6132; mae: 0.0875 - mae_val: 0.1216; r: 0.9339 - r_val: 0.7983;tau: 0.7585 - tau_val: 0.5853                                                                                                    \n",
      " epoch: 0015, loss: 0.0057 - val_loss: 0.0123; rmse: 0.0871 - rmse_val: 0.1525;  r2: 0.8833 - r2_val: 0.6385; mae: 0.0692 - mae_val: 0.1139; r: 0.9493 - r_val: 0.8026;tau: 0.7863 - tau_val: 0.5856                                                                                                    \n",
      " epoch: 0016, loss: 0.0046 - val_loss: 0.0145; rmse: 0.0806 - rmse_val: 0.1670;  r2: 0.9000 - r2_val: 0.5668; mae: 0.0619 - mae_val: 0.1259; r: 0.9620 - r_val: 0.7832;tau: 0.8215 - tau_val: 0.5752                                                                                                    \n",
      " epoch: 0017, loss: 0.0041 - val_loss: 0.0154; rmse: 0.0863 - rmse_val: 0.1723;  r2: 0.8854 - r2_val: 0.5386; mae: 0.0684 - mae_val: 0.1313; r: 0.9705 - r_val: 0.7920;tau: 0.8448 - tau_val: 0.5665                                                                                                    \n",
      " epoch: 0018, loss: 0.0042 - val_loss: 0.0129; rmse: 0.0637 - rmse_val: 0.1568;  r2: 0.9375 - r2_val: 0.6179; mae: 0.0502 - mae_val: 0.1185; r: 0.9715 - r_val: 0.7921;tau: 0.8469 - tau_val: 0.5795                                                                                                    \n",
      " epoch: 0019, loss: 0.0028 - val_loss: 0.0130; rmse: 0.0483 - rmse_val: 0.1576;  r2: 0.9641 - r2_val: 0.6141; mae: 0.0376 - mae_val: 0.1173; r: 0.9823 - r_val: 0.7851;tau: 0.8770 - tau_val: 0.5706                                                                                                    \n",
      " epoch: 0020, loss: 0.0027 - val_loss: 0.0128; rmse: 0.0453 - rmse_val: 0.1564;  r2: 0.9684 - r2_val: 0.6200; mae: 0.0345 - mae_val: 0.1178; r: 0.9861 - r_val: 0.7944;tau: 0.8949 - tau_val: 0.5732                                                                                                    \n",
      " epoch: 0021, loss: 0.0024 - val_loss: 0.0139; rmse: 0.0619 - rmse_val: 0.1636;  r2: 0.9410 - r2_val: 0.5843; mae: 0.0489 - mae_val: 0.1209; r: 0.9840 - r_val: 0.7923;tau: 0.8933 - tau_val: 0.5764                                                                                                    \n",
      " epoch: 0022, loss: 0.0020 - val_loss: 0.0129; rmse: 0.0550 - rmse_val: 0.1570;  r2: 0.9534 - r2_val: 0.6168; mae: 0.0455 - mae_val: 0.1208; r: 0.9885 - r_val: 0.7948;tau: 0.9003 - tau_val: 0.5795                                                                                                    \n",
      " epoch: 0023, loss: 0.0021 - val_loss: 0.0130; rmse: 0.0421 - rmse_val: 0.1580;  r2: 0.9728 - r2_val: 0.6119; mae: 0.0322 - mae_val: 0.1182; r: 0.9873 - r_val: 0.7825;tau: 0.9015 - tau_val: 0.5648                                                                                                    \n",
      " epoch: 0024, loss: 0.0017 - val_loss: 0.0144; rmse: 0.0490 - rmse_val: 0.1669;  r2: 0.9631 - r2_val: 0.5669; mae: 0.0384 - mae_val: 0.1246; r: 0.9907 - r_val: 0.7753;tau: 0.9164 - tau_val: 0.5587                                                                                                    \n",
      " epoch: 0025, loss: 0.0016 - val_loss: 0.0125; rmse: 0.0310 - rmse_val: 0.1549;  r2: 0.9852 - r2_val: 0.6269; mae: 0.0231 - mae_val: 0.1159; r: 0.9928 - r_val: 0.7937;tau: 0.9252 - tau_val: 0.5816                                                                                                    \n",
      " epoch: 0026, loss: 0.0013 - val_loss: 0.0127; rmse: 0.0261 - rmse_val: 0.1562;  r2: 0.9895 - r2_val: 0.6211; mae: 0.0195 - mae_val: 0.1174; r: 0.9951 - r_val: 0.7891;tau: 0.9404 - tau_val: 0.5772                                                                                                    \n",
      " epoch: 0027, loss: 0.0011 - val_loss: 0.0133; rmse: 0.0244 - rmse_val: 0.1602;  r2: 0.9909 - r2_val: 0.6014; mae: 0.0172 - mae_val: 0.1198; r: 0.9955 - r_val: 0.7771;tau: 0.9417 - tau_val: 0.5590                                                                                                    \n",
      " epoch: 0028, loss: 0.0011 - val_loss: 0.0129; rmse: 0.0224 - rmse_val: 0.1575;  r2: 0.9923 - r2_val: 0.6146; mae: 0.0160 - mae_val: 0.1190; r: 0.9963 - r_val: 0.7848;tau: 0.9488 - tau_val: 0.5682                                                                                                    \n",
      " epoch: 0029, loss: 0.0009 - val_loss: 0.0126; rmse: 0.0196 - rmse_val: 0.1561;  r2: 0.9941 - r2_val: 0.6213; mae: 0.0138 - mae_val: 0.1175; r: 0.9971 - r_val: 0.7895;tau: 0.9536 - tau_val: 0.5781                                                                                                    \n",
      " epoch: 0030, loss: 0.0009 - val_loss: 0.0131; rmse: 0.0227 - rmse_val: 0.1594;  r2: 0.9921 - r2_val: 0.6051; mae: 0.0165 - mae_val: 0.1191; r: 0.9968 - r_val: 0.7844;tau: 0.9531 - tau_val: 0.5688                                                                                                    \n",
      " epoch: 0031, loss: 0.0009 - val_loss: 0.0125; rmse: 0.0293 - rmse_val: 0.1554;  r2: 0.9868 - r2_val: 0.6245; mae: 0.0223 - mae_val: 0.1173; r: 0.9968 - r_val: 0.7915;tau: 0.9509 - tau_val: 0.5822                                                                                                    \n",
      " epoch: 0032, loss: 0.0012 - val_loss: 0.0128; rmse: 0.0274 - rmse_val: 0.1573;  r2: 0.9885 - r2_val: 0.6155; mae: 0.0202 - mae_val: 0.1180; r: 0.9943 - r_val: 0.7865;tau: 0.9335 - tau_val: 0.5726                                                                                                    \n",
      " epoch: 0033, loss: 0.0011 - val_loss: 0.0122; rmse: 0.0252 - rmse_val: 0.1533;  r2: 0.9902 - r2_val: 0.6346; mae: 0.0190 - mae_val: 0.1167; r: 0.9959 - r_val: 0.7969;tau: 0.9440 - tau_val: 0.5764                                                                                                    \n",
      " epoch: 0034, loss: 0.0010 - val_loss: 0.0126; rmse: 0.0348 - rmse_val: 0.1559;  r2: 0.9814 - r2_val: 0.6223; mae: 0.0265 - mae_val: 0.1185; r: 0.9959 - r_val: 0.7909;tau: 0.9454 - tau_val: 0.5819                                                                                                    \n",
      " epoch: 0035, loss: 0.0009 - val_loss: 0.0128; rmse: 0.0237 - rmse_val: 0.1573;  r2: 0.9914 - r2_val: 0.6155; mae: 0.0172 - mae_val: 0.1201; r: 0.9966 - r_val: 0.7849;tau: 0.9497 - tau_val: 0.5685                                                                                                    \n",
      " epoch: 0036, loss: 0.0009 - val_loss: 0.0128; rmse: 0.0276 - rmse_val: 0.1575;  r2: 0.9883 - r2_val: 0.6145; mae: 0.0194 - mae_val: 0.1168; r: 0.9950 - r_val: 0.7894;tau: 0.9428 - tau_val: 0.5726                                                                                                    \n",
      " epoch: 0037, loss: 0.0011 - val_loss: 0.0131; rmse: 0.0281 - rmse_val: 0.1596;  r2: 0.9879 - r2_val: 0.6040; mae: 0.0207 - mae_val: 0.1212; r: 0.9948 - r_val: 0.7807;tau: 0.9354 - tau_val: 0.5714                                                                                                    \n",
      " epoch: 0038, loss: 0.0010 - val_loss: 0.0131; rmse: 0.0230 - rmse_val: 0.1592;  r2: 0.9919 - r2_val: 0.6064; mae: 0.0166 - mae_val: 0.1201; r: 0.9963 - r_val: 0.7822;tau: 0.9490 - tau_val: 0.5679                                                                                                    \n",
      " epoch: 0039, loss: 0.0011 - val_loss: 0.0134; rmse: 0.0257 - rmse_val: 0.1612;  r2: 0.9899 - r2_val: 0.5963; mae: 0.0190 - mae_val: 0.1191; r: 0.9954 - r_val: 0.7771;tau: 0.9424 - tau_val: 0.5604                                                                                                    \n",
      " epoch: 0040, loss: 0.0010 - val_loss: 0.0131; rmse: 0.0256 - rmse_val: 0.1597;  r2: 0.9899 - r2_val: 0.6037; mae: 0.0191 - mae_val: 0.1207; r: 0.9951 - r_val: 0.7788;tau: 0.9392 - tau_val: 0.5688                                                                                                    \n",
      " epoch: 0041, loss: 0.0009 - val_loss: 0.0127; rmse: 0.0240 - rmse_val: 0.1568;  r2: 0.9911 - r2_val: 0.6181; mae: 0.0168 - mae_val: 0.1186; r: 0.9955 - r_val: 0.7877;tau: 0.9439 - tau_val: 0.5743                                                                                                    \n",
      " epoch: 0042, loss: 0.0009 - val_loss: 0.0128; rmse: 0.0239 - rmse_val: 0.1579;  r2: 0.9912 - r2_val: 0.6125; mae: 0.0176 - mae_val: 0.1184; r: 0.9962 - r_val: 0.7858;tau: 0.9470 - tau_val: 0.5688                                                                                                    \n",
      " epoch: 0043, loss: 0.0009 - val_loss: 0.0130; rmse: 0.0267 - rmse_val: 0.1591;  r2: 0.9890 - r2_val: 0.6066; mae: 0.0205 - mae_val: 0.1187; r: 0.9958 - r_val: 0.7847;tau: 0.9441 - tau_val: 0.5755                                                                                                    \n",
      " epoch: 0044, loss: 0.0009 - val_loss: 0.0128; rmse: 0.0210 - rmse_val: 0.1579;  r2: 0.9932 - r2_val: 0.6125; mae: 0.0156 - mae_val: 0.1200; r: 0.9969 - r_val: 0.7831;tau: 0.9492 - tau_val: 0.5737                                                                                                    \n",
      " epoch: 0045, loss: 0.0012 - val_loss: 0.0126; rmse: 0.0354 - rmse_val: 0.1565;  r2: 0.9807 - r2_val: 0.6193; mae: 0.0282 - mae_val: 0.1192; r: 0.9942 - r_val: 0.7876;tau: 0.9362 - tau_val: 0.5778                                                                                                    \n",
      " epoch: 0046, loss: 0.0011 - val_loss: 0.0126; rmse: 0.0273 - rmse_val: 0.1564;  r2: 0.9885 - r2_val: 0.6197; mae: 0.0198 - mae_val: 0.1176; r: 0.9945 - r_val: 0.7888;tau: 0.9374 - tau_val: 0.5755                                                                                                    \n",
      " epoch: 0047, loss: 0.0013 - val_loss: 0.0128; rmse: 0.0371 - rmse_val: 0.1577;  r2: 0.9789 - r2_val: 0.6135; mae: 0.0281 - mae_val: 0.1197; r: 0.9937 - r_val: 0.7851;tau: 0.9295 - tau_val: 0.5795                                                                                                    \n",
      " epoch: 0048, loss: 0.0012 - val_loss: 0.0127; rmse: 0.0265 - rmse_val: 0.1572;  r2: 0.9892 - r2_val: 0.6162; mae: 0.0197 - mae_val: 0.1185; r: 0.9956 - r_val: 0.7854;tau: 0.9420 - tau_val: 0.5677                                                                                                    \n",
      " epoch: 0049, loss: 0.0009 - val_loss: 0.0126; rmse: 0.0253 - rmse_val: 0.1563;  r2: 0.9901 - r2_val: 0.6206; mae: 0.0196 - mae_val: 0.1195; r: 0.9966 - r_val: 0.7881;tau: 0.9491 - tau_val: 0.5758                                                                                                    \n",
      " epoch: 0050, loss: 0.0010 - val_loss: 0.0126; rmse: 0.0284 - rmse_val: 0.1569;  r2: 0.9876 - r2_val: 0.6176; mae: 0.0208 - mae_val: 0.1182; r: 0.9948 - r_val: 0.7886;tau: 0.9407 - tau_val: 0.5761                                                                                                    \n",
      " epoch: 0051, loss: 0.0011 - val_loss: 0.0131; rmse: 0.0286 - rmse_val: 0.1598;  r2: 0.9875 - r2_val: 0.6030; mae: 0.0210 - mae_val: 0.1197; r: 0.9943 - r_val: 0.7815;tau: 0.9345 - tau_val: 0.5737                                                                                                    \n",
      " epoch: 0052, loss: 0.0012 - val_loss: 0.0126; rmse: 0.0304 - rmse_val: 0.1566;  r2: 0.9858 - r2_val: 0.6188; mae: 0.0234 - mae_val: 0.1188; r: 0.9946 - r_val: 0.7870;tau: 0.9358 - tau_val: 0.5737                                                                                                    \n",
      " epoch: 0053, loss: 0.0014 - val_loss: 0.0130; rmse: 0.0320 - rmse_val: 0.1593;  r2: 0.9842 - r2_val: 0.6058; mae: 0.0237 - mae_val: 0.1209; r: 0.9927 - r_val: 0.7787;tau: 0.9292 - tau_val: 0.5723                                                                                                    \n",
      " epoch: 0054, loss: 0.0010 - val_loss: 0.0129; rmse: 0.0275 - rmse_val: 0.1585;  r2: 0.9884 - r2_val: 0.6096; mae: 0.0199 - mae_val: 0.1209; r: 0.9949 - r_val: 0.7813;tau: 0.9384 - tau_val: 0.5648                                                                                                    \n",
      " epoch: 0055, loss: 0.0011 - val_loss: 0.0128; rmse: 0.0362 - rmse_val: 0.1581;  r2: 0.9798 - r2_val: 0.6115; mae: 0.0268 - mae_val: 0.1196; r: 0.9937 - r_val: 0.7830;tau: 0.9316 - tau_val: 0.5726                                                                                                    \n",
      " epoch: 0056, loss: 0.0010 - val_loss: 0.0130; rmse: 0.0369 - rmse_val: 0.1594;  r2: 0.9790 - r2_val: 0.6054; mae: 0.0277 - mae_val: 0.1196; r: 0.9937 - r_val: 0.7799;tau: 0.9321 - tau_val: 0.5781                                                                                                    \n",
      " epoch: 0057, loss: 0.0012 - val_loss: 0.0129; rmse: 0.0382 - rmse_val: 0.1585;  r2: 0.9776 - r2_val: 0.6097; mae: 0.0284 - mae_val: 0.1207; r: 0.9928 - r_val: 0.7823;tau: 0.9297 - tau_val: 0.5703                                                                                                    \n",
      " epoch: 0058, loss: 0.0011 - val_loss: 0.0126; rmse: 0.0298 - rmse_val: 0.1570;  r2: 0.9864 - r2_val: 0.6169; mae: 0.0218 - mae_val: 0.1176; r: 0.9934 - r_val: 0.7866;tau: 0.9309 - tau_val: 0.5824                                                                                                    \n",
      " epoch: 0059, loss: 0.0015 - val_loss: 0.0153; rmse: 0.0538 - rmse_val: 0.1735;  r2: 0.9555 - r2_val: 0.5324; mae: 0.0426 - mae_val: 0.1266; r: 0.9909 - r_val: 0.7595;tau: 0.9170 - tau_val: 0.5587                                                                                                    \n",
      " epoch: 0060, loss: 0.0012 - val_loss: 0.0129; rmse: 0.0293 - rmse_val: 0.1590;  r2: 0.9868 - r2_val: 0.6070; mae: 0.0217 - mae_val: 0.1182; r: 0.9939 - r_val: 0.7833;tau: 0.9305 - tau_val: 0.5781                                                                                                    \n",
      " epoch: 0061, loss: 0.0011 - val_loss: 0.0134; rmse: 0.0337 - rmse_val: 0.1618;  r2: 0.9825 - r2_val: 0.5930; mae: 0.0254 - mae_val: 0.1209; r: 0.9940 - r_val: 0.7803;tau: 0.9321 - tau_val: 0.5726                                                                                                    \n",
      " epoch: 0062, loss: 0.0012 - val_loss: 0.0135; rmse: 0.0412 - rmse_val: 0.1623;  r2: 0.9739 - r2_val: 0.5907; mae: 0.0328 - mae_val: 0.1260; r: 0.9943 - r_val: 0.7740;tau: 0.9308 - tau_val: 0.5665                                                                                                    \n",
      " epoch: 0063, loss: 0.0011 - val_loss: 0.0124; rmse: 0.0272 - rmse_val: 0.1555;  r2: 0.9886 - r2_val: 0.6245; mae: 0.0204 - mae_val: 0.1180; r: 0.9959 - r_val: 0.7905;tau: 0.9433 - tau_val: 0.5845                                                                                                    \n",
      " epoch: 0064, loss: 0.0010 - val_loss: 0.0126; rmse: 0.0291 - rmse_val: 0.1568;  r2: 0.9870 - r2_val: 0.6181; mae: 0.0219 - mae_val: 0.1184; r: 0.9940 - r_val: 0.7862;tau: 0.9329 - tau_val: 0.5761                                                                                                    \n",
      " epoch: 0065, loss: 0.0009 - val_loss: 0.0126; rmse: 0.0228 - rmse_val: 0.1564;  r2: 0.9920 - r2_val: 0.6198; mae: 0.0173 - mae_val: 0.1188; r: 0.9961 - r_val: 0.7884;tau: 0.9435 - tau_val: 0.5752                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00065: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "WARNING:root:Found input variables with inconsistent numbers of samples: [113, 113, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************\n",
      "HLA-B_5301_(lr_0.0001-bs_32-lam_1e-06-ks_[(9, 9, 13),(1, 3, 5)]-kn_(96, 64, 128))_\n",
      " epoch: 0001, loss: 0.0402 - val_loss: 0.0323; rmse: 0.2518 - rmse_val: 0.2516;  r2: 0.0247 - r2_val: 0.0163; mae: 0.2090 - mae_val: 0.2030; r: 0.1801 - r_val: 0.1596;tau: 0.1126 - tau_val: 0.1061                                                                                                    \n",
      " epoch: 0002, loss: 0.0319 - val_loss: 0.0369; rmse: 0.2728 - rmse_val: 0.2689;  r2: -0.1443 - r2_val: -0.1240; mae: 0.2327 - mae_val: 0.2240; r: 0.3493 - r_val: 0.3467;tau: 0.2158 - tau_val: 0.2200                                                                                                    \n",
      " epoch: 0003, loss: 0.0332 - val_loss: 0.0319; rmse: 0.2494 - rmse_val: 0.2529;  r2: 0.0438 - r2_val: 0.0065; mae: 0.1989 - mae_val: 0.1978; r: 0.4616 - r_val: 0.4596;tau: 0.3008 - tau_val: 0.3024                                                                                                    \n",
      " epoch: 0004, loss: 0.0288 - val_loss: 0.0273; rmse: 0.2337 - rmse_val: 0.2312;  r2: 0.1599 - r2_val: 0.1691; mae: 0.1965 - mae_val: 0.1897; r: 0.5032 - r_val: 0.4992;tau: 0.3304 - tau_val: 0.3340                                                                                                    \n",
      " epoch: 0005, loss: 0.0267 - val_loss: 0.0244; rmse: 0.2152 - rmse_val: 0.2182;  r2: 0.2876 - r2_val: 0.2602; mae: 0.1775 - mae_val: 0.1761; r: 0.5759 - r_val: 0.5590;tau: 0.3897 - tau_val: 0.3798                                                                                                    \n",
      " epoch: 0006, loss: 0.0239 - val_loss: 0.0234; rmse: 0.2055 - rmse_val: 0.2142;  r2: 0.3504 - r2_val: 0.2869; mae: 0.1665 - mae_val: 0.1709; r: 0.6350 - r_val: 0.6053;tau: 0.4387 - tau_val: 0.4195                                                                                                    \n",
      " epoch: 0007, loss: 0.0212 - val_loss: 0.0201; rmse: 0.1891 - rmse_val: 0.1969;  r2: 0.4502 - r2_val: 0.3974; mae: 0.1537 - mae_val: 0.1609; r: 0.6919 - r_val: 0.6617;tau: 0.4908 - tau_val: 0.4787                                                                                                    \n",
      " epoch: 0008, loss: 0.0187 - val_loss: 0.0187; rmse: 0.1917 - rmse_val: 0.1895;  r2: 0.4349 - r2_val: 0.4420; mae: 0.1565 - mae_val: 0.1583; r: 0.7300 - r_val: 0.7177;tau: 0.5289 - tau_val: 0.5271                                                                                                    \n",
      " epoch: 0009, loss: 0.0187 - val_loss: 0.0172; rmse: 0.1772 - rmse_val: 0.1814;  r2: 0.5174 - r2_val: 0.4885; mae: 0.1436 - mae_val: 0.1492; r: 0.7569 - r_val: 0.7281;tau: 0.5507 - tau_val: 0.5427                                                                                                    \n",
      " epoch: 0010, loss: 0.0154 - val_loss: 0.0170; rmse: 0.1819 - rmse_val: 0.1803;  r2: 0.4910 - r2_val: 0.4946; mae: 0.1467 - mae_val: 0.1456; r: 0.7820 - r_val: 0.7569;tau: 0.5735 - tau_val: 0.5810                                                                                                    \n",
      " epoch: 0011, loss: 0.0158 - val_loss: 0.0155; rmse: 0.1637 - rmse_val: 0.1716;  r2: 0.5879 - r2_val: 0.5424; mae: 0.1331 - mae_val: 0.1389; r: 0.8065 - r_val: 0.7622;tau: 0.5927 - tau_val: 0.5735                                                                                                    \n",
      " epoch: 0012, loss: 0.0128 - val_loss: 0.0137; rmse: 0.1395 - rmse_val: 0.1611;  r2: 0.7008 - r2_val: 0.5969; mae: 0.1101 - mae_val: 0.1249; r: 0.8431 - r_val: 0.7801;tau: 0.6336 - tau_val: 0.5917                                                                                                    \n",
      " epoch: 0013, loss: 0.0118 - val_loss: 0.0134; rmse: 0.1301 - rmse_val: 0.1597;  r2: 0.7398 - r2_val: 0.6038; mae: 0.1023 - mae_val: 0.1225; r: 0.8659 - r_val: 0.7961;tau: 0.6571 - tau_val: 0.5967                                                                                                    \n",
      " epoch: 0014, loss: 0.0100 - val_loss: 0.0136; rmse: 0.1282 - rmse_val: 0.1605;  r2: 0.7473 - r2_val: 0.5995; mae: 0.1017 - mae_val: 0.1246; r: 0.8805 - r_val: 0.7821;tau: 0.6787 - tau_val: 0.5868                                                                                                    \n",
      " epoch: 0015, loss: 0.0094 - val_loss: 0.0128; rmse: 0.1240 - rmse_val: 0.1553;  r2: 0.7637 - r2_val: 0.6252; mae: 0.0989 - mae_val: 0.1199; r: 0.8953 - r_val: 0.8016;tau: 0.6979 - tau_val: 0.6016                                                                                                    \n",
      " epoch: 0016, loss: 0.0082 - val_loss: 0.0123; rmse: 0.1034 - rmse_val: 0.1522;  r2: 0.8355 - r2_val: 0.6399; mae: 0.0805 - mae_val: 0.1151; r: 0.9155 - r_val: 0.8056;tau: 0.7253 - tau_val: 0.6027                                                                                                    \n",
      " epoch: 0017, loss: 0.0069 - val_loss: 0.0140; rmse: 0.1259 - rmse_val: 0.1635;  r2: 0.7564 - r2_val: 0.5846; mae: 0.1032 - mae_val: 0.1309; r: 0.9190 - r_val: 0.8038;tau: 0.7320 - tau_val: 0.6097                                                                                                    \n",
      " epoch: 0018, loss: 0.0060 - val_loss: 0.0117; rmse: 0.0822 - rmse_val: 0.1482;  r2: 0.8960 - r2_val: 0.6587; mae: 0.0640 - mae_val: 0.1104; r: 0.9474 - r_val: 0.8151;tau: 0.7801 - tau_val: 0.6158                                                                                                    \n",
      " epoch: 0019, loss: 0.0046 - val_loss: 0.0122; rmse: 0.0727 - rmse_val: 0.1518;  r2: 0.9186 - r2_val: 0.6419; mae: 0.0569 - mae_val: 0.1150; r: 0.9624 - r_val: 0.8092;tau: 0.8173 - tau_val: 0.6004                                                                                                    \n",
      " epoch: 0020, loss: 0.0041 - val_loss: 0.0123; rmse: 0.0785 - rmse_val: 0.1530;  r2: 0.9051 - r2_val: 0.6364; mae: 0.0637 - mae_val: 0.1151; r: 0.9633 - r_val: 0.8032;tau: 0.8171 - tau_val: 0.5987                                                                                                    \n",
      " epoch: 0021, loss: 0.0047 - val_loss: 0.0128; rmse: 0.0706 - rmse_val: 0.1560;  r2: 0.9235 - r2_val: 0.6219; mae: 0.0542 - mae_val: 0.1173; r: 0.9666 - r_val: 0.8073;tau: 0.8321 - tau_val: 0.5981                                                                                                    \n",
      " epoch: 0022, loss: 0.0033 - val_loss: 0.0132; rmse: 0.0884 - rmse_val: 0.1585;  r2: 0.8800 - r2_val: 0.6094; mae: 0.0728 - mae_val: 0.1217; r: 0.9674 - r_val: 0.8085;tau: 0.8279 - tau_val: 0.6022                                                                                                    \n",
      " epoch: 0023, loss: 0.0033 - val_loss: 0.0118; rmse: 0.0557 - rmse_val: 0.1497;  r2: 0.9523 - r2_val: 0.6518; mae: 0.0439 - mae_val: 0.1145; r: 0.9796 - r_val: 0.8078;tau: 0.8659 - tau_val: 0.5967                                                                                                    \n",
      " epoch: 0024, loss: 0.0023 - val_loss: 0.0122; rmse: 0.0449 - rmse_val: 0.1526;  r2: 0.9691 - r2_val: 0.6383; mae: 0.0343 - mae_val: 0.1146; r: 0.9864 - r_val: 0.8067;tau: 0.8919 - tau_val: 0.6013                                                                                                    \n",
      " epoch: 0025, loss: 0.0024 - val_loss: 0.0124; rmse: 0.0500 - rmse_val: 0.1538;  r2: 0.9615 - r2_val: 0.6324; mae: 0.0398 - mae_val: 0.1170; r: 0.9858 - r_val: 0.7983;tau: 0.8922 - tau_val: 0.5940                                                                                                    \n",
      " epoch: 0026, loss: 0.0018 - val_loss: 0.0124; rmse: 0.0353 - rmse_val: 0.1539;  r2: 0.9809 - r2_val: 0.6319; mae: 0.0267 - mae_val: 0.1165; r: 0.9908 - r_val: 0.7955;tau: 0.9124 - tau_val: 0.5839                                                                                                    \n",
      " epoch: 0027, loss: 0.0016 - val_loss: 0.0124; rmse: 0.0336 - rmse_val: 0.1537;  r2: 0.9826 - r2_val: 0.6331; mae: 0.0254 - mae_val: 0.1175; r: 0.9922 - r_val: 0.7981;tau: 0.9204 - tau_val: 0.5865                                                                                                    \n",
      " epoch: 0028, loss: 0.0014 - val_loss: 0.0133; rmse: 0.0405 - rmse_val: 0.1598;  r2: 0.9748 - r2_val: 0.6033; mae: 0.0321 - mae_val: 0.1201; r: 0.9933 - r_val: 0.7917;tau: 0.9288 - tau_val: 0.5853                                                                                                    \n",
      " epoch: 0029, loss: 0.0013 - val_loss: 0.0126; rmse: 0.0321 - rmse_val: 0.1555;  r2: 0.9841 - r2_val: 0.6241; mae: 0.0249 - mae_val: 0.1165; r: 0.9938 - r_val: 0.7971;tau: 0.9294 - tau_val: 0.5790                                                                                                    \n",
      " epoch: 0030, loss: 0.0012 - val_loss: 0.0128; rmse: 0.0302 - rmse_val: 0.1568;  r2: 0.9860 - r2_val: 0.6179; mae: 0.0225 - mae_val: 0.1179; r: 0.9940 - r_val: 0.7916;tau: 0.9306 - tau_val: 0.5810                                                                                                    \n",
      " epoch: 0031, loss: 0.0012 - val_loss: 0.0123; rmse: 0.0293 - rmse_val: 0.1534;  r2: 0.9868 - r2_val: 0.6345; mae: 0.0216 - mae_val: 0.1152; r: 0.9943 - r_val: 0.7966;tau: 0.9337 - tau_val: 0.5842                                                                                                    \n",
      " epoch: 0032, loss: 0.0011 - val_loss: 0.0124; rmse: 0.0241 - rmse_val: 0.1546;  r2: 0.9911 - r2_val: 0.6286; mae: 0.0175 - mae_val: 0.1181; r: 0.9959 - r_val: 0.7952;tau: 0.9424 - tau_val: 0.5813                                                                                                    \n",
      " epoch: 0033, loss: 0.0011 - val_loss: 0.0123; rmse: 0.0286 - rmse_val: 0.1541;  r2: 0.9874 - r2_val: 0.6310; mae: 0.0211 - mae_val: 0.1179; r: 0.9959 - r_val: 0.8005;tau: 0.9449 - tau_val: 0.5888                                                                                                    \n",
      " epoch: 0034, loss: 0.0010 - val_loss: 0.0124; rmse: 0.0231 - rmse_val: 0.1545;  r2: 0.9918 - r2_val: 0.6292; mae: 0.0171 - mae_val: 0.1176; r: 0.9965 - r_val: 0.7935;tau: 0.9482 - tau_val: 0.5845                                                                                                    \n",
      " epoch: 0035, loss: 0.0010 - val_loss: 0.0122; rmse: 0.0228 - rmse_val: 0.1532;  r2: 0.9920 - r2_val: 0.6354; mae: 0.0159 - mae_val: 0.1156; r: 0.9960 - r_val: 0.7987;tau: 0.9478 - tau_val: 0.5865                                                                                                    \n",
      " epoch: 0036, loss: 0.0009 - val_loss: 0.0123; rmse: 0.0188 - rmse_val: 0.1536;  r2: 0.9946 - r2_val: 0.6336; mae: 0.0137 - mae_val: 0.1167; r: 0.9973 - r_val: 0.7970;tau: 0.9539 - tau_val: 0.5827                                                                                                    \n",
      " epoch: 0037, loss: 0.0009 - val_loss: 0.0124; rmse: 0.0200 - rmse_val: 0.1549;  r2: 0.9938 - r2_val: 0.6271; mae: 0.0148 - mae_val: 0.1181; r: 0.9973 - r_val: 0.7944;tau: 0.9549 - tau_val: 0.5877                                                                                                    \n",
      " epoch: 0038, loss: 0.0008 - val_loss: 0.0120; rmse: 0.0184 - rmse_val: 0.1523;  r2: 0.9948 - r2_val: 0.6398; mae: 0.0137 - mae_val: 0.1157; r: 0.9977 - r_val: 0.8014;tau: 0.9570 - tau_val: 0.5865                                                                                                    \n",
      " epoch: 0039, loss: 0.0008 - val_loss: 0.0125; rmse: 0.0170 - rmse_val: 0.1552;  r2: 0.9956 - r2_val: 0.6259; mae: 0.0121 - mae_val: 0.1184; r: 0.9980 - r_val: 0.7912;tau: 0.9618 - tau_val: 0.5848                                                                                                    \n",
      " epoch: 0040, loss: 0.0008 - val_loss: 0.0120; rmse: 0.0216 - rmse_val: 0.1519;  r2: 0.9928 - r2_val: 0.6414; mae: 0.0160 - mae_val: 0.1151; r: 0.9970 - r_val: 0.8010;tau: 0.9513 - tau_val: 0.5877                                                                                                    \n",
      " epoch: 0041, loss: 0.0009 - val_loss: 0.0120; rmse: 0.0234 - rmse_val: 0.1523;  r2: 0.9916 - r2_val: 0.6394; mae: 0.0177 - mae_val: 0.1158; r: 0.9959 - r_val: 0.8000;tau: 0.9438 - tau_val: 0.5848                                                                                                    \n",
      " epoch: 0042, loss: 0.0013 - val_loss: 0.0123; rmse: 0.0294 - rmse_val: 0.1542;  r2: 0.9867 - r2_val: 0.6303; mae: 0.0216 - mae_val: 0.1176; r: 0.9936 - r_val: 0.7952;tau: 0.9306 - tau_val: 0.5833                                                                                                    \n",
      " epoch: 0043, loss: 0.0011 - val_loss: 0.0125; rmse: 0.0357 - rmse_val: 0.1552;  r2: 0.9804 - r2_val: 0.6256; mae: 0.0274 - mae_val: 0.1174; r: 0.9951 - r_val: 0.7951;tau: 0.9355 - tau_val: 0.5882                                                                                                    \n",
      " epoch: 0044, loss: 0.0010 - val_loss: 0.0123; rmse: 0.0307 - rmse_val: 0.1540;  r2: 0.9855 - r2_val: 0.6317; mae: 0.0248 - mae_val: 0.1191; r: 0.9955 - r_val: 0.7964;tau: 0.9392 - tau_val: 0.5880                                                                                                    \n",
      " epoch: 0045, loss: 0.0011 - val_loss: 0.0128; rmse: 0.0316 - rmse_val: 0.1574;  r2: 0.9846 - r2_val: 0.6151; mae: 0.0240 - mae_val: 0.1165; r: 0.9950 - r_val: 0.7922;tau: 0.9365 - tau_val: 0.5781                                                                                                    \n",
      " epoch: 0046, loss: 0.0011 - val_loss: 0.0128; rmse: 0.0347 - rmse_val: 0.1578;  r2: 0.9815 - r2_val: 0.6132; mae: 0.0256 - mae_val: 0.1190; r: 0.9932 - r_val: 0.7927;tau: 0.9277 - tau_val: 0.5813                                                                                                    \n",
      " epoch: 0047, loss: 0.0012 - val_loss: 0.0130; rmse: 0.0332 - rmse_val: 0.1590;  r2: 0.9830 - r2_val: 0.6072; mae: 0.0242 - mae_val: 0.1201; r: 0.9941 - r_val: 0.7867;tau: 0.9337 - tau_val: 0.5685                                                                                                    \n",
      " epoch: 0048, loss: 0.0011 - val_loss: 0.0122; rmse: 0.0270 - rmse_val: 0.1538;  r2: 0.9888 - r2_val: 0.6325; mae: 0.0210 - mae_val: 0.1197; r: 0.9958 - r_val: 0.7956;tau: 0.9409 - tau_val: 0.5830                                                                                                    \n",
      " epoch: 0049, loss: 0.0011 - val_loss: 0.0123; rmse: 0.0365 - rmse_val: 0.1545;  r2: 0.9795 - r2_val: 0.6291; mae: 0.0288 - mae_val: 0.1181; r: 0.9943 - r_val: 0.7966;tau: 0.9332 - tau_val: 0.5909                                                                                                    \n",
      " epoch: 0050, loss: 0.0010 - val_loss: 0.0130; rmse: 0.0307 - rmse_val: 0.1586;  r2: 0.9855 - r2_val: 0.6090; mae: 0.0246 - mae_val: 0.1199; r: 0.9959 - r_val: 0.7885;tau: 0.9432 - tau_val: 0.5743                                                                                                    \n",
      " epoch: 0051, loss: 0.0010 - val_loss: 0.0120; rmse: 0.0266 - rmse_val: 0.1525;  r2: 0.9892 - r2_val: 0.6387; mae: 0.0200 - mae_val: 0.1171; r: 0.9952 - r_val: 0.7995;tau: 0.9400 - tau_val: 0.5830                                                                                                    \n",
      " epoch: 0052, loss: 0.0009 - val_loss: 0.0130; rmse: 0.0234 - rmse_val: 0.1592;  r2: 0.9916 - r2_val: 0.6063; mae: 0.0175 - mae_val: 0.1203; r: 0.9963 - r_val: 0.7824;tau: 0.9454 - tau_val: 0.5735                                                                                                    \n",
      " epoch: 0053, loss: 0.0009 - val_loss: 0.0121; rmse: 0.0253 - rmse_val: 0.1531;  r2: 0.9901 - r2_val: 0.6356; mae: 0.0188 - mae_val: 0.1172; r: 0.9953 - r_val: 0.7973;tau: 0.9403 - tau_val: 0.5833                                                                                                    \n",
      " epoch: 0054, loss: 0.0011 - val_loss: 0.0136; rmse: 0.0454 - rmse_val: 0.1629;  r2: 0.9684 - r2_val: 0.5878; mae: 0.0346 - mae_val: 0.1215; r: 0.9912 - r_val: 0.7810;tau: 0.9234 - tau_val: 0.5668                                                                                                    \n",
      " epoch: 0055, loss: 0.0016 - val_loss: 0.0131; rmse: 0.0402 - rmse_val: 0.1598;  r2: 0.9751 - r2_val: 0.6033; mae: 0.0302 - mae_val: 0.1192; r: 0.9887 - r_val: 0.7787;tau: 0.9086 - tau_val: 0.5642                                                                                                    \n",
      " epoch: 0056, loss: 0.0024 - val_loss: 0.0144; rmse: 0.0678 - rmse_val: 0.1680;  r2: 0.9292 - r2_val: 0.5613; mae: 0.0528 - mae_val: 0.1273; r: 0.9807 - r_val: 0.7791;tau: 0.8831 - tau_val: 0.5717                                                                                                    \n",
      " epoch: 0057, loss: 0.0018 - val_loss: 0.0126; rmse: 0.0411 - rmse_val: 0.1562;  r2: 0.9740 - r2_val: 0.6210; mae: 0.0327 - mae_val: 0.1207; r: 0.9889 - r_val: 0.7892;tau: 0.9064 - tau_val: 0.5688                                                                                                    \n",
      " epoch: 0058, loss: 0.0020 - val_loss: 0.0125; rmse: 0.0384 - rmse_val: 0.1555;  r2: 0.9773 - r2_val: 0.6243; mae: 0.0282 - mae_val: 0.1199; r: 0.9889 - r_val: 0.7905;tau: 0.9091 - tau_val: 0.5732                                                                                                    \n",
      " epoch: 0059, loss: 0.0023 - val_loss: 0.0123; rmse: 0.0392 - rmse_val: 0.1541;  r2: 0.9764 - r2_val: 0.6310; mae: 0.0296 - mae_val: 0.1182; r: 0.9894 - r_val: 0.7954;tau: 0.9092 - tau_val: 0.5894                                                                                                    \n",
      " epoch: 0060, loss: 0.0014 - val_loss: 0.0125; rmse: 0.0339 - rmse_val: 0.1558;  r2: 0.9823 - r2_val: 0.6228; mae: 0.0259 - mae_val: 0.1209; r: 0.9917 - r_val: 0.7892;tau: 0.9221 - tau_val: 0.5766                                                                                                    \n",
      " epoch: 0061, loss: 0.0013 - val_loss: 0.0120; rmse: 0.0332 - rmse_val: 0.1519;  r2: 0.9831 - r2_val: 0.6414; mae: 0.0253 - mae_val: 0.1158; r: 0.9937 - r_val: 0.8017;tau: 0.9288 - tau_val: 0.5923                                                                                                    \n",
      " epoch: 0062, loss: 0.0011 - val_loss: 0.0127; rmse: 0.0314 - rmse_val: 0.1571;  r2: 0.9849 - r2_val: 0.6164; mae: 0.0239 - mae_val: 0.1210; r: 0.9959 - r_val: 0.7891;tau: 0.9451 - tau_val: 0.5787                                                                                                    \n",
      " epoch: 0063, loss: 0.0010 - val_loss: 0.0128; rmse: 0.0268 - rmse_val: 0.1576;  r2: 0.9889 - r2_val: 0.6139; mae: 0.0205 - mae_val: 0.1195; r: 0.9954 - r_val: 0.7874;tau: 0.9400 - tau_val: 0.5758                                                                                                    \n",
      " epoch: 0064, loss: 0.0009 - val_loss: 0.0126; rmse: 0.0206 - rmse_val: 0.1568;  r2: 0.9935 - r2_val: 0.6178; mae: 0.0151 - mae_val: 0.1201; r: 0.9972 - r_val: 0.7873;tau: 0.9525 - tau_val: 0.5761                                                                                                    \n",
      " epoch: 0065, loss: 0.0009 - val_loss: 0.0125; rmse: 0.0198 - rmse_val: 0.1558;  r2: 0.9940 - r2_val: 0.6228; mae: 0.0146 - mae_val: 0.1185; r: 0.9974 - r_val: 0.7912;tau: 0.9553 - tau_val: 0.5810                                                                                                    \n",
      " epoch: 0066, loss: 0.0009 - val_loss: 0.0127; rmse: 0.0244 - rmse_val: 0.1574;  r2: 0.9908 - r2_val: 0.6148; mae: 0.0175 - mae_val: 0.1196; r: 0.9964 - r_val: 0.7872;tau: 0.9498 - tau_val: 0.5746                                                                                                    \n",
      " epoch: 0067, loss: 0.0008 - val_loss: 0.0127; rmse: 0.0202 - rmse_val: 0.1568;  r2: 0.9937 - r2_val: 0.6177; mae: 0.0156 - mae_val: 0.1205; r: 0.9970 - r_val: 0.7864;tau: 0.9497 - tau_val: 0.5761                                                                                                    \n",
      " epoch: 0068, loss: 0.0009 - val_loss: 0.0124; rmse: 0.0241 - rmse_val: 0.1549;  r2: 0.9911 - r2_val: 0.6269; mae: 0.0184 - mae_val: 0.1178; r: 0.9968 - r_val: 0.7961;tau: 0.9501 - tau_val: 0.5842                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00068: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "WARNING:root:Found input variables with inconsistent numbers of samples: [113, 113, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************\n",
      "HLA-B_1501_(lr_0.0001-bs_32-lam_0.001-ks_[(9, 9, 13),(1, 3, 5)]-kn_(48, 32, 64))_\n",
      " epoch: 0001, loss: 0.3474 - val_loss: 0.2687; rmse: 0.2769 - rmse_val: 0.2715;  r2: -0.0390 - r2_val: -0.0382; mae: 0.2306 - mae_val: 0.2313; r: -0.0089 - r_val: -0.0191;tau: -0.0164 - tau_val: -0.0191                                                                                                    \n",
      " epoch: 0002, loss: 0.2312 - val_loss: 0.1979; rmse: 0.2574 - rmse_val: 0.2514;  r2: 0.1023 - r2_val: 0.1096; mae: 0.2268 - mae_val: 0.2244; r: 0.3703 - r_val: 0.3848;tau: 0.2439 - tau_val: 0.2588                                                                                                    \n",
      " epoch: 0003, loss: 0.1772 - val_loss: 0.1558; rmse: 0.2440 - rmse_val: 0.2372;  r2: 0.1929 - r2_val: 0.2072; mae: 0.2108 - mae_val: 0.2080; r: 0.4815 - r_val: 0.4980;tau: 0.3337 - tau_val: 0.3509                                                                                                    \n",
      " epoch: 0004, loss: 0.1432 - val_loss: 0.1302; rmse: 0.2384 - rmse_val: 0.2340;  r2: 0.2299 - r2_val: 0.2288; mae: 0.2075 - mae_val: 0.2042; r: 0.5691 - r_val: 0.5743;tau: 0.4034 - tau_val: 0.4066                                                                                                    \n",
      " epoch: 0005, loss: 0.1197 - val_loss: 0.1086; rmse: 0.2255 - rmse_val: 0.2186;  r2: 0.3109 - r2_val: 0.3268; mae: 0.1763 - mae_val: 0.1748; r: 0.6187 - r_val: 0.6199;tau: 0.4402 - tau_val: 0.4357                                                                                                    \n",
      " epoch: 0006, loss: 0.1015 - val_loss: 0.0936; rmse: 0.2105 - rmse_val: 0.2084;  r2: 0.3994 - r2_val: 0.3879; mae: 0.1725 - mae_val: 0.1725; r: 0.6616 - r_val: 0.6553;tau: 0.4791 - tau_val: 0.4579                                                                                                    \n",
      " epoch: 0007, loss: 0.0877 - val_loss: 0.0806; rmse: 0.2000 - rmse_val: 0.1977;  r2: 0.4577 - r2_val: 0.4493; mae: 0.1548 - mae_val: 0.1568; r: 0.6964 - r_val: 0.6808;tau: 0.5046 - tau_val: 0.4739                                                                                                    \n",
      " epoch: 0008, loss: 0.0768 - val_loss: 0.0710; rmse: 0.1924 - rmse_val: 0.1926;  r2: 0.4981 - r2_val: 0.4775; mae: 0.1487 - mae_val: 0.1528; r: 0.7161 - r_val: 0.6943;tau: 0.5185 - tau_val: 0.4835                                                                                                    \n",
      " epoch: 0009, loss: 0.0680 - val_loss: 0.0633; rmse: 0.1898 - rmse_val: 0.1907;  r2: 0.5119 - r2_val: 0.4878; mae: 0.1440 - mae_val: 0.1492; r: 0.7330 - r_val: 0.7062;tau: 0.5307 - tau_val: 0.4892                                                                                                    \n",
      " epoch: 0010, loss: 0.0606 - val_loss: 0.0567; rmse: 0.1844 - rmse_val: 0.1877;  r2: 0.5394 - r2_val: 0.5036; mae: 0.1430 - mae_val: 0.1486; r: 0.7431 - r_val: 0.7154;tau: 0.5401 - tau_val: 0.4967                                                                                                    \n",
      " epoch: 0011, loss: 0.0535 - val_loss: 0.0510; rmse: 0.1820 - rmse_val: 0.1852;  r2: 0.5511 - r2_val: 0.5168; mae: 0.1355 - mae_val: 0.1423; r: 0.7570 - r_val: 0.7243;tau: 0.5490 - tau_val: 0.5018                                                                                                    \n",
      " epoch: 0012, loss: 0.0488 - val_loss: 0.0461; rmse: 0.1745 - rmse_val: 0.1818;  r2: 0.5872 - r2_val: 0.5342; mae: 0.1325 - mae_val: 0.1396; r: 0.7705 - r_val: 0.7336;tau: 0.5620 - tau_val: 0.5114                                                                                                    \n",
      " epoch: 0013, loss: 0.0440 - val_loss: 0.0426; rmse: 0.1780 - rmse_val: 0.1834;  r2: 0.5708 - r2_val: 0.5260; mae: 0.1301 - mae_val: 0.1388; r: 0.7838 - r_val: 0.7424;tau: 0.5693 - tau_val: 0.5140                                                                                                    \n",
      " epoch: 0014, loss: 0.0398 - val_loss: 0.0396; rmse: 0.1718 - rmse_val: 0.1841;  r2: 0.6002 - r2_val: 0.5225; mae: 0.1306 - mae_val: 0.1400; r: 0.7868 - r_val: 0.7421;tau: 0.5750 - tau_val: 0.5167                                                                                                    \n",
      " epoch: 0015, loss: 0.0363 - val_loss: 0.0354; rmse: 0.1660 - rmse_val: 0.1762;  r2: 0.6265 - r2_val: 0.5626; mae: 0.1216 - mae_val: 0.1319; r: 0.8008 - r_val: 0.7522;tau: 0.5824 - tau_val: 0.5208                                                                                                    \n",
      " epoch: 0016, loss: 0.0328 - val_loss: 0.0342; rmse: 0.1751 - rmse_val: 0.1828;  r2: 0.5845 - r2_val: 0.5294; mae: 0.1255 - mae_val: 0.1363; r: 0.8086 - r_val: 0.7572;tau: 0.5882 - tau_val: 0.5238                                                                                                    \n",
      " epoch: 0017, loss: 0.0309 - val_loss: 0.0308; rmse: 0.1608 - rmse_val: 0.1749;  r2: 0.6496 - r2_val: 0.5689; mae: 0.1191 - mae_val: 0.1317; r: 0.8093 - r_val: 0.7556;tau: 0.5897 - tau_val: 0.5227                                                                                                    \n",
      " epoch: 0018, loss: 0.0281 - val_loss: 0.0314; rmse: 0.1683 - rmse_val: 0.1868;  r2: 0.6162 - r2_val: 0.5083; mae: 0.1301 - mae_val: 0.1426; r: 0.8167 - r_val: 0.7608;tau: 0.5976 - tau_val: 0.5289                                                                                                    \n",
      " epoch: 0019, loss: 0.0267 - val_loss: 0.0278; rmse: 0.1557 - rmse_val: 0.1752;  r2: 0.6713 - r2_val: 0.5674; mae: 0.1158 - mae_val: 0.1307; r: 0.8236 - r_val: 0.7618;tau: 0.6019 - tau_val: 0.5289                                                                                                    \n",
      " epoch: 0020, loss: 0.0245 - val_loss: 0.0269; rmse: 0.1563 - rmse_val: 0.1772;  r2: 0.6691 - r2_val: 0.5578; mae: 0.1173 - mae_val: 0.1334; r: 0.8295 - r_val: 0.7647;tau: 0.6085 - tau_val: 0.5281                                                                                                    \n",
      " epoch: 0021, loss: 0.0231 - val_loss: 0.0253; rmse: 0.1506 - rmse_val: 0.1744;  r2: 0.6927 - r2_val: 0.5714; mae: 0.1102 - mae_val: 0.1294; r: 0.8346 - r_val: 0.7615;tau: 0.6125 - tau_val: 0.5269                                                                                                    \n",
      " epoch: 0022, loss: 0.0218 - val_loss: 0.0241; rmse: 0.1518 - rmse_val: 0.1722;  r2: 0.6878 - r2_val: 0.5823; mae: 0.1082 - mae_val: 0.1278; r: 0.8465 - r_val: 0.7701;tau: 0.6188 - tau_val: 0.5306                                                                                                    \n",
      " epoch: 0023, loss: 0.0204 - val_loss: 0.0234; rmse: 0.1470 - rmse_val: 0.1728;  r2: 0.7070 - r2_val: 0.5795; mae: 0.1083 - mae_val: 0.1276; r: 0.8445 - r_val: 0.7695;tau: 0.6210 - tau_val: 0.5311                                                                                                    \n",
      " epoch: 0024, loss: 0.0193 - val_loss: 0.0228; rmse: 0.1483 - rmse_val: 0.1730;  r2: 0.7021 - r2_val: 0.5784; mae: 0.1052 - mae_val: 0.1279; r: 0.8502 - r_val: 0.7687;tau: 0.6228 - tau_val: 0.5322                                                                                                    \n",
      " epoch: 0025, loss: 0.0193 - val_loss: 0.0253; rmse: 0.1593 - rmse_val: 0.1903;  r2: 0.6561 - r2_val: 0.4898; mae: 0.1217 - mae_val: 0.1432; r: 0.8464 - r_val: 0.7617;tau: 0.6255 - tau_val: 0.5266                                                                                                    \n",
      " epoch: 0026, loss: 0.0178 - val_loss: 0.0218; rmse: 0.1451 - rmse_val: 0.1727;  r2: 0.7145 - r2_val: 0.5797; mae: 0.1023 - mae_val: 0.1267; r: 0.8620 - r_val: 0.7689;tau: 0.6314 - tau_val: 0.5213                                                                                                    \n",
      " epoch: 0027, loss: 0.0172 - val_loss: 0.0205; rmse: 0.1359 - rmse_val: 0.1677;  r2: 0.7496 - r2_val: 0.6037; mae: 0.0970 - mae_val: 0.1234; r: 0.8762 - r_val: 0.7786;tau: 0.6444 - tau_val: 0.5347                                                                                                    \n",
      " epoch: 0028, loss: 0.0162 - val_loss: 0.0206; rmse: 0.1318 - rmse_val: 0.1697;  r2: 0.7647 - r2_val: 0.5940; mae: 0.0944 - mae_val: 0.1230; r: 0.8757 - r_val: 0.7761;tau: 0.6450 - tau_val: 0.5336                                                                                                    \n",
      " epoch: 0029, loss: 0.0160 - val_loss: 0.0200; rmse: 0.1339 - rmse_val: 0.1680;  r2: 0.7570 - r2_val: 0.6022; mae: 0.0958 - mae_val: 0.1237; r: 0.8761 - r_val: 0.7765;tau: 0.6462 - tau_val: 0.5307                                                                                                    \n",
      " epoch: 0030, loss: 0.0152 - val_loss: 0.0197; rmse: 0.1247 - rmse_val: 0.1676;  r2: 0.7892 - r2_val: 0.6042; mae: 0.0903 - mae_val: 0.1218; r: 0.8905 - r_val: 0.7856;tau: 0.6579 - tau_val: 0.5441                                                                                                    \n",
      " epoch: 0031, loss: 0.0148 - val_loss: 0.0194; rmse: 0.1275 - rmse_val: 0.1672;  r2: 0.7799 - r2_val: 0.6063; mae: 0.0927 - mae_val: 0.1223; r: 0.8890 - r_val: 0.7794;tau: 0.6526 - tau_val: 0.5352                                                                                                    \n",
      " epoch: 0032, loss: 0.0141 - val_loss: 0.0196; rmse: 0.1200 - rmse_val: 0.1688;  r2: 0.8049 - r2_val: 0.5985; mae: 0.0853 - mae_val: 0.1214; r: 0.9003 - r_val: 0.7781;tau: 0.6659 - tau_val: 0.5355                                                                                                    \n",
      " epoch: 0033, loss: 0.0136 - val_loss: 0.0195; rmse: 0.1164 - rmse_val: 0.1689;  r2: 0.8165 - r2_val: 0.5982; mae: 0.0826 - mae_val: 0.1208; r: 0.9063 - r_val: 0.7801;tau: 0.6705 - tau_val: 0.5342                                                                                                    \n",
      " epoch: 0034, loss: 0.0135 - val_loss: 0.0203; rmse: 0.1193 - rmse_val: 0.1749;  r2: 0.8072 - r2_val: 0.5688; mae: 0.0857 - mae_val: 0.1282; r: 0.9021 - r_val: 0.7607;tau: 0.6683 - tau_val: 0.5243                                                                                                    \n",
      " epoch: 0035, loss: 0.0129 - val_loss: 0.0218; rmse: 0.1235 - rmse_val: 0.1845;  r2: 0.7933 - r2_val: 0.5205; mae: 0.0903 - mae_val: 0.1322; r: 0.9046 - r_val: 0.7729;tau: 0.6749 - tau_val: 0.5365                                                                                                    \n",
      " epoch: 0036, loss: 0.0127 - val_loss: 0.0200; rmse: 0.1179 - rmse_val: 0.1735;  r2: 0.8115 - r2_val: 0.5757; mae: 0.0824 - mae_val: 0.1232; r: 0.9156 - r_val: 0.7675;tau: 0.6828 - tau_val: 0.5245                                                                                                    \n",
      " epoch: 0037, loss: 0.0119 - val_loss: 0.0212; rmse: 0.1075 - rmse_val: 0.1803;  r2: 0.8434 - r2_val: 0.5418; mae: 0.0774 - mae_val: 0.1288; r: 0.9203 - r_val: 0.7678;tau: 0.6850 - tau_val: 0.5277                                                                                                    \n",
      " epoch: 0038, loss: 0.0115 - val_loss: 0.0202; rmse: 0.1045 - rmse_val: 0.1752;  r2: 0.8519 - r2_val: 0.5675; mae: 0.0749 - mae_val: 0.1287; r: 0.9274 - r_val: 0.7614;tau: 0.6970 - tau_val: 0.5150                                                                                                    \n",
      " epoch: 0039, loss: 0.0116 - val_loss: 0.0209; rmse: 0.1026 - rmse_val: 0.1799;  r2: 0.8572 - r2_val: 0.5441; mae: 0.0743 - mae_val: 0.1300; r: 0.9277 - r_val: 0.7662;tau: 0.6959 - tau_val: 0.5306                                                                                                    \n",
      " epoch: 0040, loss: 0.0108 - val_loss: 0.0200; rmse: 0.0984 - rmse_val: 0.1754;  r2: 0.8687 - r2_val: 0.5664; mae: 0.0705 - mae_val: 0.1251; r: 0.9343 - r_val: 0.7648;tau: 0.7036 - tau_val: 0.5274                                                                                                    \n",
      " epoch: 0041, loss: 0.0105 - val_loss: 0.0200; rmse: 0.1014 - rmse_val: 0.1757;  r2: 0.8605 - r2_val: 0.5652; mae: 0.0710 - mae_val: 0.1251; r: 0.9386 - r_val: 0.7623;tau: 0.7109 - tau_val: 0.5222                                                                                                    \n",
      " epoch: 0042, loss: 0.0103 - val_loss: 0.0197; rmse: 0.0977 - rmse_val: 0.1740;  r2: 0.8707 - r2_val: 0.5734; mae: 0.0684 - mae_val: 0.1250; r: 0.9400 - r_val: 0.7659;tau: 0.7084 - tau_val: 0.5194                                                                                                    \n",
      " epoch: 0043, loss: 0.0098 - val_loss: 0.0215; rmse: 0.0921 - rmse_val: 0.1847;  r2: 0.8850 - r2_val: 0.5192; mae: 0.0669 - mae_val: 0.1324; r: 0.9428 - r_val: 0.7541;tau: 0.7106 - tau_val: 0.5202                                                                                                    \n",
      " epoch: 0044, loss: 0.0096 - val_loss: 0.0209; rmse: 0.0880 - rmse_val: 0.1816;  r2: 0.8951 - r2_val: 0.5354; mae: 0.0619 - mae_val: 0.1287; r: 0.9470 - r_val: 0.7586;tau: 0.7184 - tau_val: 0.5207                                                                                                    \n",
      " epoch: 0045, loss: 0.0097 - val_loss: 0.0215; rmse: 0.1079 - rmse_val: 0.1846;  r2: 0.8423 - r2_val: 0.5196; mae: 0.0762 - mae_val: 0.1315; r: 0.9420 - r_val: 0.7429;tau: 0.7099 - tau_val: 0.4982                                                                                                    \n",
      " epoch: 0046, loss: 0.0092 - val_loss: 0.0243; rmse: 0.1052 - rmse_val: 0.2007;  r2: 0.8500 - r2_val: 0.4324; mae: 0.0776 - mae_val: 0.1465; r: 0.9425 - r_val: 0.7531;tau: 0.7189 - tau_val: 0.5167                                                                                                    \n",
      " epoch: 0047, loss: 0.0086 - val_loss: 0.0218; rmse: 0.0821 - rmse_val: 0.1872;  r2: 0.9087 - r2_val: 0.5063; mae: 0.0604 - mae_val: 0.1361; r: 0.9572 - r_val: 0.7541;tau: 0.7365 - tau_val: 0.5125                                                                                                    \n",
      " epoch: 0048, loss: 0.0081 - val_loss: 0.0206; rmse: 0.0805 - rmse_val: 0.1808;  r2: 0.9122 - r2_val: 0.5396; mae: 0.0570 - mae_val: 0.1283; r: 0.9574 - r_val: 0.7564;tau: 0.7332 - tau_val: 0.5198                                                                                                    \n",
      " epoch: 0049, loss: 0.0082 - val_loss: 0.0207; rmse: 0.0791 - rmse_val: 0.1814;  r2: 0.9152 - r2_val: 0.5362; mae: 0.0569 - mae_val: 0.1312; r: 0.9625 - r_val: 0.7495;tau: 0.7426 - tau_val: 0.5033                                                                                                    \n",
      " epoch: 0050, loss: 0.0077 - val_loss: 0.0214; rmse: 0.0809 - rmse_val: 0.1855;  r2: 0.9114 - r2_val: 0.5153; mae: 0.0572 - mae_val: 0.1315; r: 0.9592 - r_val: 0.7466;tau: 0.7409 - tau_val: 0.4998                                                                                                    \n",
      " epoch: 0051, loss: 0.0077 - val_loss: 0.0208; rmse: 0.0720 - rmse_val: 0.1826;  r2: 0.9297 - r2_val: 0.5303; mae: 0.0508 - mae_val: 0.1305; r: 0.9666 - r_val: 0.7516;tau: 0.7484 - tau_val: 0.5061                                                                                                    \n",
      " epoch: 0052, loss: 0.0073 - val_loss: 0.0208; rmse: 0.0713 - rmse_val: 0.1831;  r2: 0.9311 - r2_val: 0.5274; mae: 0.0507 - mae_val: 0.1313; r: 0.9668 - r_val: 0.7506;tau: 0.7528 - tau_val: 0.5101                                                                                                    \n",
      " epoch: 0053, loss: 0.0071 - val_loss: 0.0206; rmse: 0.0652 - rmse_val: 0.1823;  r2: 0.9424 - r2_val: 0.5315; mae: 0.0464 - mae_val: 0.1301; r: 0.9738 - r_val: 0.7493;tau: 0.7636 - tau_val: 0.5052                                                                                                    \n",
      " epoch: 0054, loss: 0.0070 - val_loss: 0.0223; rmse: 0.0666 - rmse_val: 0.1918;  r2: 0.9399 - r2_val: 0.4817; mae: 0.0481 - mae_val: 0.1386; r: 0.9712 - r_val: 0.7378;tau: 0.7630 - tau_val: 0.4951                                                                                                    \n",
      " epoch: 0055, loss: 0.0066 - val_loss: 0.0218; rmse: 0.0617 - rmse_val: 0.1897;  r2: 0.9483 - r2_val: 0.4928; mae: 0.0441 - mae_val: 0.1366; r: 0.9743 - r_val: 0.7481;tau: 0.7693 - tau_val: 0.5014                                                                                                    \n",
      " epoch: 0056, loss: 0.0067 - val_loss: 0.0233; rmse: 0.0645 - rmse_val: 0.1974;  r2: 0.9435 - r2_val: 0.4507; mae: 0.0485 - mae_val: 0.1438; r: 0.9747 - r_val: 0.7326;tau: 0.7674 - tau_val: 0.4884                                                                                                    \n",
      " epoch: 0057, loss: 0.0067 - val_loss: 0.0211; rmse: 0.0586 - rmse_val: 0.1862;  r2: 0.9534 - r2_val: 0.5117; mae: 0.0424 - mae_val: 0.1351; r: 0.9768 - r_val: 0.7453;tau: 0.7711 - tau_val: 0.5010                                                                                                    \n",
      " epoch: 0058, loss: 0.0061 - val_loss: 0.0211; rmse: 0.0531 - rmse_val: 0.1866;  r2: 0.9618 - r2_val: 0.5093; mae: 0.0386 - mae_val: 0.1352; r: 0.9809 - r_val: 0.7482;tau: 0.7826 - tau_val: 0.5067                                                                                                    \n",
      " epoch: 0059, loss: 0.0065 - val_loss: 0.0214; rmse: 0.0572 - rmse_val: 0.1883;  r2: 0.9556 - r2_val: 0.5005; mae: 0.0417 - mae_val: 0.1356; r: 0.9781 - r_val: 0.7437;tau: 0.7763 - tau_val: 0.4993                                                                                                    \n",
      " epoch: 0060, loss: 0.0062 - val_loss: 0.0212; rmse: 0.0586 - rmse_val: 0.1879;  r2: 0.9534 - r2_val: 0.5028; mae: 0.0427 - mae_val: 0.1347; r: 0.9772 - r_val: 0.7428;tau: 0.7779 - tau_val: 0.4925                                                                                                    \n",
      " epoch: 0061, loss: 0.0062 - val_loss: 0.0225; rmse: 0.0584 - rmse_val: 0.1950;  r2: 0.9537 - r2_val: 0.4641; mae: 0.0435 - mae_val: 0.1424; r: 0.9805 - r_val: 0.7423;tau: 0.7837 - tau_val: 0.4952                                                                                                    \n",
      " epoch: 0062, loss: 0.0059 - val_loss: 0.0205; rmse: 0.0586 - rmse_val: 0.1845;  r2: 0.9535 - r2_val: 0.5202; mae: 0.0419 - mae_val: 0.1316; r: 0.9837 - r_val: 0.7383;tau: 0.7896 - tau_val: 0.5000                                                                                                    \n",
      " epoch: 0063, loss: 0.0055 - val_loss: 0.0207; rmse: 0.0539 - rmse_val: 0.1856;  r2: 0.9607 - r2_val: 0.5145; mae: 0.0390 - mae_val: 0.1325; r: 0.9814 - r_val: 0.7442;tau: 0.7846 - tau_val: 0.4983                                                                                                    \n",
      " epoch: 0064, loss: 0.0060 - val_loss: 0.0216; rmse: 0.0604 - rmse_val: 0.1906;  r2: 0.9505 - r2_val: 0.4884; mae: 0.0436 - mae_val: 0.1353; r: 0.9755 - r_val: 0.7373;tau: 0.7731 - tau_val: 0.4966                                                                                                    \n",
      " epoch: 0065, loss: 0.0056 - val_loss: 0.0240; rmse: 0.0715 - rmse_val: 0.2037;  r2: 0.9308 - r2_val: 0.4152; mae: 0.0552 - mae_val: 0.1514; r: 0.9769 - r_val: 0.7316;tau: 0.7770 - tau_val: 0.4888                                                                                                    \n",
      " epoch: 0066, loss: 0.0060 - val_loss: 0.0211; rmse: 0.0539 - rmse_val: 0.1883;  r2: 0.9606 - r2_val: 0.5007; mae: 0.0389 - mae_val: 0.1351; r: 0.9824 - r_val: 0.7343;tau: 0.7880 - tau_val: 0.4804                                                                                                    \n",
      " epoch: 0067, loss: 0.0052 - val_loss: 0.0211; rmse: 0.0434 - rmse_val: 0.1887;  r2: 0.9745 - r2_val: 0.4983; mae: 0.0314 - mae_val: 0.1377; r: 0.9877 - r_val: 0.7412;tau: 0.8046 - tau_val: 0.4926                                                                                                    \n",
      " epoch: 0068, loss: 0.0052 - val_loss: 0.0205; rmse: 0.0491 - rmse_val: 0.1861;  r2: 0.9673 - r2_val: 0.5122; mae: 0.0355 - mae_val: 0.1340; r: 0.9844 - r_val: 0.7435;tau: 0.7919 - tau_val: 0.4964                                                                                                    \n",
      " epoch: 0069, loss: 0.0049 - val_loss: 0.0225; rmse: 0.0616 - rmse_val: 0.1969;  r2: 0.9485 - r2_val: 0.4539; mae: 0.0467 - mae_val: 0.1454; r: 0.9821 - r_val: 0.7462;tau: 0.7916 - tau_val: 0.5023                                                                                                    \n",
      " epoch: 0070, loss: 0.0049 - val_loss: 0.0219; rmse: 0.0511 - rmse_val: 0.1941;  r2: 0.9646 - r2_val: 0.4691; mae: 0.0379 - mae_val: 0.1414; r: 0.9844 - r_val: 0.7440;tau: 0.7981 - tau_val: 0.4959                                                                                                    \n",
      " epoch: 0071, loss: 0.0047 - val_loss: 0.0226; rmse: 0.0502 - rmse_val: 0.1982;  r2: 0.9658 - r2_val: 0.4466; mae: 0.0368 - mae_val: 0.1447; r: 0.9847 - r_val: 0.7261;tau: 0.8007 - tau_val: 0.4835                                                                                                    \n",
      " epoch: 0072, loss: 0.0047 - val_loss: 0.0211; rmse: 0.0721 - rmse_val: 0.1902;  r2: 0.9295 - r2_val: 0.4902; mae: 0.0525 - mae_val: 0.1336; r: 0.9845 - r_val: 0.7258;tau: 0.7991 - tau_val: 0.4761                                                                                                    \n",
      " epoch: 0073, loss: 0.0052 - val_loss: 0.0216; rmse: 0.0458 - rmse_val: 0.1928;  r2: 0.9715 - r2_val: 0.4764; mae: 0.0337 - mae_val: 0.1388; r: 0.9863 - r_val: 0.7343;tau: 0.8012 - tau_val: 0.4926                                                                                                    \n",
      " epoch: 0074, loss: 0.0047 - val_loss: 0.0209; rmse: 0.0483 - rmse_val: 0.1894;  r2: 0.9684 - r2_val: 0.4947; mae: 0.0348 - mae_val: 0.1373; r: 0.9867 - r_val: 0.7313;tau: 0.8043 - tau_val: 0.4801                                                                                                    \n",
      " epoch: 0075, loss: 0.0045 - val_loss: 0.0211; rmse: 0.0424 - rmse_val: 0.1905;  r2: 0.9756 - r2_val: 0.4885; mae: 0.0308 - mae_val: 0.1369; r: 0.9886 - r_val: 0.7356;tau: 0.8085 - tau_val: 0.4880                                                                                                    \n",
      " epoch: 0076, loss: 0.0047 - val_loss: 0.0211; rmse: 0.0451 - rmse_val: 0.1910;  r2: 0.9724 - r2_val: 0.4859; mae: 0.0329 - mae_val: 0.1375; r: 0.9875 - r_val: 0.7290;tau: 0.8049 - tau_val: 0.4851                                                                                                    \n",
      " epoch: 0077, loss: 0.0047 - val_loss: 0.0222; rmse: 0.0512 - rmse_val: 0.1968;  r2: 0.9644 - r2_val: 0.4544; mae: 0.0378 - mae_val: 0.1437; r: 0.9848 - r_val: 0.7380;tau: 0.7958 - tau_val: 0.4949                                                                                                    \n",
      " epoch: 0078, loss: 0.0048 - val_loss: 0.0224; rmse: 0.0495 - rmse_val: 0.1978;  r2: 0.9668 - r2_val: 0.4487; mae: 0.0370 - mae_val: 0.1473; r: 0.9855 - r_val: 0.7276;tau: 0.7988 - tau_val: 0.4848                                                                                                    \n",
      " epoch: 0079, loss: 0.0047 - val_loss: 0.0213; rmse: 0.0485 - rmse_val: 0.1926;  r2: 0.9681 - r2_val: 0.4775; mae: 0.0351 - mae_val: 0.1383; r: 0.9866 - r_val: 0.7265;tau: 0.8048 - tau_val: 0.4781                                                                                                    \n",
      " epoch: 0080, loss: 0.0045 - val_loss: 0.0220; rmse: 0.0446 - rmse_val: 0.1965;  r2: 0.9730 - r2_val: 0.4558; mae: 0.0327 - mae_val: 0.1420; r: 0.9870 - r_val: 0.7301;tau: 0.8086 - tau_val: 0.4888                                                                                                    \n",
      " epoch: 0081, loss: 0.0042 - val_loss: 0.0212; rmse: 0.0396 - rmse_val: 0.1924;  r2: 0.9787 - r2_val: 0.4785; mae: 0.0294 - mae_val: 0.1395; r: 0.9898 - r_val: 0.7379;tau: 0.8152 - tau_val: 0.4994                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00081: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "WARNING:root:Found input variables with inconsistent numbers of samples: [33, 33, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************\n",
      "HLA-B_1501_(lr_0.0001-bs_32-lam_0.001-ks_[(9, 9, 13),(1, 3, 5)]-kn_(48, 32, 64))_\n",
      " epoch: 0001, loss: 0.3521 - val_loss: 0.2773; rmse: 0.2720 - rmse_val: 0.2662;  r2: -0.0029 - r2_val: 0.0014; mae: 0.2335 - mae_val: 0.2326; r: 0.0509 - r_val: 0.0708;tau: 0.0221 - tau_val: 0.0502                                                                                                    \n",
      " epoch: 0002, loss: 0.2410 - val_loss: 0.2106; rmse: 0.2819 - rmse_val: 0.2759;  r2: -0.0770 - r2_val: -0.0722; mae: 0.2176 - mae_val: 0.2183; r: 0.3021 - r_val: 0.3212;tau: 0.1961 - tau_val: 0.2279                                                                                                    \n",
      " epoch: 0003, loss: 0.1860 - val_loss: 0.1631; rmse: 0.2517 - rmse_val: 0.2452;  r2: 0.1411 - r2_val: 0.1526; mae: 0.2132 - mae_val: 0.2124; r: 0.4334 - r_val: 0.4466;tau: 0.2935 - tau_val: 0.3174                                                                                                    \n",
      " epoch: 0004, loss: 0.1493 - val_loss: 0.1327; rmse: 0.2376 - rmse_val: 0.2309;  r2: 0.2353 - r2_val: 0.2486; mae: 0.2047 - mae_val: 0.2018; r: 0.5522 - r_val: 0.5651;tau: 0.3876 - tau_val: 0.4002                                                                                                    \n",
      " epoch: 0005, loss: 0.1223 - val_loss: 0.1108; rmse: 0.2217 - rmse_val: 0.2163;  r2: 0.3338 - r2_val: 0.3409; mae: 0.1896 - mae_val: 0.1853; r: 0.6454 - r_val: 0.6580;tau: 0.4667 - tau_val: 0.4627                                                                                                    \n",
      " epoch: 0006, loss: 0.1023 - val_loss: 0.0930; rmse: 0.2121 - rmse_val: 0.2014;  r2: 0.3903 - r2_val: 0.4286; mae: 0.1584 - mae_val: 0.1532; r: 0.6883 - r_val: 0.7020;tau: 0.4964 - tau_val: 0.4864                                                                                                    \n",
      " epoch: 0007, loss: 0.0872 - val_loss: 0.0792; rmse: 0.1935 - rmse_val: 0.1884;  r2: 0.4927 - r2_val: 0.5001; mae: 0.1501 - mae_val: 0.1491; r: 0.7208 - r_val: 0.7202;tau: 0.5231 - tau_val: 0.5001                                                                                                    \n",
      " epoch: 0008, loss: 0.0757 - val_loss: 0.0691; rmse: 0.1865 - rmse_val: 0.1829;  r2: 0.5286 - r2_val: 0.5285; mae: 0.1423 - mae_val: 0.1409; r: 0.7357 - r_val: 0.7299;tau: 0.5346 - tau_val: 0.5080                                                                                                    \n",
      " epoch: 0009, loss: 0.0662 - val_loss: 0.0610; rmse: 0.1820 - rmse_val: 0.1801;  r2: 0.5512 - r2_val: 0.5431; mae: 0.1379 - mae_val: 0.1391; r: 0.7563 - r_val: 0.7436;tau: 0.5486 - tau_val: 0.5204                                                                                                    \n",
      " epoch: 0010, loss: 0.0586 - val_loss: 0.0549; rmse: 0.1775 - rmse_val: 0.1800;  r2: 0.5731 - r2_val: 0.5433; mae: 0.1367 - mae_val: 0.1386; r: 0.7667 - r_val: 0.7489;tau: 0.5579 - tau_val: 0.5240                                                                                                    \n",
      " epoch: 0011, loss: 0.0524 - val_loss: 0.0488; rmse: 0.1720 - rmse_val: 0.1744;  r2: 0.5993 - r2_val: 0.5716; mae: 0.1287 - mae_val: 0.1297; r: 0.7765 - r_val: 0.7601;tau: 0.5632 - tau_val: 0.5344                                                                                                    \n",
      " epoch: 0012, loss: 0.0470 - val_loss: 0.0438; rmse: 0.1693 - rmse_val: 0.1714;  r2: 0.6114 - r2_val: 0.5863; mae: 0.1248 - mae_val: 0.1287; r: 0.7891 - r_val: 0.7669;tau: 0.5705 - tau_val: 0.5344                                                                                                    \n",
      " epoch: 0013, loss: 0.0421 - val_loss: 0.0407; rmse: 0.1737 - rmse_val: 0.1764;  r2: 0.5912 - r2_val: 0.5617; mae: 0.1255 - mae_val: 0.1299; r: 0.7933 - r_val: 0.7634;tau: 0.5730 - tau_val: 0.5294                                                                                                    \n",
      " epoch: 0014, loss: 0.0383 - val_loss: 0.0370; rmse: 0.1648 - rmse_val: 0.1727;  r2: 0.6319 - r2_val: 0.5797; mae: 0.1221 - mae_val: 0.1295; r: 0.7985 - r_val: 0.7624;tau: 0.5792 - tau_val: 0.5319                                                                                                    \n",
      " epoch: 0015, loss: 0.0353 - val_loss: 0.0337; rmse: 0.1608 - rmse_val: 0.1685;  r2: 0.6498 - r2_val: 0.6002; mae: 0.1183 - mae_val: 0.1249; r: 0.8097 - r_val: 0.7754;tau: 0.5847 - tau_val: 0.5392                                                                                                    \n",
      " epoch: 0016, loss: 0.0322 - val_loss: 0.0312; rmse: 0.1573 - rmse_val: 0.1680;  r2: 0.6645 - r2_val: 0.6023; mae: 0.1149 - mae_val: 0.1248; r: 0.8184 - r_val: 0.7762;tau: 0.5907 - tau_val: 0.5400                                                                                                    \n",
      " epoch: 0017, loss: 0.0294 - val_loss: 0.0293; rmse: 0.1574 - rmse_val: 0.1688;  r2: 0.6644 - r2_val: 0.5987; mae: 0.1138 - mae_val: 0.1248; r: 0.8227 - r_val: 0.7756;tau: 0.5945 - tau_val: 0.5382                                                                                                    \n",
      " epoch: 0018, loss: 0.0269 - val_loss: 0.0278; rmse: 0.1548 - rmse_val: 0.1699;  r2: 0.6753 - r2_val: 0.5933; mae: 0.1124 - mae_val: 0.1244; r: 0.8249 - r_val: 0.7703;tau: 0.5975 - tau_val: 0.5364                                                                                                    \n",
      " epoch: 0019, loss: 0.0254 - val_loss: 0.0280; rmse: 0.1615 - rmse_val: 0.1790;  r2: 0.6466 - r2_val: 0.5484; mae: 0.1231 - mae_val: 0.1329; r: 0.8299 - r_val: 0.7795;tau: 0.6025 - tau_val: 0.5461                                                                                                    \n",
      " epoch: 0020, loss: 0.0241 - val_loss: 0.0247; rmse: 0.1494 - rmse_val: 0.1668;  r2: 0.6976 - r2_val: 0.6081; mae: 0.1081 - mae_val: 0.1217; r: 0.8369 - r_val: 0.7811;tau: 0.6056 - tau_val: 0.5471                                                                                                    \n",
      " epoch: 0021, loss: 0.0228 - val_loss: 0.0246; rmse: 0.1555 - rmse_val: 0.1732;  r2: 0.6723 - r2_val: 0.5775; mae: 0.1156 - mae_val: 0.1267; r: 0.8297 - r_val: 0.7770;tau: 0.6024 - tau_val: 0.5448                                                                                                    \n",
      " epoch: 0022, loss: 0.0212 - val_loss: 0.0226; rmse: 0.1474 - rmse_val: 0.1658;  r2: 0.7057 - r2_val: 0.6126; mae: 0.1090 - mae_val: 0.1231; r: 0.8424 - r_val: 0.7856;tau: 0.6081 - tau_val: 0.5524                                                                                                    \n",
      " epoch: 0023, loss: 0.0198 - val_loss: 0.0220; rmse: 0.1454 - rmse_val: 0.1674;  r2: 0.7136 - r2_val: 0.6051; mae: 0.1078 - mae_val: 0.1234; r: 0.8494 - r_val: 0.7835;tau: 0.6161 - tau_val: 0.5485                                                                                                    \n",
      " epoch: 0024, loss: 0.0194 - val_loss: 0.0213; rmse: 0.1462 - rmse_val: 0.1670;  r2: 0.7103 - r2_val: 0.6071; mae: 0.1037 - mae_val: 0.1208; r: 0.8484 - r_val: 0.7814;tau: 0.6139 - tau_val: 0.5488                                                                                                    \n",
      " epoch: 0025, loss: 0.0184 - val_loss: 0.0203; rmse: 0.1404 - rmse_val: 0.1638;  r2: 0.7329 - r2_val: 0.6222; mae: 0.1010 - mae_val: 0.1187; r: 0.8573 - r_val: 0.7903;tau: 0.6224 - tau_val: 0.5533                                                                                                    \n",
      " epoch: 0026, loss: 0.0176 - val_loss: 0.0201; rmse: 0.1396 - rmse_val: 0.1659;  r2: 0.7358 - r2_val: 0.6122; mae: 0.1004 - mae_val: 0.1223; r: 0.8647 - r_val: 0.7834;tau: 0.6280 - tau_val: 0.5460                                                                                                    \n",
      " epoch: 0027, loss: 0.0167 - val_loss: 0.0217; rmse: 0.1468 - rmse_val: 0.1774;  r2: 0.7079 - r2_val: 0.5567; mae: 0.1114 - mae_val: 0.1315; r: 0.8612 - r_val: 0.7793;tau: 0.6266 - tau_val: 0.5458                                                                                                    \n",
      " epoch: 0028, loss: 0.0159 - val_loss: 0.0201; rmse: 0.1368 - rmse_val: 0.1694;  r2: 0.7464 - r2_val: 0.5955; mae: 0.0990 - mae_val: 0.1216; r: 0.8672 - r_val: 0.7815;tau: 0.6338 - tau_val: 0.5470                                                                                                    \n",
      " epoch: 0029, loss: 0.0159 - val_loss: 0.0192; rmse: 0.1315 - rmse_val: 0.1658;  r2: 0.7655 - r2_val: 0.6129; mae: 0.0963 - mae_val: 0.1216; r: 0.8785 - r_val: 0.7867;tau: 0.6424 - tau_val: 0.5491                                                                                                    \n",
      " epoch: 0030, loss: 0.0150 - val_loss: 0.0218; rmse: 0.1443 - rmse_val: 0.1820;  r2: 0.7178 - r2_val: 0.5331; mae: 0.1091 - mae_val: 0.1322; r: 0.8745 - r_val: 0.7839;tau: 0.6422 - tau_val: 0.5497                                                                                                    \n",
      " epoch: 0031, loss: 0.0144 - val_loss: 0.0195; rmse: 0.1292 - rmse_val: 0.1695;  r2: 0.7739 - r2_val: 0.5950; mae: 0.0944 - mae_val: 0.1223; r: 0.8857 - r_val: 0.7841;tau: 0.6498 - tau_val: 0.5446                                                                                                    \n",
      " epoch: 0032, loss: 0.0138 - val_loss: 0.0186; rmse: 0.1251 - rmse_val: 0.1649;  r2: 0.7879 - r2_val: 0.6168; mae: 0.0897 - mae_val: 0.1199; r: 0.8895 - r_val: 0.7875;tau: 0.6521 - tau_val: 0.5514                                                                                                    \n",
      " epoch: 0033, loss: 0.0138 - val_loss: 0.0188; rmse: 0.1210 - rmse_val: 0.1665;  r2: 0.8017 - r2_val: 0.6096; mae: 0.0871 - mae_val: 0.1228; r: 0.9016 - r_val: 0.7812;tau: 0.6603 - tau_val: 0.5385                                                                                                    \n",
      " epoch: 0034, loss: 0.0131 - val_loss: 0.0189; rmse: 0.1197 - rmse_val: 0.1673;  r2: 0.8059 - r2_val: 0.6057; mae: 0.0871 - mae_val: 0.1212; r: 0.9001 - r_val: 0.7822;tau: 0.6596 - tau_val: 0.5436                                                                                                    \n",
      " epoch: 0035, loss: 0.0126 - val_loss: 0.0188; rmse: 0.1112 - rmse_val: 0.1672;  r2: 0.8324 - r2_val: 0.6063; mae: 0.0803 - mae_val: 0.1209; r: 0.9144 - r_val: 0.7833;tau: 0.6763 - tau_val: 0.5385                                                                                                    \n",
      " epoch: 0036, loss: 0.0126 - val_loss: 0.0195; rmse: 0.1149 - rmse_val: 0.1725;  r2: 0.8211 - r2_val: 0.5809; mae: 0.0836 - mae_val: 0.1231; r: 0.9099 - r_val: 0.7771;tau: 0.6715 - tau_val: 0.5343                                                                                                    \n",
      " epoch: 0037, loss: 0.0120 - val_loss: 0.0187; rmse: 0.1138 - rmse_val: 0.1675;  r2: 0.8244 - r2_val: 0.6048; mae: 0.0791 - mae_val: 0.1213; r: 0.9172 - r_val: 0.7849;tau: 0.6814 - tau_val: 0.5376                                                                                                    \n",
      " epoch: 0038, loss: 0.0114 - val_loss: 0.0190; rmse: 0.1041 - rmse_val: 0.1695;  r2: 0.8531 - r2_val: 0.5951; mae: 0.0760 - mae_val: 0.1226; r: 0.9262 - r_val: 0.7838;tau: 0.6921 - tau_val: 0.5386                                                                                                    \n",
      " epoch: 0039, loss: 0.0112 - val_loss: 0.0197; rmse: 0.1076 - rmse_val: 0.1742;  r2: 0.8431 - r2_val: 0.5727; mae: 0.0795 - mae_val: 0.1259; r: 0.9247 - r_val: 0.7790;tau: 0.6899 - tau_val: 0.5404                                                                                                    \n",
      " epoch: 0040, loss: 0.0108 - val_loss: 0.0188; rmse: 0.1021 - rmse_val: 0.1687;  r2: 0.8586 - r2_val: 0.5989; mae: 0.0719 - mae_val: 0.1227; r: 0.9307 - r_val: 0.7775;tau: 0.6991 - tau_val: 0.5364                                                                                                    \n",
      " epoch: 0041, loss: 0.0101 - val_loss: 0.0198; rmse: 0.0970 - rmse_val: 0.1751;  r2: 0.8724 - r2_val: 0.5678; mae: 0.0689 - mae_val: 0.1274; r: 0.9350 - r_val: 0.7621;tau: 0.7017 - tau_val: 0.5227                                                                                                    \n",
      " epoch: 0042, loss: 0.0103 - val_loss: 0.0192; rmse: 0.0910 - rmse_val: 0.1714;  r2: 0.8879 - r2_val: 0.5859; mae: 0.0638 - mae_val: 0.1232; r: 0.9444 - r_val: 0.7718;tau: 0.7153 - tau_val: 0.5294                                                                                                    \n",
      " epoch: 0043, loss: 0.0096 - val_loss: 0.0193; rmse: 0.0878 - rmse_val: 0.1719;  r2: 0.8955 - r2_val: 0.5836; mae: 0.0632 - mae_val: 0.1248; r: 0.9477 - r_val: 0.7718;tau: 0.7213 - tau_val: 0.5238                                                                                                    \n",
      " epoch: 0044, loss: 0.0095 - val_loss: 0.0199; rmse: 0.0870 - rmse_val: 0.1754;  r2: 0.8974 - r2_val: 0.5663; mae: 0.0615 - mae_val: 0.1260; r: 0.9474 - r_val: 0.7663;tau: 0.7199 - tau_val: 0.5217                                                                                                    \n",
      " epoch: 0045, loss: 0.0092 - val_loss: 0.0201; rmse: 0.0968 - rmse_val: 0.1772;  r2: 0.8730 - r2_val: 0.5575; mae: 0.0675 - mae_val: 0.1259; r: 0.9483 - r_val: 0.7583;tau: 0.7236 - tau_val: 0.5119                                                                                                    \n",
      " epoch: 0046, loss: 0.0092 - val_loss: 0.0202; rmse: 0.0816 - rmse_val: 0.1777;  r2: 0.9098 - r2_val: 0.5549; mae: 0.0603 - mae_val: 0.1298; r: 0.9568 - r_val: 0.7641;tau: 0.7349 - tau_val: 0.5217                                                                                                    \n",
      " epoch: 0047, loss: 0.0085 - val_loss: 0.0196; rmse: 0.0812 - rmse_val: 0.1745;  r2: 0.9107 - r2_val: 0.5709; mae: 0.0579 - mae_val: 0.1277; r: 0.9553 - r_val: 0.7655;tau: 0.7361 - tau_val: 0.5185                                                                                                    \n",
      " epoch: 0048, loss: 0.0086 - val_loss: 0.0196; rmse: 0.0786 - rmse_val: 0.1747;  r2: 0.9162 - r2_val: 0.5699; mae: 0.0578 - mae_val: 0.1267; r: 0.9591 - r_val: 0.7695;tau: 0.7414 - tau_val: 0.5340                                                                                                    \n",
      " epoch: 0049, loss: 0.0080 - val_loss: 0.0201; rmse: 0.0742 - rmse_val: 0.1776;  r2: 0.9253 - r2_val: 0.5558; mae: 0.0542 - mae_val: 0.1280; r: 0.9644 - r_val: 0.7668;tau: 0.7488 - tau_val: 0.5243                                                                                                    \n",
      " epoch: 0050, loss: 0.0078 - val_loss: 0.0196; rmse: 0.0714 - rmse_val: 0.1755;  r2: 0.9310 - r2_val: 0.5660; mae: 0.0512 - mae_val: 0.1263; r: 0.9657 - r_val: 0.7660;tau: 0.7511 - tau_val: 0.5239                                                                                                    \n",
      " epoch: 0051, loss: 0.0074 - val_loss: 0.0210; rmse: 0.0757 - rmse_val: 0.1834;  r2: 0.9222 - r2_val: 0.5259; mae: 0.0550 - mae_val: 0.1313; r: 0.9637 - r_val: 0.7554;tau: 0.7521 - tau_val: 0.5172                                                                                                    \n",
      " epoch: 0052, loss: 0.0072 - val_loss: 0.0201; rmse: 0.0699 - rmse_val: 0.1785;  r2: 0.9338 - r2_val: 0.5511; mae: 0.0494 - mae_val: 0.1265; r: 0.9741 - r_val: 0.7535;tau: 0.7709 - tau_val: 0.5099                                                                                                    \n",
      " epoch: 0053, loss: 0.0068 - val_loss: 0.0206; rmse: 0.0631 - rmse_val: 0.1816;  r2: 0.9460 - r2_val: 0.5356; mae: 0.0448 - mae_val: 0.1288; r: 0.9729 - r_val: 0.7536;tau: 0.7662 - tau_val: 0.5194                                                                                                    \n",
      " epoch: 0054, loss: 0.0066 - val_loss: 0.0195; rmse: 0.0595 - rmse_val: 0.1754;  r2: 0.9520 - r2_val: 0.5664; mae: 0.0425 - mae_val: 0.1259; r: 0.9764 - r_val: 0.7631;tau: 0.7750 - tau_val: 0.5184                                                                                                    \n",
      " epoch: 0055, loss: 0.0065 - val_loss: 0.0199; rmse: 0.0577 - rmse_val: 0.1782;  r2: 0.9549 - r2_val: 0.5528; mae: 0.0410 - mae_val: 0.1261; r: 0.9797 - r_val: 0.7553;tau: 0.7833 - tau_val: 0.5127                                                                                                    \n",
      " epoch: 0056, loss: 0.0064 - val_loss: 0.0200; rmse: 0.0561 - rmse_val: 0.1796;  r2: 0.9574 - r2_val: 0.5457; mae: 0.0400 - mae_val: 0.1295; r: 0.9788 - r_val: 0.7578;tau: 0.7839 - tau_val: 0.5184                                                                                                    \n",
      " epoch: 0057, loss: 0.0065 - val_loss: 0.0206; rmse: 0.0682 - rmse_val: 0.1827;  r2: 0.9370 - r2_val: 0.5298; mae: 0.0495 - mae_val: 0.1315; r: 0.9688 - r_val: 0.7473;tau: 0.7594 - tau_val: 0.5139                                                                                                    \n",
      " epoch: 0058, loss: 0.0066 - val_loss: 0.0197; rmse: 0.0561 - rmse_val: 0.1778;  r2: 0.9573 - r2_val: 0.5544; mae: 0.0399 - mae_val: 0.1263; r: 0.9786 - r_val: 0.7607;tau: 0.7825 - tau_val: 0.5195                                                                                                    \n",
      " epoch: 0059, loss: 0.0062 - val_loss: 0.0209; rmse: 0.0561 - rmse_val: 0.1849;  r2: 0.9573 - r2_val: 0.5184; mae: 0.0413 - mae_val: 0.1310; r: 0.9815 - r_val: 0.7538;tau: 0.7901 - tau_val: 0.5184                                                                                                    \n",
      " epoch: 0060, loss: 0.0058 - val_loss: 0.0201; rmse: 0.0509 - rmse_val: 0.1810;  r2: 0.9648 - r2_val: 0.5384; mae: 0.0370 - mae_val: 0.1291; r: 0.9836 - r_val: 0.7560;tau: 0.7977 - tau_val: 0.5176                                                                                                    \n",
      " epoch: 0061, loss: 0.0055 - val_loss: 0.0197; rmse: 0.0557 - rmse_val: 0.1789;  r2: 0.9580 - r2_val: 0.5492; mae: 0.0403 - mae_val: 0.1265; r: 0.9840 - r_val: 0.7540;tau: 0.7969 - tau_val: 0.5179                                                                                                    \n",
      " epoch: 0062, loss: 0.0056 - val_loss: 0.0204; rmse: 0.0520 - rmse_val: 0.1835;  r2: 0.9634 - r2_val: 0.5257; mae: 0.0382 - mae_val: 0.1284; r: 0.9825 - r_val: 0.7477;tau: 0.7930 - tau_val: 0.5114                                                                                                    \n",
      " epoch: 0063, loss: 0.0056 - val_loss: 0.0205; rmse: 0.0551 - rmse_val: 0.1840;  r2: 0.9589 - r2_val: 0.5232; mae: 0.0421 - mae_val: 0.1324; r: 0.9834 - r_val: 0.7554;tau: 0.7967 - tau_val: 0.5215                                                                                                    \n",
      " epoch: 0064, loss: 0.0054 - val_loss: 0.0212; rmse: 0.0561 - rmse_val: 0.1884;  r2: 0.9574 - r2_val: 0.5000; mae: 0.0424 - mae_val: 0.1348; r: 0.9847 - r_val: 0.7485;tau: 0.8030 - tau_val: 0.5136                                                                                                    \n",
      " epoch: 0065, loss: 0.0053 - val_loss: 0.0200; rmse: 0.0484 - rmse_val: 0.1818;  r2: 0.9683 - r2_val: 0.5343; mae: 0.0349 - mae_val: 0.1286; r: 0.9846 - r_val: 0.7512;tau: 0.7980 - tau_val: 0.5093                                                                                                    \n",
      " epoch: 0066, loss: 0.0050 - val_loss: 0.0202; rmse: 0.0477 - rmse_val: 0.1832;  r2: 0.9691 - r2_val: 0.5272; mae: 0.0342 - mae_val: 0.1286; r: 0.9850 - r_val: 0.7427;tau: 0.7984 - tau_val: 0.5137                                                                                                    \n",
      " epoch: 0067, loss: 0.0050 - val_loss: 0.0196; rmse: 0.0452 - rmse_val: 0.1801;  r2: 0.9723 - r2_val: 0.5430; mae: 0.0327 - mae_val: 0.1276; r: 0.9865 - r_val: 0.7526;tau: 0.8034 - tau_val: 0.5132                                                                                                    \n",
      " epoch: 0068, loss: 0.0050 - val_loss: 0.0208; rmse: 0.0558 - rmse_val: 0.1874;  r2: 0.9578 - r2_val: 0.5051; mae: 0.0411 - mae_val: 0.1330; r: 0.9829 - r_val: 0.7478;tau: 0.7978 - tau_val: 0.5153                                                                                                    \n",
      " epoch: 0069, loss: 0.0051 - val_loss: 0.0199; rmse: 0.0474 - rmse_val: 0.1822;  r2: 0.9695 - r2_val: 0.5324; mae: 0.0346 - mae_val: 0.1280; r: 0.9849 - r_val: 0.7533;tau: 0.8018 - tau_val: 0.5211                                                                                                    \n",
      " epoch: 0070, loss: 0.0051 - val_loss: 0.0215; rmse: 0.0610 - rmse_val: 0.1914;  r2: 0.9496 - r2_val: 0.4839; mae: 0.0462 - mae_val: 0.1394; r: 0.9812 - r_val: 0.7367;tau: 0.7931 - tau_val: 0.4978                                                                                                    \n",
      " epoch: 0071, loss: 0.0052 - val_loss: 0.0198; rmse: 0.0456 - rmse_val: 0.1824;  r2: 0.9718 - r2_val: 0.5314; mae: 0.0327 - mae_val: 0.1300; r: 0.9871 - r_val: 0.7427;tau: 0.8090 - tau_val: 0.5026                                                                                                    \n",
      " epoch: 0072, loss: 0.0048 - val_loss: 0.0198; rmse: 0.0536 - rmse_val: 0.1823;  r2: 0.9611 - r2_val: 0.5318; mae: 0.0384 - mae_val: 0.1282; r: 0.9826 - r_val: 0.7508;tau: 0.7983 - tau_val: 0.5127                                                                                                    \n",
      " epoch: 0073, loss: 0.0048 - val_loss: 0.0195; rmse: 0.0477 - rmse_val: 0.1813;  r2: 0.9692 - r2_val: 0.5371; mae: 0.0342 - mae_val: 0.1285; r: 0.9870 - r_val: 0.7460;tau: 0.8090 - tau_val: 0.4983                                                                                                    \n",
      " epoch: 0074, loss: 0.0048 - val_loss: 0.0200; rmse: 0.0597 - rmse_val: 0.1840;  r2: 0.9517 - r2_val: 0.5230; mae: 0.0433 - mae_val: 0.1284; r: 0.9872 - r_val: 0.7414;tau: 0.8083 - tau_val: 0.5039                                                                                                    \n",
      " epoch: 0075, loss: 0.0048 - val_loss: 0.0200; rmse: 0.0618 - rmse_val: 0.1847;  r2: 0.9483 - r2_val: 0.5195; mae: 0.0470 - mae_val: 0.1296; r: 0.9887 - r_val: 0.7462;tau: 0.8186 - tau_val: 0.5013                                                                                                    \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00075: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "WARNING:root:Found input variables with inconsistent numbers of samples: [33, 33, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************\n"
     ]
    }
   ],
   "source": [
    "class_name = 'class_1'                                                     #here!\n",
    "# Train_dir = '/raid/hly/PK-3[2018PLOS]/data/train_data-MID/'+ class_name +'_pre'     \n",
    "Train_dir = '/raid/hly/PK-4[MHCflurry]/no_mass_spec/data/trainval_MID_otherAllele'\n",
    "Test_dir = '/raid/hly/PK-3[2018PLOS]/data/PK-3_benchmark_data'\n",
    "\n",
    "for file in os.listdir(Test_dir):\n",
    "    \n",
    "    if file not in os.listdir(Train_dir):\n",
    "        continue\n",
    "    Allele = file.split('.')[0]\n",
    "    df_trainval = pd.read_csv(os.path.join(Train_dir,file))\n",
    "    df_test = pd.read_csv(os.path.join(Test_dir,file))  \n",
    "    \n",
    "    # 创建储存 Allele 结果的文件夹\n",
    "    task_dir = '/raid/hly/PK-3[2018PLOS]/no_spec_mass/Res'             \n",
    "    Allele_fold = os.path.join(task_dir,Allele)\n",
    "\n",
    "    if not os.path.exists(Allele_fold) : \n",
    "        os.makedirs(Allele_fold)\n",
    "        os.makedirs(os.path.join(Allele_fold,'loss'))\n",
    "        os.makedirs(os.path.join(Allele_fold,'models'))\n",
    "        os.makedirs(os.path.join(Allele_fold,'results'))\n",
    "        # os.makedirs(os.path.join(Allele_fold,'fig-loss'))\n",
    "        # os.makedirs(os.path.join(Allele_fold,'fig-pfm'))\n",
    "        # os.makedirs(os.path.join(Allele_fold,'fig-pred_true')) \n",
    "\n",
    "    # 获得训练集和测试集的最大序列长度\n",
    "    train_max_seq_len = df_trainval['peptide'].apply(len).max()\n",
    "    test_max_seq_len = df_test['Description'].apply(len).max()\n",
    "    max_seq_len = max(train_max_seq_len,test_max_seq_len)\n",
    "\n",
    "    # 划分训练集与验证集\n",
    "    kf = StratifiedKFold(\n",
    "        n_splits= 10,  \n",
    "        shuffle=True,\n",
    "        random_state= 2)\n",
    "    # y_c = df_trainval['Qualitative Measure']\n",
    "    # for train_idx, valid_idx in kf.split(df_trainval, y_c):\n",
    "    #     df_train = df_trainval.iloc[train_idx]\n",
    "    #     df_valid = df_trainval.iloc[valid_idx]\n",
    "\n",
    "    ### 使用 MHCflurry数据时的划分方式\n",
    "    # Stratify by both allele and binder vs. nonbinder.\n",
    "    df_trainval[\"key\"] = [\n",
    "        \"%s_%s\" % (\n",
    "            row.allele,\n",
    "            \"binder\" if row.measurement_value <= 500 else \"nonbinder\")\n",
    "        for (_, row) in df_trainval.iterrows()\n",
    "    ]\n",
    "    \n",
    "    (train_idx, valid_idx) = next(kf.split(df_trainval, df_trainval.key))\n",
    "    df_train = df_trainval.iloc[train_idx]\n",
    "    df_valid = df_trainval.iloc[valid_idx]\n",
    "    ###  使用 MHCflurry数据时的划分方式\n",
    "\n",
    "    # 生成 X_train + Y_train \n",
    "    X_train_name = os.path.join(Allele_fold, Allele+'_X_train_'+'.data')\n",
    "    if not os.path.exists(X_train_name) :\n",
    "        X_train = []\n",
    "        for seq in df_train['peptide']:\n",
    "            X_train.append(get_3d_feat(seq))\n",
    "        X_train = np.stack(X_train)\n",
    "        dump(X_train, X_train_name)\n",
    "    else:\n",
    "        X_train = load(X_train_name)\n",
    "    X_train = X_train.astype('float32')\n",
    "    Y_train = df_train['Normalized_QM'].values.reshape(-1, 1) \n",
    "\n",
    "    # 生成 X_valid + Y_valid\n",
    "    X_valid_name = os.path.join(Allele_fold, Allele+'_X_valid_'+'.data')\n",
    "    if not os.path.exists(X_valid_name) :\n",
    "        X_valid= []\n",
    "        for seq in df_valid['peptide']:\n",
    "            X_valid.append(get_3d_feat(seq))\n",
    "        X_valid = np.stack(X_valid)\n",
    "        dump(X_valid, X_valid_name)\n",
    "    else:\n",
    "        X_valid = load(X_valid_name)\n",
    "    X_valid = X_valid.astype('float32')\n",
    "    Y_valid = df_valid['Normalized_QM'].values.reshape(-1, 1)     \n",
    "   \n",
    "   # 生成 X_test + Y_test \n",
    "    X_test_name = os.path.join(Allele_fold, Allele+'_X_test_'+'.data')\n",
    "    if not os.path.exists(X_test_name) :\n",
    "        X_test = []\n",
    "        for seq in df_test['Description']:\n",
    "            X_test.append(get_3d_feat(seq))\n",
    "        X_test = np.stack(X_test)\n",
    "        dump(X_test, X_test_name)\n",
    "    else:\n",
    "        X_test = load(X_test_name)\n",
    "    X_test = X_test.astype('float32')\n",
    "    Y_test = df_test['Normalized_QM'].values.reshape(-1, 1) \n",
    "\n",
    "    # 确定参数\n",
    "    ## 公共参数\n",
    "    inc = (1,3,5)\n",
    "    lr = 1e-4\n",
    "    bs = 32\n",
    "    ## 特定参数\n",
    "    if Allele  in ['HLA-A_0202','HLA-A_0201','HLA-A_3002','HLA-A_0203',\n",
    "                'HLA-B_2705','HLA-A_0301','HLA-B_5301','HLA-A_6802','HLA-A_3301']:   \n",
    "        df_res = pd.read_csv('/raid/hly/PK-3[2018PLOS]/R3-res/R3_res.csv',index_col=0)    #here\n",
    "\n",
    "    else : \n",
    "        df_res = pd.read_csv('/raid/hly/PK-3[2018PLOS]/R1-res/results_R1.csv',index_col=0)    #here\n",
    "    \n",
    "    ks_fir = df_res['kernel_size_1'][Allele]\n",
    "    ks_fir = eval(ks_fir)\n",
    "    kn = df_res['kernel_number'][Allele]\n",
    "    kn = eval(kn)\n",
    "    kn_1,kn_2,kn_3 = kn[0],kn[1],kn[2]\n",
    "    lamda = df_res['lamda'][Allele]\n",
    "   \n",
    "   #******************************************\n",
    "    task_name = Allele +'_noMS'\n",
    "\n",
    "    for ks_fir in [ks_fir]:\n",
    "        for lamda in [lamda]:\n",
    "\n",
    "            # continue 情况\n",
    "            df_done = pd.read_csv(os.path.join(task_dir,'done_list.csv'))\n",
    "            exists_name = Allele + '_(lr_%s-bs_%s-lam_%s-ks_[%s,%s]-kn_%s)_' %(lr,bs,lamda,ks_fir,inc,kn)\n",
    "            if (exists_name +'_results.csv') in (df_done['done_file'].values):\n",
    "                continue\n",
    "\n",
    "            # 查看目前最佳 R2\n",
    "            result_file = os.path.join(Allele_fold,'results')\n",
    "            result_csv = result_file + '/' + task_name + '_results.csv'\n",
    "            if os.path.exists(result_csv) :\n",
    "                df_exit_res = pd.read_csv(result_csv)\n",
    "                best_exit_r2 = df_exit_res['test_r2'][0]\n",
    "            else:\n",
    "                best_exit_r2 = -1000\n",
    "\n",
    "            for n in range(2):\n",
    "        \n",
    "                print(exists_name)  \n",
    "                lr = lr\n",
    "                patience = 50\n",
    "                epochs = 300\n",
    "                loss= tf.keras.losses.log_cosh     #weighted_loss #tf.keras.losses.mean_squared_error \n",
    "                batch_size = bs\n",
    "\n",
    "                df_loss = pd.DataFrame()          \n",
    "                results = []\n",
    "\n",
    "                if Allele in ['HLA-A_0202','HLA-A_0201','HLA-A_3002','HLA-A_0203',\n",
    "                'HLA-B_2705','HLA-A_0301','HLA-B_5301','HLA-A_6802','HLA-A_3301']:   \n",
    "                    model = Model_2()\n",
    "                else:\n",
    "                    model = Model_1()\n",
    "\n",
    "                opt = tf.keras.optimizers.Adam(lr=lr)\n",
    "                model.compile(optimizer=opt, loss=loss)\n",
    "\n",
    "                performance = molmap.model.cbks.Reg3D_EarlyStoppingAndPerformance((X_train, Y_train), \n",
    "                                                                (X_valid, Y_valid), \n",
    "                                                            patience = patience,\n",
    "                                                            )\n",
    "\n",
    "                model.fit(X_train, Y_train, batch_size=batch_size, \n",
    "                        epochs = epochs, verbose = 0, shuffle = True, \n",
    "                        validation_data = (X_valid, Y_valid), callbacks = [performance]) \n",
    "                \n",
    "                best_epoch = performance.best_epoch\n",
    "                trainable_params = model.count_params()\n",
    "\n",
    "                #获取RMSE和R2\n",
    "                train_rmse,train_mae,train_r,train_r2,train_tau = performance.evaluate(X_train, Y_train)            \n",
    "                valid_rmse,valid_mae,valid_r,valid_r2,valid_tau = performance.evaluate(X_valid, Y_valid)\n",
    "\n",
    "                # make prediction\n",
    "                Y_test_pred = model.predict(X_test)\n",
    "                df_pred = pd.DataFrame(Y_test_pred.tolist()).rename(columns={0:'Pred_Norm_QM'})\n",
    "                df_pred['Pred_QM'] = df_pred['Pred_Norm_QM'].apply(to_ic50)\n",
    "                df_truepred = pd.merge(df_test,df_pred,how='inner',left_index=True,right_index=True)   \n",
    "\n",
    "                y_true = df_truepred['Normalized_QM']\n",
    "                y_pred = df_truepred['Pred_Norm_QM']\n",
    "                test_r2 = r2_score(y_true, y_pred)   \n",
    "                test_r = PCC(y_true, y_pred)           \n",
    "       \n",
    "                if test_r2 >= best_exit_r2 :\n",
    "\n",
    "                    #储存loss\n",
    "                    dfl = pd.DataFrame(performance.history)\n",
    "                    df_loss = df_loss.append(dfl, ignore_index = True)\n",
    "                    df_loss.to_csv(os.path.join(os.path.join(Allele_fold,'loss'),  task_name +'_loss.csv'))\n",
    "                \n",
    "                    # 储存 prediction\n",
    "                    df_truepred.to_csv(os.path.join(Allele_fold,Allele+'true_pred.csv'))\n",
    "\n",
    "                    # 计算 tau, auc, f1\n",
    "                    test_tau = scipy.stats.kendalltau(y_pred, y_true)[0]\n",
    "\n",
    "                    y_pred_score = from_ic50(y_pred, max_ic50)\n",
    "                    try:\n",
    "                        test_auc = sklearn.metrics.roc_auc_score(\n",
    "                                    y_true <= threshold_nm,\n",
    "                                    y_pred_score,\n",
    "                                    sample_weight=sample_weight)\n",
    "                    except ValueError as e:\n",
    "                        logging.warning(e)\n",
    "                        test_auc = np.nan\n",
    "                    \n",
    "                    try:\n",
    "                        test_f1 = sklearn.metrics.f1_score(\n",
    "                                    y_true <= threshold_nm,\n",
    "                                    y_pred <= threshold_nm,\n",
    "                                    sample_weight=sample_weight)\n",
    "                    except ValueError as e:\n",
    "                        logging.warning(e)\n",
    "                        test_f1 = np.nan\n",
    "\n",
    "                    #整体性结果\n",
    "                    final_res = {\n",
    "                                'train_rmse':np.nanmean(train_rmse), \n",
    "                                'valid_rmse':np.nanmean(valid_rmse),  \n",
    "                                # 'train_mse':np.nanmean(train_mse), \n",
    "                                # 'valid_mse':np.nanmean(test_mse),                      \n",
    "                                'train_r2':np.nanmean(train_r2), \n",
    "                                'valid_r2':np.nanmean(valid_r2), \n",
    "                                'train_mae':np.nanmean(train_mae), \n",
    "                                'valid_mae':np.nanmean(valid_mae),\n",
    "                                'train_r':np.nanmean(train_r), \n",
    "                                'valid_r':np.nanmean(valid_r),\n",
    "                                'train_tau':np.nanmean(train_tau), \n",
    "                                'valid_tau':np.nanmean(valid_tau),\n",
    "                                # 'train_auc':np.nanmean(train_auc), \n",
    "                                # 'valid_auc':np.nanmean(valid_auc),\n",
    "                                'test_r2':np.nanmean(test_r2),\n",
    "                                'test_r':np.nanmean(test_r),\n",
    "                                'test_tau':np.nanmean(test_tau),\n",
    "                                'test_auc':np.nanmean(test_auc),\n",
    "                                'test_f1' : np.nanmean(test_f1),\n",
    "                                'trainable params': trainable_params, \n",
    "                                'best_epoch': best_epoch,\n",
    "                                'lr' : lr,\n",
    "                                'batch_size':bs,\n",
    "                                'kernel_size_1':ks_fir,\n",
    "                                'kernel_size_incept': inc,\n",
    "                                'kernel_number':kn,\n",
    "                                'lamda' : lamda\n",
    "                                }\n",
    "\n",
    "                    results.append(final_res)\n",
    "                    dfr = pd.DataFrame(results)\n",
    "                    dfr.to_csv(os.path.join(os.path.join(Allele_fold,'results'),  task_name +'_results.csv'))\n",
    "                    \n",
    "                    # 保存模型\n",
    "                    model.save_weights(os.path.join(os.path.join(Allele_fold,'models'),  task_name +'_model_'+'.h5'))\n",
    "                    \n",
    "                    # 删除model\n",
    "                    del model\n",
    "\n",
    "                print('*******************************************************')\n",
    "         \n",
    "\n",
    "            df_done = pd.read_csv(os.path.join(task_dir,'done_list.csv'))  \n",
    "            new_donels = df_done['done_file'].append(pd.Series(exists_name +'_results.csv'))\n",
    "            df_newdone = pd.DataFrame(new_donels,columns=['done_file'])\n",
    "            df_newdone.to_csv(os.path.join(task_dir,'done_list.csv'))\n",
    "    \n",
    "    \n",
    "    # # 删除缓存\n",
    "    # del performance\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    tf.compat.v1.reset_default_graph() # TF graph isn't same as Keras grap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HLA-B_1501'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Allele"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaccin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "616f56fef8ea7183d51ad2039e0213a0ade719c1a48fd338f6185e7423826c67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
