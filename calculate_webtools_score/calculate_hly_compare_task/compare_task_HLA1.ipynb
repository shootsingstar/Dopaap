{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def PCC_score(y_pred,y_true):\n",
    "    diff_pred,diff_true=y_pred-np.mean(y_pred),y_true-np.mean(y_true)\n",
    "    return np.sum(diff_pred*diff_true)/np.sqrt(np.sum(diff_pred**2)*np.sum(diff_true**2))\n",
    "\n",
    "## 引用 MHC_flurry 文献的标准化代码\n",
    "def from_ic50_limit_1(ic50, max_ic50=50000.0):\n",
    "    \"\"\"\n",
    "    Convert ic50s to regression targets in the range [0.0, 1.0].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ic50 : numpy.array of float\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.array of float\n",
    "    \"\"\"\n",
    "    x = 1.0 - (np.log(np.maximum(ic50, 1)) / np.log(max_ic50))\n",
    "    \n",
    "    return np.minimum(\n",
    "        1.0,\n",
    "        np.maximum(0.0, x))\n",
    "\n",
    "def to_ic50(x, max_ic50=50000.0):\n",
    "    return max_ic50 ** (1.0 - x)\n",
    "\n",
    "def from_ic50_without_limit(ic50):\n",
    "    x = 1.0 - (np.log(ic50))/np.log(50000)\n",
    "    return x\n",
    "\n",
    "\n",
    "def nmol_to_mol(ic50_nm):\n",
    "    return ic50_nm * 1e-9\n",
    "\n",
    "def negative_log10_ic50_mol(ic50_mol):\n",
    "    x = -np.log10(ic50_mol)\n",
    "    return x\n",
    "\n",
    "def negative_log10_ic50_from_nm(ic50_nm):\n",
    "    return negative_log10_ic50_mol(nmol_to_mol(ic50_nm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试函数功能正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_ic50_without_limit(0.17)\n",
    "to_ic50(from_ic50_without_limit(0.17))\n",
    "to_ic50(from_ic50_limit_1(0.17))\n",
    "negative_log10_ic50_mol(1)\n",
    "negative_log10_ic50_from_nm(1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new data net mhc pan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HLA_B_0702 r2: -0.018897350257493395 PCC 0.6168394394433353 tau 0.46798029556650234\n",
      "HLA_A_3301 r2: 0.8845057226464234 PCC 0.9862749175059198 tau 0.6666666666666669\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/raid/zt/MHC_IC50_regression/calculate_hly_compare_task/HLA-A_4403_netMHCpan.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3081209/493244173.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HLA_A_3301'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r2:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PCC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tau'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHLA_B_4403\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'netmhcpan_n'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'netmhcpan'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_ic50_without_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHLA_B_4403\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/molmap/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/molmap/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/molmap/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/molmap/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/molmap/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/raid/zt/MHC_IC50_regression/calculate_hly_compare_task/HLA-A_4403_netMHCpan.csv'"
     ]
    }
   ],
   "source": [
    "HLA_B_0702 = '/mnt/zt/Dopaap/calculate_webtools_score/calculate_hly_compare_task/HLA-B_0702_netMHCpan.csv'\n",
    "HLA_A_3301 = '/mnt/zt/Dopaap/calculate_webtools_score/calculate_hly_compare_task/HLA-A_3301_netMHCpan.csv'\n",
    "HLA_B_4403 = '/mnt/zt/Dopaap/calculate_webtools_score/calculate_hly_compare_task/HLA-B_4403_netMHCpan.csv'\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(HLA_B_0702)\n",
    "df['netmhcpan_n'] = df['netmhcpan'].apply(from_ic50_without_limit)\n",
    "df.to_csv(HLA_B_0702, index=0)\n",
    "r2 = r2_score(df['Normalized_QM'].to_list(), df['netmhcpan_n'].to_list())\n",
    "PCC = PCC_score(df['Normalized_QM'].to_list(), df['netmhcpan_n'].to_list())\n",
    "tau = scipy.stats.kendalltau(df['Normalized_QM'].to_list(), df['netmhcpan_n'].to_list())[0]\n",
    "print('HLA_B_0702','r2:', r2, 'PCC', PCC, 'tau', tau)\n",
    "\n",
    "df = pd.read_csv(HLA_A_3301)\n",
    "df['netmhcpan_n'] = df['netmhcpan'].apply(from_ic50_without_limit)\n",
    "df.to_csv(HLA_A_3301, index=0)\n",
    "r2 = r2_score(df['Normalized_QM'].to_list(), df['netmhcpan_n'].to_list())\n",
    "PCC = PCC_score(df['Normalized_QM'].to_list(), df['netmhcpan_n'].to_list())\n",
    "tau = scipy.stats.kendalltau(df['Normalized_QM'].to_list(), df['netmhcpan_n'].to_list())[0]\n",
    "print('HLA_A_3301','r2:', r2, 'PCC', PCC, 'tau', tau)\n",
    "\n",
    "df = pd.read_csv(HLA_B_4403)\n",
    "df['netmhcpan_n'] = df['netmhcpan'].apply(from_ic50_without_limit)\n",
    "df.to_csv(HLA_B_4403, index=0)\n",
    "r2 = r2_score(df['Normalized_QM'].to_list(), df['netmhcpan_n'].to_list())\n",
    "PCC = PCC_score(df['Normalized_QM'].to_list(), df['netmhcpan_n'].to_list())\n",
    "tau = scipy.stats.kendalltau(df['Normalized_QM'].to_list(), df['netmhcpan_n'].to_list())[0]\n",
    "print('HLA_B_4403','r2:', r2, 'PCC', PCC, 'tau', tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_allele_for_NMp = '/mnt/zt/Dopaap/calculate_webtools_score/calculate_hly_compare_task/cal_peptide_prediction_lasted.csv'\n",
    "except_b2706_for_not_full = '/mnt/zt/Dopaap/calculate_webtools_score/calculate_hly_compare_task/cal_not_full.csv'\n",
    "our_limit_1 = '/mnt/zt/Dopaap/calculate_webtools_score/calculate_hly_compare_task/PK3-predresults_noMS_V1.csv'\n",
    "\n",
    "\n",
    "df_full = pd.read_csv(full_allele_for_NMp)\n",
    "df_not_full = pd.read_csv(except_b2706_for_not_full)\n",
    "df_our_limit = pd.read_csv(our_limit_1)\n",
    "\n",
    "\n",
    "# 数据处理  \n",
    "# N1:对以nmol为单位的ic50值进行限制[0, 1]范围的MHC_flurry标准化\n",
    "# N2:对以nmol为单位的ic50值进行不限制范围的MHC_flurry标准化\n",
    "# n_log10:把ic50值转化为mol为单位后, 取以10为底的负对数\n",
    "df_full['QM_N1'] = df_full['QM'].apply(from_ic50_limit_1)\n",
    "df_full['QM_N2'] = df_full['QM'].apply(from_ic50_without_limit)\n",
    "\n",
    "df_full['NetMHCpan_N1'] = df_full['NetMHCpan'].apply(from_ic50_limit_1)\n",
    "df_full['NetMHCpan_N2'] = df_full['NetMHCpan'].apply(from_ic50_without_limit)\n",
    "\n",
    "df_full['QM_n_log10'] = df_full['QM'].apply(negative_log10_ic50_from_nm)\n",
    "df_full['pred_QM_n_log10'] = df_full['pred_QM'].apply(negative_log10_ic50_from_nm)\n",
    "df_full['NetMHCpan_n_log10'] = df_full['NetMHCpan'].apply(negative_log10_ic50_from_nm)\n",
    "\n",
    "df_not_full['QM_N1'] = df_not_full['QM'].apply(from_ic50_limit_1)\n",
    "df_not_full['QM_N2'] = df_not_full['QM'].apply(from_ic50_without_limit)\n",
    "\n",
    "df_not_full['SMM_N1'] = df_not_full['SMM'].apply(from_ic50_limit_1)\n",
    "df_not_full['SMM_N2'] = df_not_full['SMM'].apply(from_ic50_without_limit)\n",
    "df_not_full['SMMPMBEC_N1'] = df_not_full['SMMPMBEC'].apply(from_ic50_limit_1)\n",
    "df_not_full['SMMPMBEC_N2'] = df_not_full['SMMPMBEC'].apply(from_ic50_without_limit)\n",
    "df_not_full['ANN4_N1'] = df_not_full['ANN4'].apply(from_ic50_limit_1)\n",
    "df_not_full['ANN4_N2'] = df_not_full['ANN4'].apply(from_ic50_without_limit)\n",
    "df_not_full['NetMHCpan_N1'] = df_not_full['NetMHCpan'].apply(from_ic50_limit_1)\n",
    "df_not_full['NetMHCpan_N2'] = df_not_full['NetMHCpan'].apply(from_ic50_without_limit)\n",
    "\n",
    "df_not_full['QM_n_log10'] = df_not_full['QM'].apply(negative_log10_ic50_from_nm)\n",
    "df_not_full['pred_QM_n_log10'] = df_not_full['pred_QM'].apply(negative_log10_ic50_from_nm)\n",
    "df_not_full['SMM_n_log10'] = df_not_full['SMM'].apply(negative_log10_ic50_from_nm)\n",
    "df_not_full['SMMPMBEC_n_log10'] = df_not_full['SMMPMBEC'].apply(negative_log10_ic50_from_nm)\n",
    "df_not_full['ANN4_n_log10'] = df_not_full['ANN4'].apply(negative_log10_ic50_from_nm)\n",
    "df_not_full['NetMHCpan_n_log10'] = df_not_full['NetMHCpan'].apply(negative_log10_ic50_from_nm)\n",
    "\n",
    "df_our_limit['QM_N1'] = df_our_limit['QM'].apply(from_ic50_limit_1)\n",
    "df_our_limit['QM_N2'] = df_our_limit['QM'].apply(from_ic50_without_limit)\n",
    "df_our_limit['QM_n_log10'] = df_our_limit['QM'].apply(negative_log10_ic50_from_nm)\n",
    "df_our_limit['pred_QM_n_log10'] = df_our_limit['pred_QM'].apply(negative_log10_ic50_from_nm)\n",
    "\n",
    "\n",
    "\n",
    "# 保存文件\n",
    "df_full.to_csv(full_allele_for_NMp, index=0)\n",
    "df_not_full.to_csv(except_b2706_for_not_full, index=0)\n",
    "df_our_limit.to_csv(our_limit_1, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_result(y_true, tool_name_list, tool_data_list):\n",
    "    for i in range(len(tool_data_list)):\n",
    "        MAE = mean_absolute_error(y_true, tool_data_list[i])\n",
    "        MSE = mean_squared_error(y_true, tool_data_list[i])\n",
    "        RMSE = np.sqrt(MSE)\n",
    "        r2 = r2_score(y_true, tool_data_list[i])\n",
    "        PCC = PCC_score(y_true, tool_data_list[i])\n",
    "        tau = scipy.stats.kendalltau(y_true, tool_data_list[i])[0]\n",
    "        print(f'{tool_name_list[i]}', 'MAE', MAE, 'MSE', MSE, 'RMSE', RMSE, 'r2:', r2, 'PCC', PCC, 'tau', tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验测定值直接计算, 单位为nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实验测定值直接计算, 单位为nm\n",
      "\n",
      "无allele hla-b_2706\n",
      "Dopaap MAE 2850.1412234948834 MSE 45383677.092442185 RMSE 6736.740836075126 r2: 0.5748218906780134 PCC 0.7749167409409363 tau 0.7158811254065496\n",
      "SMM MAE 31082.787356096807 MSE 65695367353.18124 RMSE 256311.07536191493 r2: -614.468685482309 PCC 0.1056776602228501 tau 0.5067720774780522\n",
      "SMMP MAE 26341.40396231995 MSE 30830660489.643353 RMSE 175586.61819638577 r2: -287.8378107713449 PCC 0.10485235069329991 tau 0.5078549695074709\n",
      "ANN MAE 6882.010587463557 MSE 148605151.56519273 RMSE 12190.371264452642 r2: -0.39221106410784845 PCC 0.3068478634844825 tau 0.5134061726883399\n",
      "NetMHC MAE 6201.2432434402335 MSE 126557509.84004578 RMSE 11249.778212926945 r2: -0.18565718341166249 PCC 0.3594925225357332 tau 0.542462066925058\n",
      "\n",
      "全32allele, dopaap_pred from test in train 未限制0-1 进行还原\n",
      "Dopaap MAE 2862.1719058978633 MSE 45796650.89126619 RMSE 6767.322283685489 r2: 0.5727720809500537 PCC 0.7740399922814678 tau 0.7200882841133374\n",
      "NetMHC MAE 6168.231581181464 MSE 124965023.36979364 RMSE 11178.77557560727 r2: -0.16577404350077685 PCC 0.36641794388660215 tau 0.5439261781490496\n",
      "\n",
      "our最新数据  限制0-1还原\n",
      "Dopaap MAE 5035.659489750371 MSE 106162814.50031403 RMSE 10303.534078184728 r2: 0.009628052777450158 PCC 0.3722390810235512 tau 0.5425721075426336\n"
     ]
    }
   ],
   "source": [
    "print('实验测定值直接计算, 单位为nm')\n",
    "# 无allele hla-b_2706\n",
    "QM_not_full = df_not_full['QM'].to_list()\n",
    "SMM = df_not_full[\"SMM\"].to_list()\n",
    "SMMP = df_not_full[\"SMMPMBEC\"].to_list()\n",
    "ANN = df_not_full[\"ANN4\"].to_list()\n",
    "NetMHC_less = df_not_full[\"NetMHCpan\"].to_list()\n",
    "pred_QM_less = df_not_full[\"pred_QM\"].to_list()\n",
    "\n",
    "tool_name_list = ['Dopaap', 'SMM', 'SMMP', 'ANN', 'NetMHC']\n",
    "tool_data_list = [pred_QM_less, SMM, SMMP, ANN, NetMHC_less]\n",
    "print('\\n无allele hla-b_2706')\n",
    "output_result(QM_not_full, tool_name_list, tool_data_list)\n",
    "\n",
    "# 全32allele, dopaap_pred from test in train 未限制0-1 进行还原\n",
    "QM_full = df_full['QM'].to_list()\n",
    "NetMHC_full = df_full[\"NetMHCpan\"].to_list()\n",
    "pred_QM_nl = df_full[\"pred_QM\"].to_list() # not limit\n",
    "\n",
    "tool_name_list = ['Dopaap', 'NetMHC']\n",
    "tool_data_list = [pred_QM_nl, NetMHC_full]\n",
    "print('\\n全32allele, dopaap_pred from test in train 未限制0-1 进行还原')\n",
    "output_result(QM_full, tool_name_list, tool_data_list)\n",
    "\n",
    "\n",
    "# our最新数据  限制0-1还原\n",
    "QM_our = df_our_limit['QM'].to_list()\n",
    "pred_QM = df_our_limit[\"pred_QM\"].to_list()\n",
    "\n",
    "tool_name_list = ['Dopaap']\n",
    "tool_data_list = [pred_QM]\n",
    "print('\\nour最新数据  限制0-1还原')\n",
    "output_result(QM_our, tool_name_list, tool_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-log50000(x), 限制[0,1]范围计算, x单位为nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-log50000(x), 限制[0,1]范围计算, x单位为nm\n",
      "\n",
      "无allele hla-b_2706\n",
      "Dopaap MAE 0.09371570394531967 MSE 0.020644547534760742 RMSE 0.14368210582658072 r2: 0.854101991067867 PCC 0.9278127280270093 tau 0.7592334801067653\n",
      "SMM MAE 0.2283125108278742 MSE 0.07722406398245796 RMSE 0.27789218049894454 r2: 0.4542463496612139 PCC 0.7265512881383963 tau 0.5257592591462927\n",
      "SMMP MAE 0.22761350578206652 MSE 0.07635124616267203 RMSE 0.27631729255092236 r2: 0.4604146796695532 PCC 0.7290190235942223 tau 0.5273712552742171\n",
      "ANN MAE 0.2048430274902422 MSE 0.06524295155821878 RMSE 0.25542699849119077 r2: 0.5389186072897847 PCC 0.7734683358127291 tau 0.533803975080695\n",
      "NetMHC MAE 0.19140161353171745 MSE 0.05731503776049783 RMSE 0.2394055925840034 r2: 0.5949463228948619 PCC 0.8064709866232317 tau 0.5659402339057924\n",
      "\n",
      "全32allele, dopaap_pred from test in train 未限制0-1 进行还原\n",
      "Dopaap MAE 0.09230821340791 MSE 0.020189597897413623 RMSE 0.14209010485397505 r2: 0.8560796449404279 PCC 0.9286744697039431 tau 0.7609647682173719\n",
      "NetMHC MAE 0.18803075623143717 MSE 0.055903860175284474 RMSE 0.23643997161073352 r2: 0.6014926376191818 PCC 0.8086855987513513 tau 0.5659938823493381\n",
      "\n",
      "our最新数据  限制0-1还原\n",
      "Dopaap MAE 0.199762838653475 MSE 0.061964011604568985 RMSE 0.2489257150327563 r2: 0.5582932064146044 PCC 0.7706654878197465 tau 0.5703318410804444\n"
     ]
    }
   ],
   "source": [
    "print('1-log50000(x), 限制[0,1]范围计算, x单位为nm')\n",
    "# 无allele hla-b_2706\n",
    "QM_not_full = df_not_full['QM_N1'].to_list()\n",
    "SMM = df_not_full[\"SMM_N1\"].to_list()\n",
    "SMMP = df_not_full[\"SMMPMBEC_N1\"].to_list()\n",
    "ANN = df_not_full[\"ANN4_N1\"].to_list()\n",
    "NetMHC_less = df_not_full[\"NetMHCpan_N1\"].to_list()\n",
    "pred_QM_less = df_not_full[\"P_N_QM\"].to_list()\n",
    "\n",
    "tool_name_list = ['Dopaap', 'SMM', 'SMMP', 'ANN', 'NetMHC']\n",
    "tool_data_list = [pred_QM_less, SMM, SMMP, ANN, NetMHC_less]\n",
    "print('\\n无allele hla-b_2706')\n",
    "output_result(QM_not_full, tool_name_list, tool_data_list)\n",
    "\n",
    "# 全32allele, dopaap_pred from test in train 未限制0-1 进行还原\n",
    "QM_full = df_full['QM_N1'].to_list()\n",
    "NetMHC_full = df_full[\"NetMHCpan_N1\"].to_list()\n",
    "pred_QM_nl = df_full[\"P_N_QM\"].to_list() # not limit\n",
    "\n",
    "tool_name_list = ['Dopaap', 'NetMHC']\n",
    "tool_data_list = [pred_QM_nl, NetMHC_full]\n",
    "print('\\n全32allele, dopaap_pred from test in train 未限制0-1 进行还原')\n",
    "output_result(QM_full, tool_name_list, tool_data_list)\n",
    "\n",
    "\n",
    "# our最新数据  限制0-1还原\n",
    "QM_our = df_our_limit['QM_N1'].to_list()\n",
    "pred_QM = df_our_limit[\"P_N_QM\"].to_list()\n",
    "\n",
    "tool_name_list = ['Dopaap']\n",
    "tool_data_list = [pred_QM]\n",
    "print('\\nour最新数据  限制0-1还原')\n",
    "output_result(QM_our, tool_name_list, tool_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-log50000(x), 不限制[0,1]范围计算, x单位为nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-log50000(x), 不限制[0,1]范围计算, x单位为nm\n",
      "\n",
      "无allele hla-b_2706\n",
      "Dopaap MAE 0.1257235483156042 MSE 0.03234000826213124 RMSE 0.1798332790729548 r2: 0.8177834154518069 PCC 0.9259041737033104 tau 0.7158811254065496\n",
      "SMM MAE 0.2707505817124533 MSE 0.10561227027632318 RMSE 0.3249804152196301 r2: 0.4049380872092563 PCC 0.7236010436112371 tau 0.5067720774780522\n",
      "SMMP MAE 0.269591505903248 MSE 0.10432769691107459 RMSE 0.32299798282818204 r2: 0.41217588904653246 PCC 0.7264938598816544 tau 0.5078549695074709\n",
      "ANN MAE 0.23950318384877983 MSE 0.08516079420134168 RMSE 0.291823224232311 r2: 0.5201699105639801 PCC 0.7827929436921278 tau 0.5134061726883399\n",
      "NetMHC MAE 0.2260617698902551 MSE 0.0770018437918941 RMSE 0.2774920607727257 r2: 0.5661407113460095 PCC 0.813599102322912 tau 0.542462066925058\n",
      "\n",
      "全32allele, dopaap_pred from test in train 未限制0-1 进行还原\n",
      "Dopaap MAE 0.12337631561946315 MSE 0.03154168287650972 RMSE 0.1775997828729239 r2: 0.8205868130742409 PCC 0.9267464307879215 tau 0.7200882841133374\n",
      "NetMHC MAE 0.22167329922677761 MSE 0.07501266659557147 RMSE 0.2738844037099803 r2: 0.5733182143006774 PCC 0.8156551993499032 tau 0.5439261781490496\n",
      "\n",
      "our最新数据  限制0-1还原\n",
      "Dopaap MAE 0.232731333898748 MSE 0.08438429336194248 RMSE 0.29048974742999534 r2: 0.5200111846340529 PCC 0.7738105784931584 tau 0.5425721075426336\n"
     ]
    }
   ],
   "source": [
    "print('1-log50000(x), 不限制[0,1]范围计算, x单位为nm')\n",
    "# 无allele hla-b_2706\n",
    "QM_not_full = df_not_full['QM_N2'].to_list()\n",
    "SMM = df_not_full[\"SMM_N2\"].to_list()\n",
    "SMMP = df_not_full[\"SMMPMBEC_N2\"].to_list()\n",
    "ANN = df_not_full[\"ANN4_N2\"].to_list()\n",
    "NetMHC_less = df_not_full[\"NetMHCpan_N2\"].to_list()\n",
    "pred_QM_less = df_not_full[\"P_N_QM\"].to_list()\n",
    "\n",
    "tool_name_list = ['Dopaap', 'SMM', 'SMMP', 'ANN', 'NetMHC']\n",
    "tool_data_list = [pred_QM_less, SMM, SMMP, ANN, NetMHC_less]\n",
    "print('\\n无allele hla-b_2706')\n",
    "output_result(QM_not_full, tool_name_list, tool_data_list)\n",
    "\n",
    "# 全32allele, dopaap_pred from test in train 未限制0-1 进行还原\n",
    "QM_full = df_full['QM_N2'].to_list()\n",
    "NetMHC_full = df_full[\"NetMHCpan_N2\"].to_list()\n",
    "pred_QM_nl = df_full[\"P_N_QM\"].to_list() # not limit\n",
    "\n",
    "tool_name_list = ['Dopaap', 'NetMHC']\n",
    "tool_data_list = [pred_QM_nl, NetMHC_full]\n",
    "print('\\n全32allele, dopaap_pred from test in train 未限制0-1 进行还原')\n",
    "output_result(QM_full, tool_name_list, tool_data_list)\n",
    "\n",
    "\n",
    "# our最新数据  限制0-1还原\n",
    "QM_our = df_our_limit['QM_N2'].to_list()\n",
    "pred_QM = df_our_limit[\"P_N_QM\"].to_list()\n",
    "\n",
    "tool_name_list = ['Dopaap']\n",
    "tool_data_list = [pred_QM]\n",
    "print('\\nour最新数据  限制0-1还原')\n",
    "output_result(QM_our, tool_name_list, tool_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-log10(x)计算, x单位为mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-log10(x)计算, x单位为mol\n",
      "\n",
      "无allele hla-b_2706\n",
      "Dopaap MAE 0.5907711823733203 MSE 0.7140777021796086 RMSE 0.8450311841462471 r2: 0.8177834154513565 PCC 0.9259041737031188 tau 0.7158811254065496\n",
      "SMM MAE 1.2722488621233465 MSE 2.331952628750883 RMSE 1.5270732231137063 r2: 0.4049380872092563 PCC 0.7236010436112369 tau 0.5067720774780522\n",
      "SMMP MAE 1.2668023996631392 MSE 2.3035888389367147 RMSE 1.517757832770668 r2: 0.41217588904653224 PCC 0.7264938598816545 tau 0.5078549695074709\n",
      "ANN MAE 1.1254182768483914 MSE 1.8803775109155387 RMSE 1.3712685772362534 r2: 0.5201699105639801 PCC 0.7827929436921279 tau 0.5134061726883399\n",
      "NetMHC MAE 1.06225747584142 MSE 1.7002252823404014 RMSE 1.3039268700124258 r2: 0.5661407113460095 PCC 0.8135991023229121 tau 0.542462066925058\n",
      "\n",
      "全32allele, dopaap_pred from test in train 未限制0-1 进行还原\n",
      "Dopaap MAE 0.5797416063407521 MSE 0.6964504229179344 RMSE 0.8345360524973947 r2: 0.8205868130738387 PCC 0.9267464307877648 tau 0.7200882841133374\n",
      "NetMHC MAE 1.0416361838288306 MSE 1.6563036150958734 RMSE 1.2869745976886542 r2: 0.5733182143006774 PCC 0.8156551993499032 tau 0.5439261781490496\n",
      "\n",
      "our最新数据  限制0-1还原\n",
      "Dopaap MAE 1.0935975570559464 MSE 1.8632321245976204 RMSE 1.3650026097402232 r2: 0.520011184634384 PCC 0.7738105784977853 tau 0.5425721075426336\n"
     ]
    }
   ],
   "source": [
    "print('-log10(x)计算, x单位为mol')\n",
    "# 无allele hla-b_2706\n",
    "QM_not_full = df_not_full['QM_n_log10'].to_list()\n",
    "SMM = df_not_full[\"SMM_n_log10\"].to_list()\n",
    "SMMP = df_not_full[\"SMMPMBEC_n_log10\"].to_list()\n",
    "ANN = df_not_full[\"ANN4_n_log10\"].to_list()\n",
    "NetMHC_less = df_not_full[\"NetMHCpan_n_log10\"].to_list()\n",
    "pred_QM_less = df_not_full[\"pred_QM_n_log10\"].to_list()\n",
    "\n",
    "tool_name_list = ['Dopaap', 'SMM', 'SMMP', 'ANN', 'NetMHC']\n",
    "tool_data_list = [pred_QM_less, SMM, SMMP, ANN, NetMHC_less]\n",
    "print('\\n无allele hla-b_2706')\n",
    "output_result(QM_not_full, tool_name_list, tool_data_list)\n",
    "\n",
    "# 全32allele, dopaap_pred from test in train 未限制0-1 进行还原\n",
    "QM_full = df_full['QM_n_log10'].to_list()\n",
    "NetMHC_full = df_full[\"NetMHCpan_n_log10\"].to_list()\n",
    "pred_QM_nl = df_full[\"pred_QM_n_log10\"].to_list() # not limit\n",
    "\n",
    "tool_name_list = ['Dopaap', 'NetMHC']\n",
    "tool_data_list = [pred_QM_nl, NetMHC_full]\n",
    "print('\\n全32allele, dopaap_pred from test in train 未限制0-1 进行还原')\n",
    "output_result(QM_full, tool_name_list, tool_data_list)\n",
    "\n",
    "\n",
    "# our最新数据  限制0-1还原\n",
    "QM_our = df_our_limit['QM_n_log10'].to_list()\n",
    "pred_QM = df_our_limit[\"pred_QM_n_log10\"].to_list()\n",
    "\n",
    "tool_name_list = ['Dopaap']\n",
    "tool_data_list = [pred_QM]\n",
    "print('\\nour最新数据  限制0-1还原')\n",
    "output_result(QM_our, tool_name_list, tool_data_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
