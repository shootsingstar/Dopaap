{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取所需要的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_ls = ['Description',\n",
    " 'Qualitative Measure',\n",
    " 'Measurement Inequality',\n",
    " 'Quantitative measurement',\n",
    " 'Units',\n",
    " 'Allele Name',\n",
    " 'MHC allele class',\n",
    " 'Type',\n",
    " 'Date',\n",
    " 'Title',\n",
    " 'Method/Technique',\n",
    " 'Assay Group',\n",
    " 'Name']\n",
    "\n",
    "new_columns_ls = ['Description',\n",
    " 'Qualitative Measure',\n",
    " 'Measurement Inequality',\n",
    " 'Quantitative measurement',\n",
    " 'Units',\n",
    " 'Allele Name',\n",
    " 'MHC allele class',\n",
    " 'Ref Type',\n",
    " 'Ref Date',\n",
    " 'Ref Title',\n",
    " 'Assay Method/Technique',\n",
    " 'Assay Group',\n",
    " 'Host Name']\n",
    "\n",
    " # 输入与输出路径\n",
    "IEDB_origin = '/raid/hly/PK-panAllele/data/mhc_ligand_full.csv' \n",
    "IEDB_ori_need = '/raid/hly/PK-panAllele/data/IEDB2022_need.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/hly/CODE/miniconda3/envs/vaccin/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (5,14,15,16,17,18,19,20,21,22,23,24,25,26,29,30,31,32,33,34,35,36,37,38,41,42,43,44,45,46,47,48,49,50,53,54,55,56,57,58,59,60,61,62,63,64,65,68,69,70,71,72,73,74,75,76,77,78,81,84,89,90,91,92,93,94,97,99) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(IEDB_origin,header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取原始文件中需要的标签。存至“IEDB_ori_need_Data”\n",
    "df_need = df[columns_ls]\n",
    "df_need.columns = [new_columns_ls]\n",
    "df_need.to_csv(IEDB_ori_need,index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "删除不需要的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取文件\n",
    "df_all = pd.read_csv('/raid/hly/PK-panAllele/data/IEDB2022_need.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选出host为人类的条目--Homo sapiens (human) or human（Homo sapiens）\n",
    "df_host = df_all[(df_all['Host Name'] == 'Homo sapiens (human)') | (df_all['Host Name'] =='human (Homo sapiens)') ]\n",
    "\n",
    "# 筛选出有measurement标签的数值\n",
    "df_QM = df_host[pd.notnull(df_host['Quantitative measurement'])]\n",
    "\n",
    "#保留规范化的多肽序列（不含符号且不含'BXJZ'）\n",
    "    # 删除seq含'-'或' '的行\n",
    "df1 = df_QM.drop(index=(df_QM.loc[(df_QM['Description'].str.contains('-'))].index))\n",
    "df2 = df1.drop(index=(df1.loc[(df1['Description'].str.contains(' '))].index))\n",
    "    # 删除seq含'BXJZ'的行\n",
    "df3 = df2.drop(index=(df2.loc[(df2['Description'].str.contains('B'))].index))\n",
    "df4 = df3.drop(index=(df3.loc[(df3['Description'].str.contains('X'))].index))\n",
    "df5 = df4.drop(index=(df4.loc[(df4['Description'].str.contains('J'))].index))\n",
    "df6 = df5.drop(index=(df5.loc[(df5['Description'].str.contains('Z'))].index))\n",
    "\n",
    "# 筛选出精确的allele name（含'HLA'，'：'） \n",
    "df_QM = df6.loc[(df6['Allele Name'].str.contains('HLA'))]\n",
    "df_QM = df_QM.loc[(df_QM['Allele Name'].str.contains(\":\"))]\n",
    "\n",
    "# 删去assay group 不为 “KD”及 “IC50”，“EC50”相关的条目\n",
    "    #删去 assay group为 3D structure 的条目\n",
    "df_assay_1 = df_QM.drop(index=(df_QM.loc[(df_QM['Assay Group']== '3D structure' )].index))\n",
    "    #删去 assay group为 50% dissociation temperature 的条目\n",
    "df_assay_2 = df_assay_1.drop(index=(df_assay_1.loc[(df_assay_1['Assay Group']== '50% dissociation temperature' )].index))\n",
    "    #删去 assay group为 half life 的条目\n",
    "df_assay_3 = df_assay_2.drop(index=(df_assay_2.loc[(df_assay_2['Assay Group']== 'half life' )].index))\n",
    "     #删去 assay group为 off rate 的条目\n",
    "df_assay_4 = df_assay_3.drop(index=(df_assay_3.loc[(df_assay_3['Assay Group']== 'off rate' )].index))\n",
    "    #删去 assay group为 on rate 的条目\n",
    "df_assay_5 = df_assay_4.drop(index=(df_assay_4.loc[(df_assay_4['Assay Group']== 'on rate' )].index))\n",
    "    #删去 assay group为 qualitative binding 的条目\n",
    "df_assay_6 = df_assay_5.drop(index=(df_assay_5.loc[(df_assay_5['Assay Group']== 'qualitative binding' )].index))\n",
    "\n",
    "# 删去'Measurement Inequality'为'>','<','>=','<='的行\n",
    "df_MI_1 = df_assay_6.drop(index=(df_assay_6.loc[(df_assay_6['Measurement Inequality']== '>' )].index))\n",
    "df_MI_2 = df_MI_1.drop(index=(df_MI_1.loc[(df_MI_1['Measurement Inequality']== '<' )].index))\n",
    "df_MI_3 = df_MI_2.drop(index=(df_MI_2.loc[(df_MI_2['Measurement Inequality']== '>=' )].index))\n",
    "df_MI_4 = df_MI_3.drop(index=(df_MI_3.loc[(df_MI_3['Measurement Inequality']== '<=' )].index))\n",
    "\n",
    "# 去除活性值大于50000的条目\n",
    "df_QM = df_MI_4.drop(index=(df_MI_4.loc[(df_MI_4['Quantitative measurement'] > 50000)].index))\n",
    "\n",
    "# 去除“reference Title”为“Quantitating T cell cross-reactivity for unrelated peptide antigens.”的条目。\n",
    "df_QM = df_QM.drop(index=(df_QM.loc[(df_QM['Ref Title']== 'Quantitating T cell cross-reactivity for unrelated peptide antigens.' )].index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据标准化 【1-log10(IC50)/log10(50000 nM)】 ,IC50单位为nM\n",
    "df_QM[\"Normalized_QM\"] = 1-(df_QM[\"Quantitative measurement\"].apply(np.log10))/np.log10(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重置索引并保存文件\n",
    "df_QM = df_QM.reset_index(drop = True)\n",
    "\n",
    "df_QM.to_csv('/raid/hly/PK-panAllele/data/IEDB2022_processed.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获得测试集--取出IEDB2022中 \"Ref Date >= 2021\"的条目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_QM = pd.read_csv('/raid/hly/PK-panAllele/data/IEDB2022_processed.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2021 = df_QM[df_QM['Ref Date'] >= 2021]\n",
    "df_2021.to_csv('/raid/hly/PK-panAllele/data/IEDB2021+2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/raid/hly/PK-panAllele/data/test_data'\n",
    "for name, group in df_2021.groupby('Allele Name') :\n",
    "    # 替换符号，如将/替换成&\n",
    "    name = name.replace('/', '&')\n",
    "    name = name.replace('*','_')\n",
    "    name = name.replace(':','')\n",
    "    pd.DataFrame(group).to_csv(os.path.join(out_dir,name+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IEDB 2020年及之前的数据\n",
    "df_before_2021 = df_QM[df_QM['Ref Date'] < 2021]\n",
    "df_before_2021.to_csv('/raid/hly/PK-panAllele/data/IEDB_before_2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理“BD2013”数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 txt 文件\n",
    "ls_out=[]\n",
    " \n",
    "#打开文件\n",
    "with open('/raid/hly/PK-panAllele/data/BD2013.txt','r')as df_in:\n",
    "    #读每一行\n",
    "    for line in df_in:\n",
    "        list = line.strip().split('\\t')    #\".strip()\",清除前后空格\n",
    "        # seq = [''.join(list[:-2])]         #将多个氨基酸字符元素合并为一个元素\n",
    "        ls_out.append(list)\n",
    "df_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BD2013 = pd.DataFrame(ls_out[1:],columns=ls_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理数据\n",
    "# 筛选出species为人类的条目\n",
    "df_host = df_BD2013[(df_BD2013['species'] == 'human')]\n",
    "\n",
    "# 筛选出有meas数值的条目\n",
    "df_QM = df_host[pd.notnull(df_host['meas'])]\n",
    "\n",
    "#保留规范化的多肽序列（不含符号且不含'BXJZ'）\n",
    "    # 删除seq含'-'或' '的行\n",
    "df1 = df_QM.drop(index=(df_QM.loc[(df_QM['sequence'].str.contains('-'))].index))\n",
    "df2 = df1.drop(index=(df1.loc[(df1['sequence'].str.contains(' '))].index))\n",
    "    # 删除seq含'BXJZ'的行\n",
    "df3 = df2.drop(index=(df2.loc[(df2['sequence'].str.contains('B'))].index))\n",
    "df4 = df3.drop(index=(df3.loc[(df3['sequence'].str.contains('X'))].index))\n",
    "df5 = df4.drop(index=(df4.loc[(df4['sequence'].str.contains('J'))].index))\n",
    "df6 = df5.drop(index=(df5.loc[(df5['sequence'].str.contains('Z'))].index))\n",
    "\n",
    "# 筛选出精确的allele name（含'HLA'，'：'） \n",
    "df_QM = df6.loc[(df6['mhc'].str.contains('HLA'))]\n",
    "df_QM = df_QM.loc[(df_QM['mhc'].str.contains(\":\"))]\n",
    "\n",
    "# 仅保留'inequality'为'='的行\n",
    "df_MI = df_QM[(df_QM['inequality']=='=')]\n",
    "\n",
    "# 去除活性值大于50000的条目\n",
    "df_BD2013 = df_MI.drop(index=(df_MI.loc[(df_MI['meas'].astype(float) > 50000)].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据标准化 【1-log10(IC50)/log10(50000 nM)】 ,IC50单位为nM\n",
    "df_BD2013[\"Normalized_QM\"] = 1-(df_BD2013[\"meas\"].astype(float).apply(np.log10))/np.log10(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重置索引并保存文件\n",
    "df_BD2013 = df_BD2013.reset_index(drop = True)\n",
    "\n",
    "df_BD2013.to_csv('/raid/hly/PK-panAllele/data/BD2013_processed.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获得训练集（IEDBbefore2021 + BD2013）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_ls_1 = ['Description',\n",
    " 'Quantitative measurement',\n",
    " 'Normalized_QM',\n",
    " 'Allele Name',\n",
    " 'MHC allele class',\n",
    " ]\n",
    "\n",
    "columns_ls_2 = ['sequence',\n",
    " 'meas',\n",
    " 'Normalized_QM',\n",
    " 'mhc',\n",
    " 'MHC allele class',\n",
    " ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/raid/hly/PK-panAllele/data/IEDB_before_2021.csv',index_col=0)\n",
    "df1 = df1[columns_ls_1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('/raid/hly/PK-panAllele/data/BD2013_processed.csv',index_col=0)\n",
    "df2['MHC allele class'] = 'I'\n",
    "df2 = df2[columns_ls_2]\n",
    "df2.columns = columns_ls_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接IEDBbefore2021 + BD2013文件\n",
    "df3 = pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/raid/hly/PK-panAllele/data/train_MID'\n",
    "for name, group in df3.groupby('Allele Name') :\n",
    "    # 替换符号，如将/替换成&\n",
    "    name = name.replace('/', '&')\n",
    "    name = name.replace('*','_')\n",
    "    name = name.replace(':','')\n",
    "    pd.DataFrame(group).to_csv(os.path.join(train_dir,name+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/hly/CODE/miniconda3/envs/vaccin/lib/python3.6/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "train_dir = '/raid/hly/PK-panAllele/data/train_MID'\n",
    "train_dir_1 = '/raid/hly/PK-panAllele/data/train_MID_1'\n",
    "train_dir_2 = '/raid/hly/PK-panAllele/data/train_MID_2'\n",
    "test_dir = '/raid/hly/PK-panAllele/data/test_data'\n",
    "\n",
    "for file in os.listdir(train_dir):\n",
    "    if os.path.exists(os.path.join(test_dir,file)) :\n",
    "        out_file = train_dir_1  \n",
    "    else:\n",
    "        out_file = train_dir_2\n",
    "\n",
    "    df = pd.read_csv(os.path.join(train_dir,file),index_col=0)\n",
    "\n",
    "#### 去重,取中值\n",
    "    #按 Description列排序\n",
    "    df.sort_values(by='Description',axis=0,ascending='True', inplace=True)\n",
    "\n",
    "    #重置索引\n",
    "    df = df.reset_index(drop = True)\n",
    "\n",
    "    #创建新表，用来保存有重复的Description及其对应的measurement中位数\n",
    "    df_uniq = pd.DataFrame(columns = ['Description','Normalized_QM'])\n",
    "\n",
    "    #获得所有重复的 Description及其 measurement的中位数\n",
    "    j = 1\n",
    "\n",
    "    # Do not use parallel!!使用并行会出错！\n",
    "    for i in range(0, len(df)):\n",
    "        if(i == 0 or df['Description'][i] != df['Description'][i-1]):\n",
    "            #取出所有Description==df['Description'][i]的行\n",
    "            df_tmp = df[df['Description'] == df['Description'][i]]\n",
    "            \n",
    "            if(len(df_tmp) > 0):\n",
    "                df_tmp.sort_values(by='Normalized_QM',axis=0,ascending='True', inplace=True)\n",
    "\n",
    "                df_tmp = df_tmp.reset_index(drop = True)\n",
    "\n",
    "                index = math.ceil(len(df_tmp) / 2) - 1\n",
    "                measurement = df_tmp['Normalized_QM'][index]\n",
    "                df_uniq = df_uniq.append({'Description':df['Description'][i],'Normalized_QM':measurement}, ignore_index=True)\n",
    "\n",
    "    df = df.drop_duplicates(subset = ['Description'], keep = 'first')\n",
    "    df = df.reset_index(drop = True)\n",
    "\n",
    "    # 重新确认。在df中找到与df_unique相同的Description和对应Quantitative measurement值\n",
    "    for i in range(0, len(df_uniq)):\n",
    "        df.loc[df['Description'] == df_uniq['Description'][i], ['Normalized_QM']] = df_uniq['Normalized_QM'][i]\n",
    "\n",
    "    df.to_csv(os.path.join(out_file,file),index=0)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计\n",
    "\n",
    "#统计了各数据集的条目数，多肽长度的最值，活性值最值，标准化活性值的最值。\n",
    "\n",
    "files_dir = '/raid/hly/PK-panAllele/data/train_MID_2'\n",
    "files = os.listdir(files_dir)\n",
    "statistic = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(os.path.join(files_dir,file))\n",
    "    file_name = file.split('.')[0]\n",
    "    # 条目数\n",
    "    pep_num = len(df)\n",
    "\n",
    "    #多肽长度范围\n",
    "    pep_len_min = min(map(len,df['Description']))\n",
    "    pep_len_max = max(map(len,df['Description']))\n",
    "\n",
    "    #QM范围\n",
    "    QM_min = min(df['Quantitative measurement'])\n",
    "    QM_max = max(df['Quantitative measurement'])\n",
    "    \n",
    "    #log_QM范围\n",
    "    Normalized_QM_min = min(df['Normalized_QM'])\n",
    "    Normalized_QM_max = max(df['Normalized_QM'])\n",
    "\n",
    "    statistic.append([file_name,pep_num,pep_len_min,pep_len_max,QM_min,QM_max,Normalized_QM_min,Normalized_QM_max])\n",
    "df_stt = pd.DataFrame(statistic,columns=['HLA-allele','pep_num','pep_len_min','pep_len_max','QM_min','QM_max','Normalized_QM_min','Normalized_QM_max'])\n",
    "df_stt.sort_values(by='pep_num',axis=0,ascending=False, inplace=True)\n",
    "df_stt = df_stt.reset_index(drop = True)\n",
    "df_stt.to_csv('/raid/hly/PK-panAllele/data/train_MID_2_statistics220708.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv('/raid/hly/PK-panAllele/data/IEDB2021+2022.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = dft[(dft['MHC allele class']=='II')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for s in dft['Description']:\n",
    "    if len(s)<13 or len(s)>21:\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('vaccin': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "616f56fef8ea7183d51ad2039e0213a0ade719c1a48fd338f6185e7423826c67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
